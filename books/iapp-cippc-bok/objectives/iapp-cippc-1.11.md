# 1.11: Understand common governance principles for responsible AI

Source: IAPP CIPP/C Body of Knowledge (Version 3.1.0, Effective 1 Sept. 2025)

## Key concepts

- **OECD AI Principles**: Adopted in 2019 by 46 countries including Canada, these
  principles establish international baseline standards for trustworthy AI.
  - Five values-based principles guide AI actors
  - Five recommendations for national policies and international cooperation
  - First intergovernmental standard on AI
  - Inform domestic AI governance frameworks worldwide

- **The five OECD AI values-based principles**:
  - **Inclusive growth, sustainable development, and well-being**: AI should
    benefit people and the planet
  - **Human-centered values and fairness**: AI must respect human rights,
    democratic values, and include safeguards for fair outcomes
  - **Transparency and explainability**: AI actors should provide meaningful
    information about AI systems appropriate to the context
  - **Robustness, security, and safety**: AI systems should function
    appropriately and not pose unreasonable safety risks
  - **Accountability**: AI actors should be accountable for proper functioning
    of AI systems based on their roles and context

- **NIST AI Risk Management Framework (AI RMF)**: Published January 2023, this
  voluntary framework helps organizations design, develop, deploy, and use AI
  systems responsibly.
  - Designed to be flexible and adaptable across sectors
  - Emphasizes ongoing risk management throughout the AI lifecycle
  - Addresses both enterprise-level and societal risks
  - Complements existing risk management practices

- **NIST AI RMF core functions**: The framework organizes AI risk management
  into four interconnected functions.
  - **Govern**: Establishes culture, policies, and accountability structures
    for AI risk management
  - **Map**: Identifies and documents AI system context, capabilities,
    limitations, and potential impacts
  - **Measure**: Employs quantitative and qualitative methods to assess and
    track AI risks
  - **Manage**: Prioritizes and responds to identified risks throughout the
    AI lifecycle

- **Canada's Voluntary Code of Conduct on Responsible AI**: Announced September
  2023, this code provides guidance for organizations developing and managing
  advanced generative AI systems in Canada.
  - Focuses on advanced generative AI systems specifically
  - Voluntary commitment by signatory organizations
  - Covers development, deployment, and management practices
  - Emphasizes accountability, transparency, and safety

- **Key elements of Canada's Voluntary Code**:
  - **Accountability**: Organizations should have governance structures for AI
    oversight and designate responsible individuals
  - **Safety**: Conduct safety assessments before and during deployment
  - **Fairness and equity**: Test for bias and discriminatory outputs
  - **Transparency**: Provide clear information about AI system capabilities
    and limitations
  - **Human oversight**: Maintain meaningful human control over AI systems
  - **Valid and reliable**: Ensure AI systems perform as intended

## Common scenarios

| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Organization deploying generative AI in Canada | Apply Canada's Voluntary Code principles even if not a signatory | Code reflects government expectations for responsible AI development |
| Assessing AI system risks across lifecycle | Use NIST AI RMF's Map-Measure-Manage structure | Framework provides systematic approach to identifying and addressing AI risks |
| Developing AI governance policy | Reference OECD principles as foundational values | International consensus principles provide credible baseline |
| AI system produces unexplainable outputs | OECD transparency principle requires meaningful explanations | Context determines level of explanation needed; high-stakes decisions require more |
| Cross-border AI data processing | Consider how OECD principles align with privacy law requirements | Both frameworks emphasize accountability and human-centered values |
| Building AI oversight committee | NIST Govern function and Canada Code accountability requirements | Both frameworks require designated governance structures |

## Gotchas

- **OECD principles are not legally binding.** The OECD AI Principles are a
  soft law instrument. They guide policy development but do not create direct
  legal obligations. Organizations may still face liability under existing
  privacy and human rights laws.

- **NIST AI RMF is voluntary and flexible, not prescriptive.** The framework
  provides guidance, not checklists. Organizations must tailor implementation
  to their specific context. Claiming "NIST compliance" without substantive
  risk management is insufficient.

- **Canada's Voluntary Code is not a safe harbor.** Signing the code does not
  shield organizations from regulatory enforcement under PIPEDA, provincial
  privacy laws, or other applicable legislation.

- **Transparency does not mean full disclosure.** The OECD transparency
  principle calls for "meaningful" information "appropriate to the context."
  Trade secrets and security considerations may limit disclosure.

- **AI governance frameworks complement but do not replace privacy law.** AI
  systems processing personal information must still comply with PIPEDA or
  applicable provincial privacy laws. AI governance adds additional
  considerations, not substitutes.

- **"Human oversight" varies by risk level.** Not all AI systems require the
  same level of human intervention. Higher-risk applications (healthcare,
  employment, credit) require more meaningful human control.

## Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| OECD AI Principles adoption | 2019 | 46 adhering countries including Canada |
| NIST AI RMF publication | January 2023 | Version 1.0; updates expected |
| NIST AI RMF core functions | 4 | Govern, Map, Measure, Manage |
| Canada Voluntary Code | September 2023 | Targets advanced generative AI systems |
| OECD values-based principles | 5 | Plus 5 policy recommendations |
| AI RMF characteristics of trustworthy AI | 7 | Valid/reliable, safe, secure, accountable, transparent, explainable, privacy-enhanced, fair |

## Related topics

- **Privacy Impact Assessments**: PIAs may be required when AI processes
  personal information (Domain III.B)
- **Consent for AI processing**: How consent requirements apply to AI systems
  using personal information (Domain II.A)
- **Cross-border data transfers**: AI systems may involve international data
  flows (Objective 1.13)
- **Safeguards for personal information**: Technical and organizational
  measures applicable to AI systems (Objective 1.6)
- **Privacy Commissioner oversight**: Commissioners may investigate AI-related
  privacy complaints (Objective 1.7)
- **PIPEDA accountability principle**: Organizational accountability extends
  to AI system governance (Domain II.A)
