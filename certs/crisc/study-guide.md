# Certified in Risk and Information Systems Control Study Guide

Exam code: CRISC

This study guide is organized by exam domain and objective. Content is
extracted from 2 source books.

---

<!-- toc -->

- [Domain 1: Governance (26%)](#domain-1-governance-26%25)
  * [1.1: Collect and review information about business and IT environments](#11-collect-and-review-information-about-business-and-it-environments)
    + [Key concepts](#key-concepts)
    + [Key activities](#key-activities)
    + [Common scenarios](#common-scenarios)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide)
    + [Gotchas](#gotchas)
    + [Limits and defaults](#limits-and-defaults)
    + [Related topics](#related-topics)
  * [1.2: Identify potential or realized impacts of IT risk on business objectives](#12-identify-potential-or-realized-impacts-of-it-risk-on-business-objectives)
    + [Key concepts](#key-concepts-1)
    + [Common scenarios](#common-scenarios-1)
    + [Gotchas](#gotchas-1)
    + [Limits and defaults](#limits-and-defaults-1)
    + [Related topics](#related-topics-1)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-1)
    + [Impact categories](#impact-categories)
    + [Quantifying impact](#quantifying-impact)
    + [Risk register contents](#risk-register-contents)
  * [1.3: Identify threats and vulnerabilities to people, processes, and technology](#13-identify-threats-and-vulnerabilities-to-people-processes-and-technology)
    + [Key concepts](#key-concepts-2)
    + [Threats by asset category](#threats-by-asset-category)
  * [People](#people)
  * [Processes](#processes)
  * [Technology](#technology)
    + [Common scenarios](#common-scenarios-2)
      - [Doshi Review Manual](#doshi-review-manual)
    + [Gotchas](#gotchas-2)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-2)
      - [Doshi Review Manual](#doshi-review-manual-1)
    + [Vulnerability sources](#vulnerability-sources)
    + [Threat modeling methods](#threat-modeling-methods)
    + [Related topics](#related-topics-2)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-3)
      - [Doshi Review Manual](#doshi-review-manual-2)
    + [Key concepts (Doshi)](#key-concepts-doshi)
    + [Threat and vulnerability assessment](#threat-and-vulnerability-assessment)
    + [Threat modelling](#threat-modelling)
    + [Misuse case modelling](#misuse-case-modelling)
    + [Vulnerability assessment](#vulnerability-assessment)
    + [People-related threats and vulnerabilities](#people-related-threats-and-vulnerabilities)
    + [Process-related vulnerabilities](#process-related-vulnerabilities)
    + [Technology-related vulnerabilities](#technology-related-vulnerabilities)
  * [1.4: Evaluate threats, vulnerabilities, and risk to identify IT risk scenarios](#14-evaluate-threats-vulnerabilities-and-risk-to-identify-it-risk-scenarios)
    + [Key concepts](#key-concepts-3)
    + [Threat modeling methods](#threat-modeling-methods-1)
  * [STRIDE security mapping](#stride-security-mapping)
    + [Common scenarios](#common-scenarios-3)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-4)
      - [Doshi Review Manual](#doshi-review-manual-3)
    + [Gotchas](#gotchas-3)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-5)
      - [Doshi Review Manual](#doshi-review-manual-4)
    + [Vulnerability identification sources](#vulnerability-identification-sources)
    + [Risk assessment approaches](#risk-assessment-approaches)
    + [Related topics](#related-topics-3)
    + [Key concepts (Doshi)](#key-concepts-doshi-1)
    + [Risk scenario development](#risk-scenario-development)
  * [Risk scenario components](#risk-scenario-components)
    + [Limits and defaults](#limits-and-defaults-2)
    + [Related topics (Doshi)](#related-topics-doshi)
  * [1.5: Establish and maintain IT risk register integrated with enterprise risk profile](#15-establish-and-maintain-it-risk-register-integrated-with-enterprise-risk-profile)
    + [Key concepts](#key-concepts-4)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-6)
      - [Doshi Review Manual](#doshi-review-manual-5)
    + [Common scenarios](#common-scenarios-4)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-7)
      - [Doshi Review Manual](#doshi-review-manual-6)
    + [Gotchas](#gotchas-4)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-8)
      - [Doshi Review Manual](#doshi-review-manual-7)
    + [Limits and defaults](#limits-and-defaults-3)
    + [Related topics](#related-topics-4)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-9)
      - [Doshi Review Manual](#doshi-review-manual-8)
    + [Risk register contents](#risk-register-contents-1)
    + [Risk profile change triggers](#risk-profile-change-triggers)
  * [1.6: Facilitate identification of risk appetite and tolerance by key stakeholders](#16-facilitate-identification-of-risk-appetite-and-tolerance-by-key-stakeholders)
    + [Key concepts](#key-concepts-5)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-10)
      - [Doshi Review Manual](#doshi-review-manual-9)
    + [Key stakeholder roles](#key-stakeholder-roles)
    + [Common scenarios](#common-scenarios-5)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-11)
      - [Doshi Review Manual](#doshi-review-manual-10)
    + [Gotchas](#gotchas-5)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-12)
      - [Doshi Review Manual](#doshi-review-manual-11)
    + [Facilitation process](#facilitation-process)
    + [Documentation requirements](#documentation-requirements)
    + [Related topics](#related-topics-5)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-13)
      - [Doshi Review Manual](#doshi-review-manual-12)
    + [Stakeholder responsibilities](#stakeholder-responsibilities)
    + [Benefits of defining capacity, appetite, and tolerance](#benefits-of-defining-capacity-appetite-and-tolerance)
    + [Limits and defaults](#limits-and-defaults-4)
  * [1.7: Promote a risk-aware culture aligned with enterprise risk management](#17-promote-a-risk-aware-culture-aligned-with-enterprise-risk-management)
    + [Key concepts](#key-concepts-6)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-14)
      - [Doshi Review Manual](#doshi-review-manual-13)
    + [Common scenarios](#common-scenarios-6)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-15)
      - [Doshi Review Manual](#doshi-review-manual-14)
    + [Gotchas](#gotchas-6)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-16)
      - [Doshi Review Manual](#doshi-review-manual-15)
    + [Limits and defaults](#limits-and-defaults-5)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-17)
      - [Doshi Review Manual](#doshi-review-manual-16)
    + [Related topics](#related-topics-6)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-18)
      - [Doshi Review Manual](#doshi-review-manual-17)
- [Domain 2: Risk Assessment](#domain-2-risk-assessment)
  * [2.1: Collect and analyze documentation about internal and external environments](#21-collect-and-analyze-documentation-about-internal-and-external-environments)
    + [Key concepts](#key-concepts-7)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-19)
      - [Doshi Review Manual](#doshi-review-manual-18)
    + [Common scenarios](#common-scenarios-7)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-20)
      - [Doshi Review Manual](#doshi-review-manual-19)
    + [Gotchas](#gotchas-7)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-21)
      - [Doshi Review Manual](#doshi-review-manual-20)
    + [Limits and defaults](#limits-and-defaults-6)
    + [Related topics](#related-topics-7)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-22)
      - [Doshi Review Manual](#doshi-review-manual-21)
    + [Internal environment documentation](#internal-environment-documentation)
    + [External environment considerations](#external-environment-considerations)
    + [Information gathering methods](#information-gathering-methods)
  * [2.2: Identify potential risks and vulnerabilities affecting organization](#22-identify-potential-risks-and-vulnerabilities-affecting-organization)
    + [Key concepts](#key-concepts-8)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-23)
      - [Doshi Review Manual](#doshi-review-manual-22)
    + [Common scenarios](#common-scenarios-8)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-24)
      - [Doshi Review Manual](#doshi-review-manual-23)
    + [Gotchas](#gotchas-8)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-25)
      - [Doshi Review Manual](#doshi-review-manual-24)
    + [Tools for identifying vulnerabilities](#tools-for-identifying-vulnerabilities)
    + [Risk assessment techniques](#risk-assessment-techniques)
    + [Threat modeling methods](#threat-modeling-methods-2)
    + [Related topics](#related-topics-8)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-26)
      - [Doshi Review Manual](#doshi-review-manual-25)
    + [Risk identification methods](#risk-identification-methods)
    + [Limits and defaults](#limits-and-defaults-7)
  * [2.3: Develop IT risk scenarios based on available data](#23-develop-it-risk-scenarios-based-on-available-data)
    + [Key concepts](#key-concepts-9)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-27)
      - [Doshi Review Manual](#doshi-review-manual-26)
    + [Common scenarios](#common-scenarios-9)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-28)
      - [Doshi Review Manual](#doshi-review-manual-27)
    + [Data sources for scenario development](#data-sources-for-scenario-development)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-29)
      - [Doshi Review Manual](#doshi-review-manual-28)
    + [Gotchas](#gotchas-9)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-30)
      - [Doshi Review Manual](#doshi-review-manual-29)
    + [Risk analysis methodologies for scenarios](#risk-analysis-methodologies-for-scenarios)
    + [Risk assessment techniques supporting scenarios](#risk-assessment-techniques-supporting-scenarios)
    + [Related topics](#related-topics-9)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-31)
      - [Doshi Review Manual](#doshi-review-manual-30)
    + [Limits and defaults](#limits-and-defaults-8)
    + [Benefits of risk scenarios](#benefits-of-risk-scenarios)
  * [2.4: Identify key stakeholders for IT risk scenarios to establish accountability](#24-identify-key-stakeholders-for-it-risk-scenarios-to-establish-accountability)
    + [Key concepts](#key-concepts-10)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-32)
      - [Doshi Review Manual](#doshi-review-manual-31)
    + [Common scenarios](#common-scenarios-10)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-33)
      - [Doshi Review Manual](#doshi-review-manual-32)
    + [Gotchas](#gotchas-10)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-34)
      - [Doshi Review Manual](#doshi-review-manual-33)
    + [Limits and defaults](#limits-and-defaults-9)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-35)
      - [Doshi Review Manual](#doshi-review-manual-34)
    + [Related topics](#related-topics-10)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-36)
      - [Doshi Review Manual](#doshi-review-manual-35)
  * [2.5: Create and maintain IT risk register with recognized risk scenarios](#25-create-and-maintain-it-risk-register-with-recognized-risk-scenarios)
    + [Key concepts](#key-concepts-11)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-37)
      - [Doshi Review Manual](#doshi-review-manual-36)
    + [Common scenarios](#common-scenarios-11)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-38)
      - [Doshi Review Manual](#doshi-review-manual-37)
    + [Gotchas](#gotchas-11)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-39)
      - [Doshi Review Manual](#doshi-review-manual-38)
    + [Limits and defaults](#limits-and-defaults-10)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-40)
      - [Doshi Review Manual](#doshi-review-manual-39)
    + [Types of risk in register](#types-of-risk-in-register)
    + [Related topics](#related-topics-11)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-41)
      - [Doshi Review Manual](#doshi-review-manual-40)
  * [2.6: Determine risk appetite and tolerance aligned with business objectives](#26-determine-risk-appetite-and-tolerance-aligned-with-business-objectives)
    + [Key concepts](#key-concepts-12)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-42)
      - [Doshi Review Manual](#doshi-review-manual-41)
    + [Common scenarios](#common-scenarios-12)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-43)
      - [Doshi Review Manual](#doshi-review-manual-42)
    + [Gotchas](#gotchas-12)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-44)
      - [Doshi Review Manual](#doshi-review-manual-43)
    + [Limits and defaults](#limits-and-defaults-11)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-45)
      - [Doshi Review Manual](#doshi-review-manual-44)
    + [Related topics](#related-topics-12)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-46)
      - [Doshi Review Manual](#doshi-review-manual-45)
    + [Relationship hierarchy](#relationship-hierarchy)
    + [Alignment with business objectives](#alignment-with-business-objectives)
    + [Determining compliance with risk appetite](#determining-compliance-with-risk-appetite)
    + [Factors affecting risk appetite](#factors-affecting-risk-appetite)
    + [Risk culture relationship](#risk-culture-relationship)
    + [Periodic review requirements](#periodic-review-requirements)
    + [Benefits of defining appetite and tolerance](#benefits-of-defining-appetite-and-tolerance)
  * [2.7: Collaborate on risk awareness program and training for stakeholders](#27-collaborate-on-risk-awareness-program-and-training-for-stakeholders)
    + [Key concepts](#key-concepts-13)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-47)
      - [Doshi Review Manual](#doshi-review-manual-46)
    + [Common scenarios](#common-scenarios-13)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-48)
      - [Doshi Review Manual](#doshi-review-manual-47)
    + [Gotchas](#gotchas-13)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-49)
      - [Doshi Review Manual](#doshi-review-manual-48)
    + [Key indicators for awareness programs](#key-indicators-for-awareness-programs)
    + [Training program objectives](#training-program-objectives)
    + [Related topics](#related-topics-13)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-50)
      - [Doshi Review Manual](#doshi-review-manual-49)
- [Domain 3: Risk Response and Reporting](#domain-3-risk-response-and-reporting)
    + [Limits and defaults](#limits-and-defaults-12)
  * [3.1: Consult with risk owners to align risk responses with organizational objectives](#31-consult-with-risk-owners-to-align-risk-responses-with-organizational-objectives)
    + [Key concepts](#key-concepts-14)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-51)
      - [Doshi Review Manual](#doshi-review-manual-50)
    + [Common scenarios](#common-scenarios-14)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-52)
      - [Doshi Review Manual](#doshi-review-manual-51)
    + [Gotchas](#gotchas-14)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-53)
      - [Doshi Review Manual](#doshi-review-manual-52)
    + [Limits and defaults](#limits-and-defaults-13)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-54)
      - [Doshi Review Manual](#doshi-review-manual-53)
    + [Related topics](#related-topics-14)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-55)
      - [Doshi Review Manual](#doshi-review-manual-54)
  * [3.2: Assist risk owners in developing risk action plans](#32-assist-risk-owners-in-developing-risk-action-plans)
    + [Key concepts](#key-concepts-15)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-56)
      - [Doshi Review Manual](#doshi-review-manual-55)
    + [Common scenarios](#common-scenarios-15)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-57)
      - [Doshi Review Manual](#doshi-review-manual-56)
    + [Gotchas](#gotchas-15)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-58)
      - [Doshi Review Manual](#doshi-review-manual-57)
    + [Limits and defaults](#limits-and-defaults-14)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-59)
      - [Doshi Review Manual](#doshi-review-manual-58)
    + [Related topics](#related-topics-15)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-60)
      - [Doshi Review Manual](#doshi-review-manual-59)
  * [3.3: Advise on design and deployment of mitigating controls](#33-advise-on-design-and-deployment-of-mitigating-controls)
    + [Key concepts](#key-concepts-16)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-61)
      - [Doshi Review Manual](#doshi-review-manual-60)
    + [Control categories](#control-categories)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-62)
      - [Doshi Review Manual](#doshi-review-manual-61)
    + [Control implementation techniques](#control-implementation-techniques)
    + [Common scenarios](#common-scenarios-16)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-63)
      - [Doshi Review Manual](#doshi-review-manual-62)
    + [Post-implementation review](#post-implementation-review)
    + [Control testing best practices](#control-testing-best-practices)
    + [Gotchas](#gotchas-16)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-64)
      - [Doshi Review Manual](#doshi-review-manual-63)
    + [Related topics](#related-topics-16)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-65)
      - [Doshi Review Manual](#doshi-review-manual-64)
    + [Control implementation methods](#control-implementation-methods)
    + [Failure modes](#failure-modes)
    + [Limits and defaults](#limits-and-defaults-15)
  * [3.4: Establish accountability by assigning control ownership](#34-establish-accountability-by-assigning-control-ownership)
    + [Key concepts](#key-concepts-17)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-66)
      - [Doshi Review Manual](#doshi-review-manual-65)
    + [Common scenarios](#common-scenarios-17)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-67)
      - [Doshi Review Manual](#doshi-review-manual-66)
    + [Gotchas](#gotchas-17)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-68)
      - [Doshi Review Manual](#doshi-review-manual-67)
    + [Limits and defaults](#limits-and-defaults-16)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-69)
      - [Doshi Review Manual](#doshi-review-manual-68)
    + [Related topics](#related-topics-17)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-70)
      - [Doshi Review Manual](#doshi-review-manual-69)
  * [3.5: Support control owners in establishing procedures and documentation](#35-support-control-owners-in-establishing-procedures-and-documentation)
    + [Key concepts](#key-concepts-18)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-71)
      - [Doshi Review Manual](#doshi-review-manual-70)
    + [Common scenarios](#common-scenarios-18)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-72)
      - [Doshi Review Manual](#doshi-review-manual-71)
    + [Gotchas](#gotchas-18)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-73)
      - [Doshi Review Manual](#doshi-review-manual-72)
    + [Limits and defaults](#limits-and-defaults-17)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-74)
      - [Doshi Review Manual](#doshi-review-manual-73)
    + [Related topics](#related-topics-18)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-75)
      - [Doshi Review Manual](#doshi-review-manual-74)
    + [Exam focus](#exam-focus)
  * [3.6: Update risk register to reflect changes in risk profile](#36-update-risk-register-to-reflect-changes-in-risk-profile)
    + [Key concepts](#key-concepts-19)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-76)
      - [Doshi Review Manual](#doshi-review-manual-75)
    + [Factors triggering risk profile changes](#factors-triggering-risk-profile-changes)
    + [Common scenarios](#common-scenarios-19)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-77)
      - [Doshi Review Manual](#doshi-review-manual-76)
    + [Gotchas](#gotchas-19)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-78)
      - [Doshi Review Manual](#doshi-review-manual-77)
    + [Minimum risk register fields](#minimum-risk-register-fields)
    + [Related topics](#related-topics-19)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-79)
      - [Doshi Review Manual](#doshi-review-manual-78)
    + [Limits and defaults](#limits-and-defaults-18)
  * [3.7: Verify risk responses executed per approved action plans](#37-verify-risk-responses-executed-per-approved-action-plans)
    + [Key concepts](#key-concepts-20)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-80)
      - [Doshi Review Manual](#doshi-review-manual-79)
    + [Common scenarios](#common-scenarios-20)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-81)
      - [Doshi Review Manual](#doshi-review-manual-80)
    + [Gotchas](#gotchas-20)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-82)
      - [Doshi Review Manual](#doshi-review-manual-81)
    + [Verification techniques](#verification-techniques)
    + [Key indicators for verification](#key-indicators-for-verification)
    + [Reporting verified responses](#reporting-verified-responses)
    + [Related topics](#related-topics-20)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-83)
      - [Doshi Review Manual](#doshi-review-manual-82)
    + [Limits and defaults](#limits-and-defaults-19)
  * [3.8: Establish Key Risk Indicators (KRIs) and thresholds for monitoring](#38-establish-key-risk-indicators-kris-and-thresholds-for-monitoring)
    + [Key concepts](#key-concepts-21)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-84)
      - [Doshi Review Manual](#doshi-review-manual-83)
    + [Common scenarios](#common-scenarios-21)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-85)
      - [Doshi Review Manual](#doshi-review-manual-84)
    + [Gotchas](#gotchas-21)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-86)
      - [Doshi Review Manual](#doshi-review-manual-85)
    + [Limits and defaults](#limits-and-defaults-20)
    + [Related topics](#related-topics-21)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-87)
      - [Doshi Review Manual](#doshi-review-manual-86)
    + [SMART criteria for KRI selection](#smart-criteria-for-kri-selection)
    + [KRI design priorities](#kri-design-priorities)
    + [KRI threshold example](#kri-threshold-example)
    + [Advantages of KRIs](#advantages-of-kris)
    + [Reporting and monitoring responsibilities](#reporting-and-monitoring-responsibilities)
  * [3.9: Monitor and assess KRIs to detect IT risk profile shifts](#39-monitor-and-assess-kris-to-detect-it-risk-profile-shifts)
    + [Key concepts](#key-concepts-22)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-88)
      - [Doshi Review Manual](#doshi-review-manual-87)
    + [Common scenarios](#common-scenarios-22)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-89)
      - [Doshi Review Manual](#doshi-review-manual-88)
    + [Gotchas](#gotchas-22)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-90)
      - [Doshi Review Manual](#doshi-review-manual-89)
    + [Reporting formats for KRI monitoring](#reporting-formats-for-kri-monitoring)
    + [Control assessment techniques](#control-assessment-techniques)
    + [Related topics](#related-topics-22)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-91)
      - [Doshi Review Manual](#doshi-review-manual-90)
    + [SMART criteria for KRI selection](#smart-criteria-for-kri-selection-1)
    + [KRI design priorities](#kri-design-priorities-1)
    + [Examples of KRIs](#examples-of-kris)
    + [KRI reporting](#kri-reporting)
    + [Advantages of KRIs](#advantages-of-kris-1)
  * [3.10: Report IT risk profile changes and trends to management](#310-report-it-risk-profile-changes-and-trends-to-management)
    + [Key concepts](#key-concepts-23)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-92)
      - [Doshi Review Manual](#doshi-review-manual-91)
    + [Reporting formats](#reporting-formats)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-93)
      - [Doshi Review Manual](#doshi-review-manual-92)
    + [Reporting considerations](#reporting-considerations)
    + [Common scenarios](#common-scenarios-23)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-94)
      - [Doshi Review Manual](#doshi-review-manual-93)
    + [Gotchas](#gotchas-23)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-95)
      - [Doshi Review Manual](#doshi-review-manual-94)
    + [Reporting cadence](#reporting-cadence)
    + [Related topics](#related-topics-23)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-96)
      - [Doshi Review Manual](#doshi-review-manual-95)
    + [Factors driving risk profile changes](#factors-driving-risk-profile-changes)
  * [3.11: Facilitate identification of KPIs for control performance assessment](#311-facilitate-identification-of-kpis-for-control-performance-assessment)
    + [Key concepts](#key-concepts-24)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-97)
      - [Doshi Review Manual](#doshi-review-manual-96)
    + [Common scenarios](#common-scenarios-24)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-98)
      - [Doshi Review Manual](#doshi-review-manual-97)
    + [Gotchas](#gotchas-24)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-99)
      - [Doshi Review Manual](#doshi-review-manual-98)
    + [Control assessment techniques for KPI validation](#control-assessment-techniques-for-kpi-validation)
    + [Reporting formats for KPIs](#reporting-formats-for-kpis)
    + [Related topics](#related-topics-24)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-100)
      - [Doshi Review Manual](#doshi-review-manual-99)
    + [Limits and defaults](#limits-and-defaults-21)
    + [KPI examples by domain](#kpi-examples-by-domain)
    + [KCI examples](#kci-examples)
  * [3.12: Monitor and evaluate KPIs to measure control efficiency](#312-monitor-and-evaluate-kpis-to-measure-control-efficiency)
    + [Key concepts](#key-concepts-25)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-101)
      - [Doshi Review Manual](#doshi-review-manual-100)
    + [Common scenarios](#common-scenarios-25)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-102)
      - [Doshi Review Manual](#doshi-review-manual-101)
    + [Gotchas](#gotchas-25)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-103)
      - [Doshi Review Manual](#doshi-review-manual-102)
    + [SMART metrics for selecting key indicators](#smart-metrics-for-selecting-key-indicators)
    + [Control assessment techniques](#control-assessment-techniques-1)
    + [Reporting formats](#reporting-formats-1)
    + [Related topics](#related-topics-25)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-104)
      - [Doshi Review Manual](#doshi-review-manual-103)
    + [SMART characteristics of good KPIs](#smart-characteristics-of-good-kpis)
    + [Control monitoring and reporting](#control-monitoring-and-reporting)
    + [Limits and defaults](#limits-and-defaults-22)
  * [3.13: Review control assessment findings for effectiveness](#313-review-control-assessment-findings-for-effectiveness)
    + [Key concepts](#key-concepts-26)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-105)
      - [Doshi Review Manual](#doshi-review-manual-104)
    + [Common scenarios](#common-scenarios-26)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-106)
      - [Doshi Review Manual](#doshi-review-manual-105)
    + [Control assessment techniques](#control-assessment-techniques-2)
    + [Gotchas](#gotchas-26)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-107)
      - [Doshi Review Manual](#doshi-review-manual-106)
    + [Managing assessment findings](#managing-assessment-findings)
    + [Reporting considerations](#reporting-considerations-1)
    + [Related topics](#related-topics-26)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-108)
      - [Doshi Review Manual](#doshi-review-manual-107)
    + [Limits and defaults](#limits-and-defaults-23)
  * [3.14: Report on risk profile, control performance, and trends to stakeholders](#314-report-on-risk-profile-control-performance-and-trends-to-stakeholders)
    + [Key concepts](#key-concepts-27)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-109)
      - [Doshi Review Manual](#doshi-review-manual-108)
    + [Common scenarios](#common-scenarios-27)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-110)
      - [Doshi Review Manual](#doshi-review-manual-109)
    + [Gotchas](#gotchas-27)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-111)
      - [Doshi Review Manual](#doshi-review-manual-110)
    + [Reporting formats](#reporting-formats-2)
    + [Related topics](#related-topics-27)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-112)
      - [Doshi Review Manual](#doshi-review-manual-111)
- [Domain 4: Information Technology and Security](#domain-4-information-technology-and-security)
    + [Limits and defaults](#limits-and-defaults-24)
  * [4.1: Enterprise architecture and IT operations management](#41-enterprise-architecture-and-it-operations-management)
    + [Key concepts](#key-concepts-28)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-113)
      - [Doshi Review Manual](#doshi-review-manual-112)
    + [Common scenarios](#common-scenarios-28)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-114)
      - [Doshi Review Manual](#doshi-review-manual-113)
    + [Gotchas](#gotchas-28)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-115)
      - [Doshi Review Manual](#doshi-review-manual-114)
    + [Limits and defaults](#limits-and-defaults-25)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-116)
      - [Doshi Review Manual](#doshi-review-manual-115)
    + [Related topics](#related-topics-28)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-117)
      - [Doshi Review Manual](#doshi-review-manual-116)
  * [4.2: Project and program management principles](#42-project-and-program-management-principles)
    + [Key concepts](#key-concepts-29)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-118)
      - [Doshi Review Manual](#doshi-review-manual-117)
    + [Common scenarios](#common-scenarios-29)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-119)
      - [Doshi Review Manual](#doshi-review-manual-118)
    + [Gotchas](#gotchas-29)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-120)
      - [Doshi Review Manual](#doshi-review-manual-119)
    + [Limits and defaults](#limits-and-defaults-26)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-121)
      - [Doshi Review Manual](#doshi-review-manual-120)
    + [Related topics](#related-topics-29)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-122)
      - [Doshi Review Manual](#doshi-review-manual-121)
    + [SDLC models](#sdlc-models)
    + [SDLC phases](#sdlc-phases)
    + [Success factors for effective project management](#success-factors-for-effective-project-management)
    + [Project risks](#project-risks)
    + [Risk assessment considerations](#risk-assessment-considerations)
    + [Project management tools](#project-management-tools)
    + [Project closeout](#project-closeout)
    + [Changeover techniques](#changeover-techniques)
  * [4.3: Disaster recovery and business continuity management](#43-disaster-recovery-and-business-continuity-management)
    + [Key concepts](#key-concepts-30)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-123)
      - [Doshi Review Manual](#doshi-review-manual-122)
    + [Common scenarios](#common-scenarios-30)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-124)
      - [Doshi Review Manual](#doshi-review-manual-123)
    + [Gotchas](#gotchas-30)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-125)
      - [Doshi Review Manual](#doshi-review-manual-124)
    + [Limits and defaults](#limits-and-defaults-27)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-126)
      - [Doshi Review Manual](#doshi-review-manual-125)
    + [Related topics](#related-topics-30)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-127)
      - [Doshi Review Manual](#doshi-review-manual-126)
    + [Recovery site types](#recovery-site-types)
    + [BCP phases](#bcp-phases)
    + [BCP content requirements](#bcp-content-requirements)
    + [RTO and RPO relationships](#rto-and-rpo-relationships)
    + [BIA objectives](#bia-objectives)
    + [Cost factors in BIA](#cost-factors-in-bia)
  * [4.4: Data lifecycle management and data protection](#44-data-lifecycle-management-and-data-protection)
    + [Key concepts](#key-concepts-31)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-128)
      - [Doshi Review Manual](#doshi-review-manual-127)
    + [Common scenarios](#common-scenarios-31)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-129)
      - [Doshi Review Manual](#doshi-review-manual-128)
    + [Gotchas](#gotchas-31)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-130)
      - [Doshi Review Manual](#doshi-review-manual-129)
    + [Limits and defaults](#limits-and-defaults-28)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-131)
      - [Doshi Review Manual](#doshi-review-manual-130)
    + [Related topics](#related-topics-31)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-132)
      - [Doshi Review Manual](#doshi-review-manual-131)
  * [4.5: System development life cycle (SDLC) and change management](#45-system-development-life-cycle-sdlc-and-change-management)
    + [Key concepts](#key-concepts-32)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-133)
      - [Doshi Review Manual](#doshi-review-manual-132)
    + [Common scenarios](#common-scenarios-32)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-134)
      - [Doshi Review Manual](#doshi-review-manual-133)
    + [Gotchas](#gotchas-32)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-135)
      - [Doshi Review Manual](#doshi-review-manual-134)
    + [Limits and defaults](#limits-and-defaults-29)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-136)
      - [Doshi Review Manual](#doshi-review-manual-135)
    + [Related topics](#related-topics-32)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-137)
      - [Doshi Review Manual](#doshi-review-manual-136)
  * [4.6: Emerging technologies (AI/LLM, quantum computing, Zero Trust)](#46-emerging-technologies-aillm-quantum-computing-zero-trust)
    + [Key concepts](#key-concepts-33)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-138)
      - [Doshi Review Manual](#doshi-review-manual-137)
    + [Common scenarios](#common-scenarios-33)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-139)
      - [Doshi Review Manual](#doshi-review-manual-138)
    + [Gotchas](#gotchas-33)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-140)
      - [Doshi Review Manual](#doshi-review-manual-139)
    + [Limits and defaults](#limits-and-defaults-30)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-141)
      - [Doshi Review Manual](#doshi-review-manual-140)
    + [Related topics](#related-topics-33)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-142)
      - [Doshi Review Manual](#doshi-review-manual-141)
    + [Exam-critical points](#exam-critical-points)
  * [4.7: Information security frameworks and standards](#47-information-security-frameworks-and-standards)
    + [Key concepts](#key-concepts-34)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-143)
      - [Doshi Review Manual](#doshi-review-manual-142)
    + [Common scenarios](#common-scenarios-34)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-144)
      - [Doshi Review Manual](#doshi-review-manual-143)
    + [Gotchas](#gotchas-34)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-145)
      - [Doshi Review Manual](#doshi-review-manual-144)
    + [Limits and defaults](#limits-and-defaults-31)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-146)
      - [Doshi Review Manual](#doshi-review-manual-145)
    + [Related topics](#related-topics-34)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-147)
      - [Doshi Review Manual](#doshi-review-manual-146)
    + [Widely recognized standards and frameworks](#widely-recognized-standards-and-frameworks)
  * [4.8: Security awareness training programs](#48-security-awareness-training-programs)
    + [Key concepts](#key-concepts-35)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-148)
      - [Doshi Review Manual](#doshi-review-manual-147)
    + [Common scenarios](#common-scenarios-35)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-149)
      - [Doshi Review Manual](#doshi-review-manual-148)
    + [Gotchas](#gotchas-35)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-150)
      - [Doshi Review Manual](#doshi-review-manual-149)
    + [Limits and defaults](#limits-and-defaults-32)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-151)
      - [Doshi Review Manual](#doshi-review-manual-150)
    + [Related topics](#related-topics-35)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-152)
      - [Doshi Review Manual](#doshi-review-manual-151)
  * [4.9: Authentication, encryption, and access control principles](#49-authentication-encryption-and-access-control-principles)
    + [Key concepts](#key-concepts-36)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-153)
      - [Doshi Review Manual](#doshi-review-manual-152)
    + [Common scenarios](#common-scenarios-36)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-154)
      - [Doshi Review Manual](#doshi-review-manual-153)
    + [Gotchas](#gotchas-36)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-155)
      - [Doshi Review Manual](#doshi-review-manual-154)
    + [Limits and defaults](#limits-and-defaults-33)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-156)
      - [Doshi Review Manual](#doshi-review-manual-155)
    + [Related topics](#related-topics-36)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-157)
      - [Doshi Review Manual](#doshi-review-manual-156)
  * [4.10: Network security (firewalls, IDS/IPS, VPN, cloud security)](#410-network-security-firewalls-idsips-vpn-cloud-security)
    + [Key concepts](#key-concepts-37)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-158)
      - [Doshi Review Manual](#doshi-review-manual-157)
    + [Common scenarios](#common-scenarios-37)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-159)
      - [Doshi Review Manual](#doshi-review-manual-158)
    + [Gotchas](#gotchas-37)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-160)
      - [Doshi Review Manual](#doshi-review-manual-159)
    + [Limits and defaults](#limits-and-defaults-34)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-161)
      - [Doshi Review Manual](#doshi-review-manual-160)
    + [Related topics](#related-topics-37)
      - [CRISC All-in-One Exam Guide](#crisc-all-in-one-exam-guide-162)
      - [Doshi Review Manual](#doshi-review-manual-161)

<!-- tocstop -->

## Domain 1: Governance (26%)

### 1.1: Collect and review information about business and IT environments
#### Key concepts

- **Governance of Enterprise IT (GEIT)** (also **Enterprise governance of IT (EGIT)**): The process of managing IT activities
  - Board of Directors holds primary responsibility
  - Implemented through leadership, organizational structures, policies, and performance monitoring
  - Leverages technology to support and optimize enterprise needs
  - Addresses applicable laws, regulations, and compliance
  - Ensures IT investments align with business objectives and that IT risks are addressed
  - Helps generate value for stakeholders by:
    - Achieving benefits
    - Optimizing risks
    - Optimizing resourcse

- **Enterprise Architecture (EA)**: Foundation for effecitvely running a business
  - **Business architecture**
    - Captures how the business operates
    - Defines processes in context of org
  - **Application architecture**: Defines software that enables business objectives
  - **Data architecture**: Models that facilitate working with different data sources and formats
  - **Technology architecture**: Underlying infrastructure needed to run business applications
  - Common frameworks: TOGAF, Zachman, DODAF, FEAF, SABSA

- **Risk Profile**: Overall risk exposure of the organization
  - Enterprise factors
    - Regulations
    - Technology changes
    - Business objectives
    - Mergers and acquisitions
    - Competitors
  - IT risk factors
    - Emerging threats
    - Malicious actors
    - Incidents
    - Privacy frameworks
    - New/acquired assets supply chain risks
  - Need to define actionable Key Risk Indicators (KRIs) to monitor risks

- **Risk Appetite, Tolerance, and Capacity**:
  - **Risk appetite**: Amount of risk org is willing to accept to achieve objectives
  - **Risk tolerance**: Acceptable amount of variation from risk appetite
  - **Risk capacity**: Maximum risk before threatening organizational existence
  - Hierarchy: appetite â‰¤ tolerance < capacity

- **Organizational structure**: Defines roles, responsibilities, and accountability
  - Board of directors: oversight and direction
  - Management: execute and implement governance decisions
  - IT risk manager: understand Enterprise Risk Management (ERM) structure
  - RACI model: assign roles for projects

- **RACI Model**: Tool for determining project responsibilities
  - **Responsible**: Who does the work
  - **Accountable**: Who provides resources to do the work and is answerable for success
  - **Consulted**: Subject matter experts, business process owners
  - **Informed**: Stakeholders affected by success or failure

- **Organizational culture**: Determines behaviour toward risk management
  1. **Vulnerable**: Responds after risk materializes; indifferent to complaints/compliance
  2. **Reactive**: Responds to complaints or compliance requirements
  3. **Compliant**: Defines responsibilities but still driven by external requirements
  4. **Proactive**: Senior management is informed and sponsors risk management activity
  5. **Resilient**: Risk management is baked into all processes with clear accountability

- **Organizational assets**: Anything providing value to the organization
  - **People**: Greatest asset; org is vulnerable to loss of key expertise
  - **Technology**: Outdated systems increase malware and patch risk
  - **Data**: Requires classification before deciding on which controls to apply (proportional to value)
  - **Intellectual property**: Trademarks, copyrights, patents, trade secrets

- **Policy documentation hierarchy**: Translates strategy into action
  - **Policies**: High-level management intent (business decisions)
  - **Standards**: Mandatory requirements that satisfy security control objectives
  - **Procedures**: Documented steps for specific tasks (SOPs, runbooks)
  - **Guidelines**: Recommended practices that permit discretion

- **Business and IT alignment**
  - IT activities must align with business objectives to deliver value
    - Risk consultant should verify IT and business requirements are integrated and moving in the same direction
  - A strategic IT plan must contain a clear statement of IT's vision and mission
  - IT can add value only when IT strategies align with business strategy

- **Organizational assets**: Includes people, technology, data, intellectual property, and business processes
  - Risk management's prime objective: safeguard these assets
  - Asset valuation considers
    - Reputational loss
    - Third-party impact
    - Business continuity
    - Monetary loss
    - Contract breaches
    - Competitive advantage loss

- **Risk culture**: Values, beliefs, and attitudes about risk held by the  organization
  - Determines which risk management methodology to choose
  - Risk appetite depends on culture and predisposition toward risk taking
  - In a mature culture, employees:
    - Recognize risk
    - Discuss it openly
    - Collaborate to resolve

#### Key activities

- **First step in understanding strategic IT risk**: Discuss with senior executives to understand business strategy/goals
  - Provides insight into expectations and dependencies from IT
  - Reveals potential risks

- **Business process review**: Evaluates how effective/efficient processes are in achieving objectives
  - Identifies process issues, gathers improvement information, reviews project progress
  - Business process owners provide the best feedback on IT system effectiveness
    - They understand system functionalities and links to business objectives

- **Documentation review before risk assessment**
  - Purpose: understand current business processes
  - To do a good job, risk assessor must:
    - Understand business objectives, processes, and environment
    - Thoroughly understand business processes and technology in scope

- **Review organizational charts**
  - Primary purpose: understanding individials' roles, responsibilities, and authorities
  - Helps determine how to properly segregate functions


#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario/activity | Correct approach | Why |
| -------- | ---------------- | --- |
| New risk manager joining organization | Understand culture and sponsorship first | Culture determines how risk management will be received |
| Assessing IT risk for first time | Identify and inventory assets | "You can't protect what you don't know exists" |
| Determining control requirements | Classify data and value assets | Controls should be proportional to asset value |
| Building risk program without support | Obtain senior management sponsorship | Without sponsorship, budget and legitimacy are insufficient |
| Multiple stakeholders have unclear roles | Implement RACI matrix | Clarifies responsibilities with varying priorities |
| IT governance effectiveness unclear | Ensure stakeholder involvement | Addressing stakeholder needs drives IT governance success |
| Major IT investment | Risk practitioners provide accurate, timely information | Enables well-informed decisions with due diligence |
| Aligning risk with business objectives | Maintain active leadership communication | Risk supports business, not the reverse |
| Determining if IT supports business objectives | Interview business process owners | They understand system functionalities and linkage to objectives; unbiased viewpoint |
| Understanding strategic IT risk | Discuss with senior executives first | Provides view of expectations, dependencies, and potential risks |
| Reviewing documentation before risk assessment | Focus on understanding current business processes | Assessment effective only with awareness of objectives, processes, environment |
| Reviewing organizational chart | Identify roles, responsibilities, authority | Determines proper segregation of functions |

#### Gotchas

- **Governance versus management**
  - Governance provides oversight and risk optimization for stakeholders
  - Management implements goals set by governance

- **Risk tolerance versus risk capacity**
  - Can operate within risk tolerance using compensating controls
  - Cannot exceedi capacity without threatening organizational existence

- **Policies versus technology**
  - Policies are business decisions
  - Technology determines how policies are implemented

- **Risk management alignment**
  - Align risk management with business objectives, not vice versa

- **Culture trumps training**: Risk culture is must be communicated from the top and exhibited by leadership

- **Cost of controls**: Control costs should never exceed asset value

- **Exception management**
  - OK to deviate from policy when enabling business objectives
  - Must have  explicit business process owner approval and central logging.

- **Senior management vs. process owners**
  - Eenior executives understand strategic risk and goals
  - Business process owners assess IT system effectiveness in meeting goals

- **First step**: always gather info about current and future business environment

- **Purpose of documentation review**: Understand business processes and objectives

- **Risk culture vs. industry practices**
  - Risk culture determines which risk management methodology selection to select
  - Industry practices or cost-benefit analyses are not factors

- **Centralized vs. decentralized governance**
  - Centralized: more consistent, better resource use
  - Decentralized: better local alignment and faster turnaround

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| CRISC Governance domain weight | 26% | Approximately 39 exam questions |
| Experience requirement | 3 years minimum | In at least 2 of 4 CRISC domains |
| Policy review frequency | Annual minimum | Or after major business/infrastructure changes |
| Exception review | Annual | Remove unnecessary policy exceptions |
| Risk acceptance ceiling | Risk capacity | May exceed appetite/tolerance but never capacity |
| Data disposal standard | NIST 800-88 | Industry-standard media sanitization |
| Information security policy review | Annual minimum | Required to address new and emerging risks |
| IT governance responsibility | Board of Directors | Primary, not delegated |
| Risk management sign-off | Senior Management | Final approval authority |
| Risk program execution | Mid-level management | Centrally located with operational understanding |

#### Related topics

- **Three lines of defense (3LoD)**: First line (operational management owns
  risk), second line (risk/compliance oversight), third line (audit/assurance)
- **IT risk management lifecycle**: Identification â†’ Assessment â†’ Response â†’
  Monitoring â†’ Reporting
- **Common IT risks**: Access, availability, cyber/security, emerging tech,
  infrastructure, integrity, investment, program/project, relevance, schedule,
  talent, third-party, fourth-party
- **Enterprise risk management (ERM)**: Combines departmental risk programs
  into unified enterprise view
- **Capability Maturity Model (CMM)**: Assesses process maturity from ad hoc
  practices to optimized processes (5 levels)
- **Organizational goals and strategy**: Understanding business objectives is
  prerequisite to collecting environment information
- **Organization structure**: Organizational chart review supports
  understanding of roles and responsibilities
- **Organization culture**: Risk culture affects how information is gathered
  and communicated
- **Business process review**: Core method for collecting business
  environment information
- **Organizational assets**: Asset identification is key outcome of
  environment review

### 1.2: Identify potential or realized impacts of IT risk on business objectives
#### Key concepts

- **IT risk categories**: IT risk affects business objectives through:
  - IT value enablement risk: delivered projects fail to create expected value, causing loss of shareholder value and missed opportunities
  - IT program and project delivery risk: projects not delivered as agreed, leading to strategic misalignment with stakeholders
  - IT operations and service delivery risk: services fail to meet SLAs, disrupting business operations

- **Risk measurement principle**: IT risk must be measured by its impact on IT services and the business operations those services support
  - IT risk is a subset of enterprise risk
  - Impact assessment considers effects on confidentiality, integrity, and availability

- **Impact on business objectives**: Risk management efforts must align with business objectives to obtain senior management sponsorship
  - Steering committees with cross-functional participants focus on high-risk areas that adversely impact business objectives
  - Risk scenarios in top-down assessments are developed for events that directly impact business goals

- **Tangible vs. intangible impacts**: IT risks affect both asset types:
  - Tangible: equipment, physical media, infrastructure
  - Intangible: data, knowledge, reputation, intellectual property, people
  - Loss of intangible assets (e.g., competitive advantage from IP theft) can exceed
    tangible losses

- **Enterprise risk context**: IT risk feeds into broader enterprise risk categories:
  - Strategic risk, operational risk, compliance risk, reputational risk, market risk,
    credit risk, environmental risk

- **Risk formula**: Risk = Probability Ã— Impact (zero probability or impact = zero risk)
- **Risk event**: Any unexpected occurrence that can negatively affect org goals
  - E.g. new regulatory requirements, loss of key personnel, natural disasters, ransomware attacks
- **Business Impact Analysis (BIA)**: Process to determine which business processes are critical by analyzing how disruption of each process affects org's ability to achieve goals
  - Examines risk, incidents, and interdependencies to determine impact on org goals
- **Impact assessment**: Process to determine how to classify information assets in relation to org goals
  - Evaluates criticality and sensitivity for each
- **Risk scenario**: Visualization of a possible event that can harm business goals
  - Used to imagine what could go wrong and identify hurdles

#### Common scenarios

| Scenario/action | Correct approach | Why |
| -------- | ---------------- | --- |
| Data leakage via email causing reputational damage | Trace through risk lifecycle: identify, categorize, assess impact, respond, report, monitor | Links IT control failure to business impact |
| New EHR system implementation | Top-down: BoD reviews strategic/revenue impact; bottom-up: departments assess operational impact | Combines strategic and operational impact views |
| Vendor fails to meet SLA | Assess cascading effects on dependent business processes | Third-party risk translates to service delivery risk |
| Key resource leaves organization | Evaluate talent risk impact on knowledge continuity and business operations | People are organizational assets; loss creates operational gaps |
| Valuing assets for risk assessment | Use replacement cost | Replacement cost gives realistic impact assessment; acquisition cost does not reflect current value |
| Determining criticality for BIA | Consult business process owners | Process owners possess most relevant information about impact of disruption |
| Assessing impact with no probability data | Use qualitative assessment | Qualitative methods evaluate impact through scenarios when quantitative data unavailable |
| IT not aligned with business objectives | Investment in IT has no value | IT activities that don't support business objectives create risk without corresponding benefit |

#### Gotchas

- **IT risk is not isolated**: it affects org objectives, must be communicated in business terms
- **Impact is not just financial**
  - Regulatory penalties
  - Reputational damage
  - Operational disruption
  - Loss of competitive advantage
- **Realized vs. potential**
  - Realized: has materialized and caused actual loss
  - Potential: needs assessment of likelihood and impact
- **BIA vs. risk assessment**
  - BIA: recovery priorities after disruption
  - Risk assessment: threats and impacts before they materialize
- **Risk ownership confusion**: Risk owner is responsible for managing impact and bears accountability for realized losses
- **Probability without impact is zero risk**
- **Individual low-risk aggregation**: Multiple low-level risks exploited simultaneously may have major combined impact
  - Risk aggregation evaluates combined value of low risks
- **Acquisition cost vs business value**
  - A $100 website that generates $1000 annual revenue has $1000 impact if it breaks
- **Period of downtime determines severity** (not the cause of the disruption)

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk assessment frequency | Quarterly to annually | At minimum, annual assessment required |
| RPO/RTO/MTD | Business-defined | BIA outputs that quantify acceptable impact thresholds |
| Risk register contents | Threat, vulnerability, likelihood, impact, inherent risk, controls, residual risk, owner | Minimum required fields |
| Corrective action plan (CAP) | Owner, timeline, remediation actions | Required when risk cannot be immediately remediated |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Business Impact Analysis (BIA)**: Determines RPO, RTO, and MTD to quantify acceptable downtime and data loss -- directly measures impact tolerance
- **Risk register**: Documents identified risks with impact ratings and owners; central record for tracking realized and potential impacts
- **Qualitative vs. quantitative analysis**: Qualitative uses High/Medium/Low impact ratings; quantitative assigns monetary values to potential losses
- **Risk response strategies**: Mitigate, accept, transfer, or avoid -- selection  depends on impact severity relative to risk appetite
- **Top-down and bottom-up assessment**: Top-down captures strategic impacts to business objectives; bottom-up captures operational and process-level impacts
- **Enterprise Risk Management (ERM)**: Structured process for managing risks that can adversely impact business objectives. Ensures standardized, consistent risk management across the organization.
- **Risk appetite alignment**: Risk appetite should align with business objectives so resources are directed toward high-risk areas that impact objectives.
- **CIA Principle**: Impacts on Confidentiality, Integrity, and Availability provide framework for assessing IT risk impact on business operations.
- **Key Risk Indicators (KRI)**: Metrics used to monitor changes in risk profile over time. Changes indicate potential or realized impacts requiring response.

#### Impact categories

- **Reputational loss**: Damage to organization's standing with stakeholders
- **Legal and regulatory noncompliance**: Penalties, fines, enforcement actions
- **Third-party and business partner impact**: Contractual breaches, supply chain disruption
- **Business continuity impact**: Disruption to critical operations
- **Monetary loss**: Direct financial costs from incidents
- **Breach of contracts**: Failure to meet contractual obligations
- **Loss of competitive advantage**: Intellectual property compromise,
  competitive disadvantage
- **Legal costs**: Litigation, regulatory proceedings

#### Quantifying impact

- **Single Loss Expectancy (SLE)**: Loss per incident occurrence
- **Annual Loss Expectancy (ALE)**: ARO Ã— SLE, calculates expected monetary
  loss for an asset due to a particular risk over one year
- **Annualized Rate of Occurrence (ARO)**: Number of times incident is
  expected to occur per year
- **Business value of asset**: Value created by use of the asset. If asset is
  compromised, impact equals loss of business value, not acquisition cost
- **Downtime cost**: Includes drop in sales, cost of idle resources, interest
  cost, and recovery costs

#### Risk register contents

| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk scenario | Description of potential event | Based on identified threats |
| Likelihood | Probability rating | Qualitative or quantitative |
| Potential impact | Impact rating | On business objectives |
| Priority | Risk ranking | Based on probability Ã— impact |
| Status | Current mitigation state | In progress, complete, pending |
| Risk owner | Assigned individual | Business process owner |

### 1.3: Identify threats and vulnerabilities to people, processes, and technology
#### Key concepts

- **Threat**: Anything (human, malicious code, bot, natural disaster) that could
  impact an asset and cause harm. Threats employ threat actors to exploit
  vulnerabilities; threat vectors are the paths used to access targets.
  - Organizations cannot control the existence of threats
  - Risk managers document threats as the first step in risk identification
- **Vulnerability**: A weakness in design, implementation, operation, or internal
  control of a process that exposes systems or assets to adverse threats.
  - Unlike threats, vulnerabilities can be controlled and remediated
  - Severity categories: Critical, High, Medium, Low, Informational
  - Quantified using Common Vulnerability Scoring System (CVSS)
- **Risk**: The outcome when a threat exploits a vulnerability and adversely
  affects a system. Risk = Threat + Vulnerability + Impact.
- **Threat actor**: A malicious person or group that could cause organizational
  harm.
- **Threat vector**: The path or route an adversary uses to gain access to the
  target (e.g., phishing emails, malicious websites, infected attachments).

#### Threats by asset category

### People

- **Key employee loss**: Organizations are vulnerable to losing employees with
  unique expertise. Failure to cross-train creates single points of failure.
- **Human element in breaches**: Verizon 2022 report found 82% of breaches
  involved the human element (stolen credentials, phishing, misuse, errors).
- **Insider threats**: Employees can inadvertently introduce malware, fall for
  phishing, or share sensitive information when uneducated on security.
- **Social engineering**: Attacks that rely on human behavior and psychology to
  trick people into divulging sensitive information or performing unauthorized
  actions.

### Processes

- **Procedural weaknesses**: Lack of documented policies, standards, and
  procedures creates gaps. Procedures address "how" the organization operates.
- **Inadequate termination procedures**: Failure to monitor employee offboarding
  can leave accounts active after departure.
- **Configuration management gaps**: Without baseline configurations, systems
  drift into vulnerable states.
- **Lack of change management**: Undocumented changes introduce untracked
  vulnerabilities.

### Technology

- **Outdated systems**: Legacy or unpatched systems are vulnerable to malware
  and known exploits.
- **Misconfigurations**: Cloud environments with hundreds of engineers spinning
  up infrastructure expose the organization to configuration-based
  vulnerabilities.
- **Zero-day vulnerabilities**: Unpatched vulnerabilities where no fix exists
  yet. Risk managers must monitor 0-day reports.
- **Network threats**: Spoofing attacks, SQL injection, cross-site scripting.
- **Malware**: Viruses spread through infected files, malicious websites, or
  email attachments.

#### Common scenarios

| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| New vulnerability discovered in production system | Perform threat and vulnerability analysis; prioritize by severity and exploitability | Not all vulnerabilities are critical; prioritization ensures resources address highest-risk items first |
| Key employee announces resignation | Identify knowledge gaps; implement cross-training before departure | Prevents loss of institutional knowledge and reduces single-point-of-failure risk |
| Cloud infrastructure expanding rapidly | Implement periodic configuration scans; establish baseline configurations | Multiple engineers creating infrastructure increases misconfiguration risk |
| Employees falling for phishing | Implement security awareness training within 30 days of onboarding, annually thereafter | Training is more effective than technical controls against social engineering |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Startup gains popularity, attracting hackers | Classify as emerging threat | External factor beyond organizational control; requires senior management notification |
| Missing input validation in web application | Identify as vulnerability | Weakness in control allowing SQL injection or other attacks; can be remediated |
| Alerted to organization on cyber-criminal target list | Inform senior management first | Need-to-know basis; senior managers have authority for preventive action |
| Printer stores copies on built-in hard disk | Conduct risk assessment | Evaluate disclosure risk before determining appropriate response |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Threats vs. vulnerabilities**: Threats cannot be controlled; vulnerabilities
  can be. Risk managers focus mitigation efforts on vulnerabilities, not
  eliminating threats.
- **People as assets vs. threats**: Employees are both the greatest asset and
  the biggest vulnerability. Prioritize training as much as external defenses.
- **Technical controls alone are insufficient**: Access controls and firewalls
  do not specifically address social engineering; awareness training is
  required.
- **Zero-day vs. known vulnerabilities**: Risk managers must monitor industry
  advisories (NIST, CISA) for both emerging threats and known vulnerabilities.

##### Doshi Review Manual
- **Threat vs. vulnerability confusion**: ISACA frequently tests this distinction
  - Threats are external forces we protect against (earthquakes, hackers, malware)
  - Vulnerabilities are internal weaknesses we can control (weak coding, poor access controls)

- **First step in risk identification**: Gather information about current and future environment, not immediately identifying vulnerabilities or reviewing audit reports

- **Configuration management**: Most vulnerable IT area from a security perspective due to misconfiguration and untimely OS updates

- **Threat analysis frequency**: Conduct enterprise-wide threat analysis annually to address new and emerging threats

#### Vulnerability sources

| Source | Purpose |
| ------ | ------- |
| Vulnerability assessment scans (Nessus, Qualys) | Identify open vulnerabilities in systems |
| Penetration tests | Surface exploitable weaknesses (annual or after major changes) |
| Static analysis | Find logical code issues before deployment |
| Dynamic analysis | Detect runtime vulnerabilities without source code access |
| Configuration scans | Assess misconfiguration issues in cloud/infrastructure |
| Risk assessments | Identify non-technical risks that translate to vulnerabilities |
| Zero-day reports | Track unpatched vulnerabilities requiring immediate attention |
| Industry advisories (NIST, CISA) | Stay current on recent threats and vulnerabilities |
| Vendor security bulletins | Monitor product-specific security issues |

#### Threat modeling methods

| Method | Focus |
| ------ | ----- |
| STRIDE | Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege |
| DREAD | Damage, Reproducibility, Exploitability, Affected users, Discoverability |
| PASTA | Seven-stage risk-centered methodology with business context |
| OCTAVE | Organizational risk focus; omits technological risks |
| VAST | Scalable for Agile environments; actionable outputs for developers |
| Trike | Security audit framework using risk-management approach |
| SDL (SD3+C) | Secure by Design, Default, Deployment, and Communication |

#### Related topics

##### CRISC All-in-One Exam Guide
- **IT risk identification**: First step of IT risk management; document threats
  to people, processes, and technologies per enterprise risk appetite.
- **Vulnerability management program (VMP)**: Prioritize, track, and fix
  vulnerabilities systematically; coordinate remediation timelines with
  engineering teams.
- **Security awareness training**: Critical for addressing the human element;
  train within 30 days of onboarding and at least annually.
- **Threat landscape**: Constantly changing; risk management must be ongoing.
  The "perfect" solution addressing all threats and vulnerabilities does not
  exist.

##### Doshi Review Manual
- **Risk scenarios**: Primary technique for identifying threats and vulnerabilities
- **Risk register**: Contains potential threats used in developing risk scenarios
- **Control deficiency analysis**: Identifies gaps in existing security measures
- **Risk assessment**: Foundation for setting up information security infrastructure

#### Key concepts (Doshi)

- **Threat**: Any element that can cause harm to organizational assets
  - Can exploit vulnerabilities intentionally or accidentally
  - Can be internal or external to the organization
  - Examples: hackers, natural disasters, unfavorable regulations, system failures, malware
  - Threats always exist and are beyond the organization's direct control

- **Vulnerability**: A weakness or gap in protection efforts
  - Represents lack of adequate controls
  - Can be controlled by the organization (unlike threats)
  - Examples: weak coding, missing anti-virus, weak access controls, misconfiguration

- **Threat agent**: The element that generates the threat
  - Can be internal (employees, contractors) or external (hackers, criminals)
  - Key component of risk scenarios

- **Risk event**: Unforeseen occurrence with adverse impact on organizational goals
  - Requires both likelihood of occurrence and potential impact
  - Examples: new regulatory requirements, loss of key personnel, natural disasters, ransomware attacks

#### Threat and vulnerability assessment

- **Purpose**: Detect threats and vulnerabilities impacting the business
- **Primary tool**: Risk scenarios estimate likelihood and impact of probable events
- **Risk scenario components**:
  - Agent (internal or external threat generator)
  - Threat type (natural, system failure, external attack, accidental)
  - Event (data leakage, system down, theft)
  - Asset (IT infrastructure, reputation, data)
  - Time (immediate vs. long-term impact)

#### Threat modelling

- Uses same methods and techniques as attackers (technical and non-technical)
- Purpose: Design adequate controls to address all possible threats
- Objective: Build defense-in-depth system controls
- Example: "Ping of death" attack analysis

#### Misuse case modelling

- Analyzes major errors, mistakes, and events impacting system functionality
- Objective: Ensure system resilience against errors and misuse
- Attackers can misuse ICMP, NTP, or DNS services to attack systems
- Example: Attacker changes ICMP packet size to disable target system

#### Vulnerability assessment

- **When to perform penetration tests**: Periodically and when major infrastructure changes occur
- **Best method for Internet-facing systems**: Penetration testing
- **Reviewing risk and control analysis results**: Assesses gaps between current and desired states

#### People-related threats and vulnerabilities

- **Insider threats**: Role-based access controls (RBAC) most effective countermeasure
- **Loss of key personnel**: Recognized risk event requiring contingency planning
- **Lack of awareness**: Periodic training and awareness sessions reduce risk
- **Ethical behavior**: Promoted through training, evaluation, and attestation

#### Process-related vulnerabilities

- **Configuration management**: Most susceptible to introducing vulnerabilities
- **Incident management**: Improper processes create exposure
- **Business process alignment**: Lack of alignment between technology and business creates risk

#### Technology-related vulnerabilities

- **Missing input validation**: Enables SQL injection and other web attacks
- **Weak access controls**: Allows unauthorized access to systems and data
- **Missing anti-virus**: Leaves systems exposed to malware
- **Outdated systems**: Failure to update OS code creates high risk

### 1.4: Evaluate threats, vulnerabilities, and risk to identify IT risk scenarios
#### Key concepts

- **Threat**: Anything (human, malicious code, bot, natural disaster) that could
  impact an asset and cause harm
  - Threats employ threat actors to exploit vulnerabilities
  - Threat vector: the path or route used by an adversary to gain access to a
    target
  - Threats are not within organizational control; focus effort on
    vulnerabilities instead

- **Vulnerability**: A weakness in design, implementation, operation, or
  internal control that could expose a system to adverse threats
  - Vulnerabilities can be controlled and remediated
  - Prioritize using CVSS (Common Vulnerability Scoring System)
  - Severity levels: Critical, High, Medium, Low, Informational

- **Risk**: When a threat exploits a vulnerability and adversely affects the
  system
  - Requires both a threat and an exploitable vulnerability
  - Formula: Threat + Vulnerability + Threat Vector = Risk to Asset

- **IT risk scenario**: A description of an IT-related event that could lead to
  a business impact
  - Developed using top-down approach (management perspective aligned to
    business objectives) or bottom-up approach (identified by individuals and
    teams)
  - Best practice: combine both approaches

#### Threat modeling methods

| Method | Purpose |
| ------ | ------- |
| SDL (Security Development Lifecycle) | Security at every SDLC stage; motto: SD3+C (Secure by Design, Default, Deployment, Communication) |
| STRIDE | Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege |
| DREAD | Damage, Reproducibility, Exploitability, Affected users, Discoverability |
| PASTA | Seven-stage risk-centered methodology with stakeholder collaboration |
| Trike | Security audit framework with risk-management and defensive approach |
| VAST | Scales across infrastructure, integrates with Agile, actionable outputs |
| OCTAVE | Organizational risk focus; evaluates operational risk, security practices, technology |

### STRIDE security mapping

| Threat | Desired security principle |
| ------ | -------------------------- |
| Spoofing | Authenticity |
| Tampering | Integrity |
| Repudiation | Non-repudiation |
| Information Disclosure | Confidentiality |
| Denial of Service | Availability |
| Elevation of Privilege | Authorization |

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| New vulnerability published in NVD | Check organizational impact, prioritize by CVSS score, implement controls | Proactive response reduces exposure window |
| Malware spreading via email attachments | Threat = malicious actor; Vector = email; Vulnerability = lack of email scanner or antivirus | All three elements must be addressed |
| Multiple critical vulnerabilities discovered | Prioritize Critical and High first; use threat and vulnerability analysis | Resources are limited; focus on greatest risk |
| Starting a risk assessment program | Begin with qualitative assessment, graduate to hybrid or quantitative | Qualitative is faster to implement; quantitative requires historical data |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Allow employees to identify risks anonymously | Delphi technique | Enables anonymous polling and private information gathering |
| Determine probability and likelihood of events during threat/vulnerability assessment | Use risk scenarios | Scenarios estimate likelihood and impact of probable events |
| Detect vulnerabilities in internet-facing systems | Penetration testing | Tests actual exploitability of external attack surface |
| Assess IS risk | Analyze current threats associated with information systems | Provides current exposure level rather than historical data |
| Understand potential impact of law/regulations on business | Compliance-oriented business impact analysis (BIA) | Identifies all compliance requirements and their business impacts |
| Critical data subcontracted by vendor | Review subcontracting process | Subcontracting increases risk due to loss of control |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Threat vs. vulnerability confusion**: Threats cannot be controlled; focus
  controls on vulnerabilities
- **Threat modeling timing**: Perform during design phase of SDLC, not during
  requirements (too early) or testing (too late)
- **Single solution fallacy**: No single solution addresses all threats; the
  threat landscape constantly changes
- **Vulnerability identification sources**: Risk assessments are a valid source
  of vulnerabilities despite historically being considered non-technical

##### Doshi Review Manual
- **Threat vs. vulnerability confusion**: Threats are external forces we protect
  against (not controllable); vulnerabilities are internal weaknesses
  (controllable)

- **First step in risk identification**: Gather information about current and
  future environment - not identifying vulnerabilities or reviewing audit
  reports

- **Hackers targeting a popular startup**: This is an emerging threat, not an
  emerging vulnerability or impact

- **Risk scenarios are not used in all assessments**: They are specifically used
  in threat and vulnerability assessment, not IT audit, gap assessment, or
  general security assessment

- **Penetration testing timing**: Best performed after infrastructure changes,
  not on a fixed schedule or after an attack attempt

- **Configuration management**: Most vulnerable process because
  misconfiguration and failure to update OS code correctly pose very high risk

#### Vulnerability identification sources

| Source | Description |
| ------ | ----------- |
| Vulnerability scans | Nessus, Qualys; automated scanning for open vulnerabilities |
| Penetration tests | Annual or after major changes; findings reveal exploitable weaknesses |
| Static analysis | Code pipeline tools; identifies logical issues in source code |
| Dynamic analysis | Runtime scanning; no access to source code |
| Configuration checks | Cloud environment scans; catches misconfiguration issues |
| Risk assessments | Non-technical risks that translate to vulnerabilities |
| Zero-day findings | Unpatched vulnerabilities; monitor and remediate urgently |
| Industry advisories | NIST, CISA publications on recent threats |
| Vendor bulletins | Security feeds from technology vendors |

#### Risk assessment approaches

| Approach | Characteristics |
| -------- | --------------- |
| Qualitative | Subjective; uses High/Medium/Low ratings; requires experience; less expensive |
| Quantitative | Objective; calculates monetary value at risk; requires historical data; more expensive |
| Hybrid (semiquantitative) | Combines both; assigns numeric scores (1-5) to likelihood and impact; result ranges 1-25 |

#### Related topics

- Risk register: Repository for documenting identified risk scenarios
- Vulnerability management program (VMP): Prioritize, track, and remediate
  vulnerabilities per severity
- Business impact analysis: Complements risk scenario identification with impact
  quantification
- Control design: Implement controls to limit probability of threat exploiting
  vulnerability
#### Key concepts (Doshi)

- **Threat**: Any factor that can cause harm to organizational assets
  - Can be internal or external to the organization
  - Examples: hackers, natural disasters, unfavorable regulations, malware,
    system failure
  - Threats are beyond direct organizational control
  - Unidentified threats are more dangerous than documented ones

- **Vulnerability**: A weakness or gap in protection efforts
  - Represents lack of adequate controls
  - Can be controlled by the organization (unlike threats)
  - Examples: weak coding, missing anti-virus, weak access control,
    misconfiguration
  - Configuration management is the most vulnerable area from an information
    security perspective

- **Risk scenario**: A visualization of a possible event with adverse business
  impact
  - Based on identified risks and potential threats from the risk register
  - Most effective technique for assessing business risk
  - Helps estimate frequency and impact of risk events
  - Components: agent, threat type, event, asset, time

- **Threat modelling**: Uses attacker methods and techniques to identify
  potential attacks
  - Purpose: design adequate controls to address all possible threats
  - Objective: build defense-in-depth system controls

- **Misuse case modelling**: Analyzes major errors, mistakes, and events
  impacting system functionality
  - Objective: ensure system resilience against errors and misuse
  - Attackers may misuse ICMP, NTP, or DNS services for attacks

#### Risk scenario development

| Approach | Perspective | Focus | Scope |
| -------- | ----------- | ----- | ----- |
| Top-down | Senior management | Business objectives | IT and non-IT risks |
| Bottom-up | Process owners/employees | Job functions | Process-level risks |
| Combined | Both | Complementary coverage | Most effective approach |

### Risk scenario components

| Component | Description |
| --------- | ----------- |
| Agent | Element generating the threat (internal or external) |
| Threat type | Nature: natural, system failure, external attack, accidental |
| Event | Incident nature: data leakage, system down, theft |
| Asset | Impacted resource: IT infrastructure, reputation, data |
| Time | Impact timeframe: immediate vs. long-term |

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Enterprise-wide threat analysis frequency | Annual | Address new and emerging threats |
| Penetration test timing | After infrastructure changes | Also periodic basis |
| Risk identification first step | Information gathering | Before vulnerability identification |
| Risk scenario first step | Identify risk factors | Before developing scenarios |

#### Related topics (Doshi)

- Risk register: Documents identified risks; serves as source for potential
  threats when developing risk scenarios
- Vulnerability assessment: Regular assessments to bridge gaps before adversary
  exploitation
- Control deficiency analysis: Lack of adequate controls indicates
  vulnerabilities
- Offshore data transfer: Key considerations are privacy laws/regulations and
  security controls in outsourcing contracts

### 1.5: Establish and maintain IT risk register integrated with enterprise risk profile
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Risk register**: A central repository documenting all identified risks from
  risk assessments. Can be a sophisticated SaaS tool or a spreadsheet. Serves
  as the single source of truth for organizational risk tracking.
  - Minimum required fields: threats, vulnerabilities, likelihood, impact,
    inherent risk, current controls, residual risk, countermeasures, risk owner
  - Should be a live document updated when risk changes due to internal or
    external factors
  - Immediate output of any completed risk assessment

- **Risk catalog**: The collection of all documented risks in the risk
  register. Provides a baseline for the risk assessment program. Industry risk
  catalogs can be leveraged to establish initial risk baselines.

- **Enterprise risk profile**: The overall risk exposure of the organization
  across all risk types. Factors affecting the profile include:
  - New regulations
  - Technology changes
  - Business objective changes
  - Mergers and acquisitions
  - Direct and indirect competitors

- **IT risk profile**: The subset of enterprise risk focused on IT-specific
  exposures. Influenced by:
  - Emerging threats
  - Internal and external malicious actors
  - Incidents
  - IT regulations and privacy frameworks
  - New or acquired assets
  - Supply chain risks

- **Enterprise Risk Management (ERM)**: The umbrella program combining all
  individual risk programs across departments. IT risk managers must be
  acquainted with ERM and establish roles using tools like RACI.

- **Risk owner**: A manager or executive accountable for risk treatment
  decisions. Must be recorded in the risk register for each identified risk.
  - Provides budget and mandate for risk response
  - Owns the loss incurred if risk materializes
  - Should be a single individual per risk for clear accountability

- **Control owner**: The individual responsible for implementing and
  maintaining a specific control. Should be noted in the risk register when
  identified. Ideally separate from risk owner to maintain segregation of
  duties.

##### Doshi Review Manual
- **Risk register**: Centralized inventory of all identified risks consolidating
  risk data for driving risk response and tracking risk status across the
  organization
  - Starts with the risk identification stage
  - Documents risk scenarios with description, category, probability, impact,
    risk score, risk owner, and risk treatment
  - Enables prioritization by providing complete view of all risks (e.g., 100
    low, 50 medium, 20 high risks)
  - Supports decision-making by improving visibility into organizational risk

- **Risk profile**: Overall risk status the organization is exposed to
  - Represents aggregated risk to enterprise (historical and emerging)
  - Must be kept updated with new and emerging risks
  - Enables risk-aware business decisions by management
  - Provides current risk status for the organization

- **Enterprise risk management (ERM)**: Structured practices, methods, and
  processes for managing risks that can adversely impact business objectives
  - Ensures standardized, consistent approach across the organization
  - Without ERM, different departments may use different methodologies
  - Facilitates comparison of risk management results across departments

- **Integration requirement**: Risk register must reflect and update the
  enterprise risk profile
  - Changes in risk profile must be captured in the risk register
  - Risk register provides status of organization's current risk profile
  - Serves as the single source of truth for risk status

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Risk impacts multiple business units | Assign owner who can provide budget, resources, and expertise | Single accountability enables effective remediation |
| Risk cannot be immediately remediated | Create Corrective Action Plan (CAP) with owner, timeline, and actions | Ensures tracking and eventual resolution |
| Same person as risk and control owner | Acceptable but should be avoided | Segregation of duties maintains oversight integrity |
| New IT risk identified | Enter into risk register with all required fields and link to enterprise risk | Maintains integrated view of organizational risk |
| Risk profile changes due to external factors | Update risk register and re-prioritize | Register must reflect current state |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Identify changes in risk profile | Review the risk register | Risk register captures all profile changes and current status |
| Determine current risk status | Use risk register dashboard | Provides complete picture of organization's risk profile |
| New risk identified but not mitigated | Capture in risk register and maintain remediation status | All risks must be documented with their current state |
| Risk is no longer relevant | Remove from risk register | Register should reflect only current, applicable risks |
| Activity triggering new risk initiated | Add new risk to risk register | Capture risks when activities that trigger them begin |
| Newly identified vulnerability | Discuss with owner/security manager, recommend addition to risk register | Proper escalation path ensures documented tracking |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Risk register is not comprehensive**: A limitation of risk registers is
  they may not capture all risks facing an organization. Emerging risks or
  those not yet identified will be missing.

- **Confusing BIA with risk assessment**: BIA identifies critical business
  processes for recovery prioritization. Risk assessment identifies threats and
  controls. Both feed the risk register but serve different purposes.

- **Ignoring risk reporting phase**: Often overlooked but equally important.
  Key findings must be communicated to stakeholders after the risk treatment
  cycle completes.

- **No designated risk owner**: Without a risk owner, accountability is lost
  and risks go unnoticed. Every risk in the register must have an assigned
  owner.

- **Static risk register**: The register should be continuously updated when
  technology, threats, or business objectives change. A stale register provides
  false assurance.

##### Doshi Review Manual
- **Trap: Risk register captures all risks, not just high risks**: Document all
  identified risks regardless of severity level; prioritization happens after
  capture

- **Trap: Communication plans and industry benchmarks are not risk register
  contents**: Risk register includes scenario, impact, probability, score,
  owner, and treatment - not communication plans or external benchmarks

- **Trap: Primary purpose is driving risk response, not just documentation**:
  While capturing risks is important, the primary purpose is consolidating data
  to drive the risk response plan

- **Trap: Risk register maintenance requires periodic polling**: Centralized
  register with periodic polling from risk assessors keeps it accurate; single
  owner or audit responsibility is insufficient

- **Trap: Risk profile changes trigger register updates, not vice versa**:
  Changes in profile from new tech, business processes, regulations, or market
  conditions should flow into register updates

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk acceptance review | Annual minimum | Reassess asset value and current risk level |
| KRIs | Actionable | Non-actionable KRIs provide no value to management |
| Risk response strategies | 4 types | Mitigate, accept, transfer, avoid |
| Control cost threshold | Less than effective risk | Cost of mitigation must not exceed risk value |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk appetite, tolerance, and capacity**: Define acceptable risk levels
  that inform register thresholds and escalation criteria
- **Key Risk Indicators (KRIs)**: Metrics derived from register data to monitor
  and report on risk profile changes
- **Three Lines of Defense**: First line owns risks, second line develops KRIs
  and monitors, third line audits the process
- **Inherent and residual risk**: Register tracks both states; residual =
  inherent minus implemented controls
- **RACI model**: Defines Responsible, Accountable, Consulted, and Informed
  roles for risk management activities

##### Doshi Review Manual
- **Risk ownership**: Risk register documents the owner accountable for each
  risk; mapping risk to business process owners establishes ownership

- **Key risk indicators (KRI)**: Periodic KRI monitoring identifies changes in
  risk profile that require register updates

- **Three lines of defense**: First line (process owners) actively manages risk;
  register integration ensures consistent tracking across all lines

- **Risk response planning**: Risk register drives risk action plans with start
  date, end date, strategy details, and responsible parties

- **Risk prioritization**: Register enables focusing on high-priority risks
  first (concentrate on 20 high risks before 50 medium or 100 low)

#### Risk register contents

| Field | Purpose |
| ----- | ------- |
| Risk scenario | Description of the risk event |
| Category | Classification of risk type |
| Probability | Likelihood of occurrence |
| Impact | Potential consequences |
| Risk score | Calculated priority level |
| Risk owner | Accountable senior official |
| Risk treatment | Planned or implemented response |
| Corrective actions | Steps taken to address the risk |
| Residual risk | Remaining risk after treatment |

#### Risk profile change triggers

| Trigger | Risk register action |
| ------- | -------------------- |
| New technology implementation | Assess and add associated risks |
| Business process changes | Update affected risk scenarios |
| Regulatory requirement changes | Add compliance risks |
| Market demand or customer changes | Update business impact assessments |
| Competitor policy changes | Reassess competitive risks |
| Cascading effects of minor changes | Review interdependencies |

### 1.6: Facilitate identification of risk appetite and tolerance by key stakeholders
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Risk appetite**: The amount of risk an organization is willing to accept to
  achieve its objectives
  - Represents strategic-level risk acceptance boundaries
  - Must be agreed upon with relevant stakeholders
  - Translates into standards and policies that contain risk within defined
    boundaries
  - Requires regular adjustment as business conditions change

- **Risk tolerance**: The acceptable level of variation that management is
  willing to allow to achieve its objectives
  - Represents a slight deviation from acceptable risk levels
  - Provides operational flexibility within appetite boundaries
  - Going beyond appetite but within tolerance is manageable with compensating
    controls

- **Risk capacity**: The amount of risk an organization can afford to take
  without its continued existence being called into question
  - Represents the absolute upper limit of risk exposure
  - Breaching capacity threatens organizational survival
  - Risk appetite and tolerance must always remain below capacity

- **Risk profile**: The overall risk exposure of the organization to any type
  of risk
  - Factors affecting profile: regulations, technology changes, business
    objectives, mergers/acquisitions, competitors
  - IT risk profile: overall identified IT risk exposure including emerging
    threats, malicious actors, incidents, regulatory changes

##### Doshi Review Manual
- **Risk capacity**: Maximum risk an organization can afford to take. Represents
  the absolute upper limit based on available resources and constraints.
  - Always greater than both risk tolerance and risk appetite
  - Example: Total savings of $1000 available for investment

- **Risk appetite**: Amount of risk an organization is willing to take.
  - Reflects management's predisposition toward risk taking
  - Differs by organization: risk-prone organizations have high appetite;
    risk-averse organizations have low appetite
  - Determined by organizational culture and inclination toward risk taking
  - Example: Willingness to invest $700 of available $1000

- **Risk tolerance**: Acceptable deviation from risk appetite.
  - Always lower than risk capacity
  - Can be equal to or greater than appetite
  - Represents permissible flexibility around stated appetite
  - Example: Willing to stretch investment to $750 if conditions favor it

- **Relationship hierarchy**: Risk Capacity > Risk Tolerance >= Risk Appetite
  - Risk acceptance should stay within risk appetite
  - Risk acceptance must never exceed risk capacity

#### Key stakeholder roles

- **Board of directors**: Risk owners who set strategic direction and approve
  risk appetite
- **Senior management**: Risk practitioners who operationalize appetite into
  policies
- **Business owners**: First line of defense; own both business processes and
  associated risks
- **Risk manager**: Proposes risk responses to stakeholders and ensures
  alignment with appetite
- **Executive sponsors** (CRO, CISO, CFO, CEO): Provide program sponsorship and
  wider organizational/industry perspective

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Setting initial risk appetite | Obtain agreement from relevant stakeholders; translate into standards and policies | Ensures buy-in and operationalizes appetite into enforceable controls |
| Risk exceeds appetite but within tolerance | Document compensating controls; obtain formal sign-off | Tolerance allows controlled deviation when properly managed |
| Risk approaches capacity threshold | Escalate immediately to senior management | Breaching capacity threatens organizational existence |
| Business conditions change | Regularly review and adjust appetite boundaries | Static appetite becomes misaligned with evolving objectives |
| Risk acceptance request | Document risk owner, countermeasures, duration, executive sign-off | Formal process ensures accountability and stakeholder alignment |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Aligning appetite with business objectives | Direct resources toward areas of low risk tolerance | Critical processes need more controls; ensures appropriate resource allocation |
| Determining compliance with risk appetite | Evaluate whether residual risk is within acceptable risk level | Residual risk within appetite = compliant |
| Setting appetite for new initiative | Assess organizational culture and predisposition toward risk taking | Culture is the primary driver of appetite |
| Reviewing existing appetite levels | Reassess when technology, structure, or strategy changes | External factors may invalidate prior assumptions |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Tolerance and capacity are not interchangeable**: Practitioners often
  conflate these terms; tolerance is acceptable variation, capacity is survival
  threshold
- **Risk acceptance can exceed appetite**: Acceptance may go beyond appetite
  and tolerance but must never exceed capacity
- **Appetite must align with business objectives**: High-risk areas providing
  more value should receive more resources than low-risk, low-reward processes
- **Senior management defines, not just approves**: Risk appetite and tolerance
  must be defined, approved, and clearly communicated by senior management
- **Exception process required**: Organizations need formal processes to review
  and approve exceptions to stated appetite levels

##### Doshi Review Manual
- **Trap: Confusing tolerance with appetite**: Tolerance is the deviation
  allowed from appetite, not a synonym for it. Exam questions test this
  distinction.

- **Trap: Assuming appetite is static**: Risk appetite and tolerance require
  periodic review. New technology, organizational restructuring, or strategy
  changes trigger reassessment.

- **Trap: Ignoring culture**: The most important factor determining risk
  appetite is organizational culture and predisposition toward risk taking, not
  technical factors or external benchmarks.

- **Trap: Believing any stakeholder can set appetite**: Only senior management
  has authority to approve risk appetite and tolerance. Risk practitioners
  facilitate but do not decide.

#### Facilitation process

1. Engage key stakeholders (board, executives, business owners)
2. Define risk appetite aligned with business objectives
3. Establish tolerance thresholds and capacity limits
4. Translate appetite into policies, standards, and procedures
5. Communicate framework across the organization
6. Obtain buy-in from key stakeholders
7. Implement formal exception and risk acceptance process
8. Review and adjust boundaries as conditions change

#### Documentation requirements

Risk acceptance documentation must include:
- Risk owner (business owner) accepting the risk
- Countermeasures to reduce risk in the future
- Duration of risk acceptance
- Final sign-off from executive team
- Confirmation that all relevant teams and stakeholders are aligned

#### Related topics

##### CRISC All-in-One Exam Guide
- **Three lines of defense**: Provides framework for risk ownership and
  accountability; first line owns risk, second line provides oversight
- **Risk register**: Must include risk owner and document appetite alignment
- **KRIs**: Should be actionable and enable monitoring of risk against appetite
  thresholds
- **Risk response strategies**: Mitigation, acceptance, transfer, and avoidance
  must align with stated appetite
- **Enterprise risk management**: Risk appetite is foundational to the ERM
  framework

##### Doshi Review Manual
- **Risk culture**: Organizational values and attitudes toward risk that drive
  appetite determination. Poor risk culture shows gaps between documented
  appetite and actual behavior.

- **Three lines of defense**: Business process owners (first line) keep risk
  within appetite; risk and compliance functions (second line) provide
  oversight.

- **Key Risk Indicators (KRI)**: Thresholds should align with risk appetite and
  tolerance. KRIs validate that appetite levels remain appropriate.

- **Residual risk**: The measure used to determine compliance with appetite.
  Successful risk management keeps residual risk within appetite.

- **Risk response prioritization**: Appetite and tolerance are deciding factors
  for which risks to address first and how to allocate resources.

#### Stakeholder responsibilities

- **Senior management**: Accountable for approving risk appetite and tolerance
  related to information security. Must define and formally approve both values.

- **Risk owners (business process owners)**: Responsible for monitoring that
  risk stays within tolerance levels. First line of defense in managing risks.

- **Risk practitioners**: Facilitate identification by understanding business
  processes, data flows, decision-making processes, and organizational culture.
  Design controls based on appetite and tolerance levels.

#### Benefits of defining capacity, appetite, and tolerance

- Provides evidence of risk-based decision-making processes
- Helps understand how each component of the enterprise contributes to overall
  risk profile
- Enables prioritization and approval of risk response
- Identifies specific areas where risk response is warranted
- Risks with low appetite are addressed immediately

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Approval authority | Senior management | Must formally define and approve |
| Review trigger | Technology, restructuring, strategy changes | Reassess risk portfolio when these occur |
| Compliance measure | Residual risk vs acceptable risk | Residual risk within appetite = compliant |

### 1.7: Promote a risk-aware culture aligned with enterprise risk management
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Risk-aware culture**: A common set of practices and processes, supported by
  enabling technologies, that improves decision-making and performance through
  an integrated view of how well an organization manages its unique set of
  risks.
  - GRC success depends on risk-aware culture permeating the organization
  - Culture directly impacts employee behavior toward policies and standards

- **Organizational risk culture maturity levels**: Five stages of progression:
  - **Vulnerable**: Neither senior management nor employees care about risk;
    response is always reactive after risk materializes
  - **Reactive**: Response based on employee complaints or contractual/
    compliance obligations
  - **Compliant**: Responsibilities defined but response driven by external
    compliance requirements (HIPAA, SOX)
  - **Proactive**: Senior management informed about risks and provides
    sufficient sponsorship and resources
  - **Resilient**: Clear accountabilities established and communicated;
    risk management emphasized in everything the organization does

- **Tone from the top**: Senior management must communicate and exhibit
  risk-driven culture. Leadership sponsorship is the most important factor in
  establishing a resilient culture toward risk.
  - "Tone from the top" (preferred) reflects behaviors for employees to follow
  - No amount of training works if leadership does not model risk awareness

- **Enterprise risk management (ERM)**: The integration of individual risk
  programs across the enterprise. IT risk strategy is an essential part of ERM
  as it supports all key functions and business objectives.
  - IT risk manager must be acquainted with ERM program
  - Roles and responsibilities defined using RACI model

- **Three lines of defense (3LoD)**: Organizational structure for risk
  management accountability:
  - First LoD: Operational management (owns and manages risk)
  - Second LoD: Risk monitoring and oversight (develops KRIs, monitors
    compliance)
  - Third LoD: Independent assurance (internal/external audit)

##### Doshi Review Manual
- **Risk culture**: Values, beliefs, knowledge, attitudes and understanding about
  risk shared by an organization. Reflects senior management's tendency to
  embrace, cautiously accept, or avoid risk.
  - Determines risk management methodology selection
  - Influences risk appetite and tolerance levels
  - Observable through management and employee behavior

- **Enterprise risk management (ERM)**: Structured practices, methods and
  processes for managing risks that could adversely impact business objectives.
  - Standardizes risk management across the organization
  - Enables comparison of risk results between departments
  - Requires flexibility to accommodate local culture, priorities and regulations

- **Three lines of defense**: Governance model distributing risk responsibilities.
  - First line (operational management): Business process owners who manage
    daily risks, monitor controls, ensure compliance with risk procedures
  - Second line (risk and compliance): Develops risk framework, policies and
    standards; monitors and oversees risk management across the enterprise
  - Third line (audit): Independent function providing assurance, control testing
    and attestation; reports directly to board

- **Risk ownership**: Business process owners are risk owners for their processes.
  They must identify, assess and report risks to the board. Risk monitoring
  results should be communicated to risk owners who are accountable for
  maintaining risk within acceptable levels.

- **Open communication on risk**: Enables timely escalation of suspicious
  activity, informed decisions by senior management, greater stakeholder
  awareness, and transparency to external parties.

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| New risk manager joining organization | Understand organizational culture before drafting risk strategy | Culture determines how risk initiatives will be received and adopted |
| Leadership does not prioritize risk | Escalate to demonstrate business impact; seek executive sponsorship | Without leadership buy-in, risk programs fail regardless of technical merit |
| Employees bypass security controls | Address through awareness training and leadership modeling, not just technical controls | Culture change requires visible leadership commitment |
| Annual ethics training completed but no behavior change | Integrate ethics into daily operations rather than check-the-box compliance | Ethics must be inherent in culture, not a yearly seminar |
| Determining risk appetite | Align with business objectives; translate into standards and policies | Risk appetite must support value creation while containing risk within acceptable boundaries |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Selecting risk management methodology | Assess organization's risk culture first | Risk-prone vs risk-averse organizations require different methodologies |
| Determining risk appetite | Evaluate risk culture and inclination toward risk-taking | These are the two primary factors for setting appetite |
| Problematic risk culture detected | Address blame-focused discussions; foster collaboration | Blaming prevents root cause identification and transparent discussion |
| New employee onboarding | Include security awareness before system access | Awareness must precede access to establish proper behavior |
| Improving security culture | Conduct frequent awareness campaigns | Gradual, repeated training changes organizational behavior |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Risk tolerance vs risk capacity**: Risk tolerance allows slight deviation
  from acceptable risk levels; risk capacity is the maximum risk before
  organizational existence is threatened. Both must always be less than risk
  capacity.

- **Accountability vs responsibility**: Senior management is accountable for
  risk culture and classification; operational staff are responsible for
  execution. Exam questions distinguish between who is accountable (owns the
  outcome) versus who is responsible (performs the work).

- **Policies are business decisions, not technical ones**: Technology determines
  how policies are implemented, but policy creation is a governance function
  driven by business objectives.

- **KRIs must be actionable**: Key Risk Indicators reported to stakeholders
  must enable decision-making. Non-actionable KRIs provide no value to senior
  management.

- **Ethics and culture are inseparable**: Ethics is not a check-the-box
  function. Good ethics must be an organization's cultural way of life, modeled
  from the top.

##### Doshi Review Manual
- **Risk culture vs risk appetite**: Risk culture describes attitudes and values;
  risk appetite is the specific level of risk the organization is willing to accept.
  Culture influences appetite, not the reverse.

- **First line responsibility**: Business process owners manage risk directly and
  monitor controls. They do not develop the risk framework (second line) or
  provide assurance (third line).

- **Awareness timing**: Security awareness training must occur before users
  receive system or data access, not after they become comfortable with systems.

- **Top-down approach required**: Security programs succeed when senior
  management visibly commits to and supports risk awareness. Without executive
  sponsorship, programs lack resources and authority.

- **Maturity indicator**: An organization's risk management maturity is determined
  by its risk culture and awareness level, not by the sophistication of its tools.

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Security awareness training frequency | Within 30 days of onboarding, then annually | Minimum cadence for maintaining risk-aware behavior |
| Risk assessment frequency | At least annually | May be quarterly based on risk culture and requirements |
| Risk acceptance review | Annual minimum | All documented exceptions must be revisited |
| Risk capacity threshold | Organization-specific | Exceeding capacity threatens continued existence |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Capability maturity model (CMM) | 0-5 scale | Common method to measure risk management maturity |
| Primary awareness method | Customized training per audience | System developers need secure coding; operators need function-specific training |
| Awareness effectiveness metric | Incident reports from staff | Increase indicates higher awareness, not more incidents |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Security awareness training**: Critical component for promoting risk-aware
  culture; educates employees on identifying and mitigating security risks
- **ISACA Code of Professional Ethics**: Sets conduct expectations for CRISC
  holders, including supporting professional education of stakeholders
- **Policy documentation hierarchy**: Policies, standards, procedures, and
  guidelines form the framework through which risk culture is operationalized
- **Risk appetite alignment**: Must be agreed upon with stakeholders and
  translated into enforceable standards and policies
- **RACI model**: Tool for determining roles and responsibilities across
  stakeholders with varying priorities in the ERM program

##### Doshi Review Manual
- **Risk appetite and tolerance (1.12)**: Risk culture directly influences appetite
  setting; culture determines how aggressively the organization pursues risk
- **Policies and standards (1.6)**: Risk culture shapes policy content and
  enforcement; policies formalize cultural expectations
- **Risk monitoring (3.x)**: Monitoring results feed back to risk owners; culture
  affects how openly issues are reported
- **Security awareness training (4.31)**: Primary mechanism for changing
  organizational culture; must be continuous and audience-customized

---

## Domain 2: Risk Assessment

**Weight: 22%**

### 2.1: Collect and analyze documentation about internal and external environments
#### Key concepts

##### CRISC All-in-One Exam Guide
- **IT risk identification**: First step in the risk management life cycle.
  Requires understanding the technologies used in the organization and the
  development, acquisition, implementation, integration, and sunset processes
  for those technologies. An organization can only assess and treat risks it
  knows exist.
- **Internal environment documentation**: Encompasses organizational structure,
  culture, policies, standards, procedures, guidelines, and asset inventories.
  Provides context for how the organization operates and manages risk.
- **External environment documentation**: Includes regulatory requirements,
  threat landscape data, vendor/third-party assessments, industry frameworks,
  and market conditions. Informs risk scenarios driven by factors outside the
  organization's direct control.
- **Risk profile**: The overall risk exposure of an organization. Impacted by
  new regulations, technology changes, business objective shifts, mergers and
  acquisitions, and competitor activity. IT risk profile specifically captures
  identified IT risk exposure, including emerging threats, malicious actors,
  incidents, privacy frameworks, acquired assets, and supply chain risks.
- **Top-down risk assessment**: Driven from management perspective, focused on
  risks that directly impact business objectives. Provides broader strategic
  view but may overlook operational details.
- **Bottom-up risk assessment**: Identified by individuals and teams, then
  cascaded to department and organization level. Captures granular
  process-related risks but requires complex coordination.

##### Doshi Review Manual
- **Documentation review purpose**: The primary reason for reviewing documentation before starting a risk assessment is to understand current business processes, objectives, and environment. Risk assessment is effective only when the assessor understands the organization's context.

- **First step in risk identification**: Gathering information about current and future business environment is the initial step in any risk identification process. This precedes determining threats, vulnerabilities, or risk appetite.

- **Business process review objectives**:
  - Identify issues with current processes
  - Gather information for process improvement
  - Review and monitor project progress and milestones

- **Business process owners**: Best source for feedback about IT system effectiveness. They understand system functionalities and linkage to business objectives, and provide unbiased viewpoints.

- **Organizational assets**: Risk management protects both tangible and intangible assets:
  - People (key employee risk, succession planning)
  - Technology (outdated systems, patching vulnerabilities)
  - Data (sensitive vs. critical, protection at rest and in transit)
  - Intellectual property (trademarks, patents, trade secrets)
  - Business processes (flexibility, currency)

- **Asset valuation factors**:
  - Reputational loss and legal penalties
  - Impact on third parties and business partners
  - Business continuity impact
  - Monetary loss and breach of contracts
  - Loss of competitive advantage
  - Legal costs

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| New EHR system implementation | Collect Board of Directors revenue reviews, Ethics & Compliance regulatory reports, senior management performance data, security reports | Multiple stakeholder perspectives ensure comprehensive risk identification across strategic, regulatory, and operational dimensions |
| Disagreement between business manager and security manager on vendor risk | Escalate to senior management with documented pros and cons for final input and risk acceptance | Major vendor decisions require executive judgment when risk assessment results are contested |
| First risk assessment at organization | Start with qualitative methodology, leverage industry risk catalogs to baseline | Quantitative techniques like FAIR require historical data and mature processes; checklists and qualitative ratings enable rapid program initiation |
| Assessing supplier-related risks | Review NIST SP 800-161 for supply chain guidance, identify vendor risk management strategy, assess fourth-party risks | Supply chain risks extend beyond direct vendors to their dependencies |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| External team begins risk assessment | Review documentation first to understand business processes | Assessment is ineffective without understanding business context |
| Determining IT system support of objectives | Interview business process owners | They understand system-to-objective linkage and provide unbiased feedback |
| New law impacts security requirements | Analyze which systems and processes are affected | Must determine if existing controls already address new requirements |
| Changes in organization's risk profile | Review risk register | Risk registers document all identified risks and profile changes |
| Understanding compliance impact on objectives | Compliance-oriented BIA | Identifies all compliance requirements and their business impact |
| Third-party outsourcing to foreign country | Consider laws and regulations first | Origin country laws may not be enforceable abroad |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Risk register is not optional**: All identified risks must be entered into a
  risk register. Minimum fields: threats, vulnerabilities, likelihood, impact,
  inherent risk, current controls, residual risk, countermeasures, risk owner.
- **Both approaches needed**: Best results require combining top-down and
  bottom-up risk assessment. Neither alone provides complete coverage.
- **Culture trumps process**: Senior management sponsorship and organizational
  culture toward risk are the primary determinants of risk management program
  success. Documentation quality follows cultural commitment.
- **Policies are business decisions**: Technology determines how policies are
  implemented, not what they require. Policy documentation (policies, standards,
  procedures, guidelines) forms the foundation for control implementation.
- **Asset identification precedes protection**: "You can't protect what you
  don't know exists." Asset inventories covering people, technology, data, and
  intellectual property are prerequisites for meaningful risk assessment.

##### Doshi Review Manual
- **Documentation review vs. gap analysis**: Documentation review aims to understand business processes, not to identify documentation gaps. The purpose is context, not completeness assessment.

- **Internal audit reports vs. risk register**: For tracking risk profile changes, use the risk register rather than internal audit reports. Audit reports are point-in-time; risk registers maintain ongoing risk status.

- **Previous audit reports as first step**: Reviewing previous audit reports is not the first step in risk identification. Gathering current and future environment information comes first.

- **Fresh risk assessment trigger**: Changes in business environment trigger fresh risk assessments, not purchases of new assets, information classification changes, or procedure updates.

- **Senior management accountability**: Accountability for IT system risk resides with senior management, not IT department, end users, or risk management department. Others support implementation.

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk assessment frequency | At least annually | More frequent (quarterly) assessments acceptable; many regulations require periodic assessment but do not specify frequency |
| Policy review cycle | Annually or after major change | Major business process or infrastructure changes trigger review |
| Exception review | Annually | Logged exceptions should be reviewed to remove those no longer required |
| CRISC Domain 2 weight | 20% | Approximately 30 questions on the exam |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Three Lines of Defense**: Establishes accountability structure for risk
  management; first line (operations), second line (risk management/compliance),
  third line (internal audit)
- **Business Impact Analysis (BIA)**: Identifies critical business processes and
  recovery priorities (RPO, RTO, MTD); complements risk assessment by focusing
  on recovery rather than threat identification
- **Threat modeling**: PASTA, STRIDE, and other methodologies for systematic
  threat identification; informs external environment analysis
- **RACI model**: Defines Responsible, Accountable, Consulted, Informed roles;
  essential for documenting risk management responsibilities
- **Industry frameworks**: NIST SP 800-30/37/161, ISO 27005, ISO 31000, OCTAVE,
  FAIR provide structured approaches to documentation and analysis

##### Doshi Review Manual
- **Risk register**: Central repository documenting identified risks, updated from risk identification through monitoring phases
- **Threat modelling**: Uses attacker techniques to design adequate controls; threats are external and uncontrollable
- **Vulnerability analysis**: Identifies weaknesses in protection efforts that can be controlled
- **Risk profile**: Overall risk status derived from risk register analysis
- **Enterprise risk management (ERM)**: Framework integrating business environment context with risk activities

#### Internal environment documentation

| Document type | Purpose | Key review points |
| ------------- | ------- | ----------------- |
| Policies | High-level management direction | Alignment with business objectives, approval authority |
| Standards | Mandatory requirements for policy compliance | Currency, control objective achievement |
| Procedures | Detailed steps supporting policies | Frequency of updates, operational relevance |
| Guidelines | Implementation details and examples | Practical applicability |
| Risk register | Document all identified risks | Risk owner, probability, impact, current status |
| Data classification policy | Define protection levels by asset class | Categories, protection requirements, roles |
| Data retention policy | Define retention periods | Business requirements, legal/contractual requirements |

#### External environment considerations

| Factor | Risk consideration |
| ------ | ------------------ |
| Laws and regulations | Compliance requirements, enforceability across jurisdictions |
| Contractual requirements | Third-party obligations, SLA terms |
| Industry standards | Benchmarking, peer practices |
| Threat landscape | External threat sources, emerging threats |
| Technology changes | Obsolescence risk, new vulnerabilities |
| Market conditions | Business process flexibility requirements |

#### Information gathering methods

- **Delphi technique**: Allows anonymous risk identification through multiple questionnaire rounds with expert consensus building
- **Brainstorming/structured interviews**: Gather information through meetings with individuals or small groups
- **Checklists**: Predefined lists of potential threats using previous lists, codes, or standards
- **Business impact analysis (BIA)**: Determines critical processes and recovery strategies
- **Compliance-oriented BIA**: Identifies compliance requirements and their impact on objectives

### 2.2: Identify potential risks and vulnerabilities affecting organization
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Threat**: Anything (human, malicious code, natural disaster) that could
  impact an asset and adversely affect it, resulting in harm
  - Employs threat actors to exploit vulnerabilities
  - Uses threat vectors (paths/routes) to gain access to targets
- **Vulnerability**: Weakness in design, implementation, operation, or internal
  control of a process that could expose the system to adverse threats
  - Can exist in people, processes, or technology
  - Subject to controls that organizations can implement
- **Risk**: Occurs when a threat exploits a vulnerability and adversely affects
  a system
  - Threats cannot result in risk without a vulnerability to exploit
  - Organizations control vulnerabilities, not threats
- **Risk identification**: First step in IT risk management lifecycle
  - Foundation for all subsequent risk management activities
  - "You cannot protect what you do not know exists"
  - Must document all relevant threats (technology and non-technology)
  - Requires understanding of development, acquisition, implementation,
    integration, and sunset processes
- **Risk categorization**: Follows identification to classify risk severity
  (Critical/High/Medium/Low)
- **Risk scenario**: Description of a risk event with contributing conditions
  and potential loss result
  - Top-down: Developed from management perspective, linked to business
    objectives
  - Bottom-up: Identified by individuals/teams, cascaded upward

##### Doshi Review Manual
- **Risk identification**: Process to recognize threats, vulnerabilities, assets,
  and controls of the organization
  - Primary objective: detect threats and vulnerabilities impacting the business
  - Zero-risk environment is not feasible; goal is identification for mitigation
  - First step: gather information about current and future business environment

- **Threat**: Element that can cause harm by exploiting a vulnerability
  - Can be intentional or accidental
  - Examples: hackers, natural disasters, unfavorable regulations, system failure
  - Threats are external to organizational control
  - Unidentified threats are more dangerous than documented ones

- **Vulnerability**: Weakness or gap in protection efforts
  - Represents lack of adequate controls
  - Examples: weak coding, missing anti-virus, weak access control
  - Vulnerabilities are within organizational control
  - Configuration management is most susceptible to introducing vulnerabilities

- **Risk register**: Central repository documenting all identified risks
  - Maintenance begins during risk identification phase
  - Contains: risk scenario, impact, probability, risk score, risk owner,
    risk treatment
  - Provides potential threats for developing risk scenarios
  - Updated when risk profile changes; entries removed when no longer relevant

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| New technology implementation | Identify technology-specific risks during acquisition phase | Risks vary by technology; early identification enables proactive controls |
| Data leakage incidents | Document as risk, categorize severity, assess controls | Pattern of events may reveal unidentified risk requiring mitigation |
| Outdated operating systems | Log as issue to monitor | Not yet a materialized risk but requires tracking |
| Multiple failed login attempts | Correlate events to identify incident pattern | Single event may be normal; pattern indicates attack |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Employees need anonymous risk input | Delphi technique | Preserves anonymity through facilitator |
| Assessing business-level risk | Risk scenarios | Most effective for estimating frequency and impact |
| New system implementation | Risk assessment before controls | Identifies risks before deciding mitigation |
| Third-party alert about cyber threat | Inform senior management first | They have authority for preventive action |
| Infrastructure modification | Perform penetration test | Changes introduce new exposures and vulnerabilities |
| Offshore data transfer | Evaluate laws and regulations | Local laws may not be enforceable abroad |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Threats cannot be eliminated**: Organizations can only implement controls
  to limit the probability of exploitation; the threat landscape constantly
  changes
- **Issue vs event vs incident**: Issue is unmaterialized risk to monitor;
  event is any observable occurrence; incident is an event with negative impact
  on CIA triad
- **Risk register limitations**: Does not provide comprehensive view of all
  risks; may miss emerging risks or those not yet identified
- **Quantitative vs qualitative timing**: FAIR (quantitative) is inappropriate
  for first-time risk assessments; checklists are insufficient for mature
  programs

##### Doshi Review Manual
- **Threat vs. vulnerability confusion**: ISACA frequently tests this
  distinction. Threats are what you protect against (external); vulnerabilities
  are weaknesses in protection (internal, controllable).

- **First step in risk identification**: Always gather information about current
  and future environment first, not immediately identify vulnerabilities or
  determine risk appetite.

- **Enterprise threat analysis timing**: Conduct annually to address new and
  emerging threats, not only when attacks are detected.

- **Emerging threat identification**: A startup becoming popular and attracting
  hackers represents an emerging threat, not a vulnerability or environmental
  factor.

- **Subcontracting risk**: When vendors subcontract processing of critical data,
  this increases risk because enterprise loses control over subcontractor
  processes.

- **Penetration testing timing**: Best performed after infrastructure changes,
  which are most likely to introduce new vulnerabilities.

#### Tools for identifying vulnerabilities

| Tool/Source | Purpose | Notes |
| ----------- | ------- | ----- |
| Vulnerability assessment scans | Identify open vulnerabilities | Nessus, Qualys; use CVSS scoring |
| Penetration tests | Surface security weaknesses | Required at least annually or after major changes |
| Static analysis (SAST) | Find code-level vulnerabilities | Identifies logical issues before deployment |
| Dynamic analysis (DAST) | Find runtime vulnerabilities | Tests running applications without source code |
| Configuration checks | Detect misconfigurations | Critical for cloud environments with many engineers |
| Risk assessments | Identify non-technical risks | Increasingly relevant with modern development practices |
| Zero-day findings | Track unpatched vulnerabilities | Follow security researcher publications |
| Industry advisories | Monitor external threats | NIST, CISA publish alerts |
| Vendor security bulletins | Track product-specific risks | Subscribe to vendor notification feeds |

#### Risk assessment techniques

| Technique | Use case |
| --------- | -------- |
| Brainstorming/interview | Gather broad range of potential risks from groups |
| Delphi method | Build consensus among experts via iterative questionnaires |
| Checklists | Baseline assessment for less mature programs |
| FAIR | Quantitative analysis for mature risk programs |
| Bow-tie analysis | Visualize links between causes, controls, consequences |
| Fault tree analysis | Top-down examination of event causes |
| Event tree analysis | Bottom-up probability assessment of outcomes |
| OCTAVE | Self-directed assessment with business and IT teams |

#### Threat modeling methods

| Method | Key characteristic |
| ------ | ------------------ |
| STRIDE | Categorizes threats: Spoofing, Tampering, Repudiation, Information Disclosure, DoS, Elevation of Privilege |
| DREAD | Risk assessment factors: Damage, Reproducibility, Exploitability, Affected users, Discoverability |
| PASTA | Seven-stage risk-centric methodology with stakeholder collaboration |
| SDL | Secure by Design, Default, Deployment, and Communication |
| OCTAVE | Focuses on organizational (not technological) risks |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk register**: Documents identified risks with threat, vulnerability,
  likelihood, impact, inherent risk, current controls, residual risk, and owner
- **Vulnerability management program (VMP)**: Prioritizes, tracks, and
  remediates vulnerabilities based on severity
- **CVSS**: Common Vulnerability Scoring System for quantifying vulnerabilities
  (Critical, High, Medium, Low, Informational)
- **Risk appetite and tolerance**: Identified risks must be evaluated against
  organizational thresholds for prioritization
- **Regulatory requirements**: GDPR, PCI DSS, HIPAA, SOX, and others mandate
  formal risk assessments at minimum annually

##### Doshi Review Manual
- 2.1 Risk assessment methodology: Foundation for identification process
- 2.3 Threat modelling and landscape: Detailed threat analysis techniques
- 2.4 Vulnerability and control deficiency analysis: Deep dive into weaknesses
- 2.5 Risk scenarios: Primary tool for risk identification and assessment
- 2.8 Risk register: Central documentation for all identified risks

#### Risk identification methods

- **Delphi technique**: Anonymous risk identification through expert polling
  - Two or more rounds of questionnaires
  - Results summarized and communicated by facilitator
  - Builds consensus among experts

- **Risk scenarios**: Visualization of possible adverse events
  - Most effective technique for assessing business risk
  - Estimates frequency and impact of risk
  - Components: agent, threat type, event, asset, time
  - Developed from risk register's potential threats

- **Top-down approach**: Risk events identified from senior management
  perspective
  - Focuses on business objectives and goals
  - Addresses both IT and non-IT risks
  - Facilitates management buy-in

- **Bottom-up approach**: Risk events identified from process owner/employee
  perspective
  - Focuses on process-level risks
  - Best practice: combine both approaches for comprehensive coverage

- **Threat modelling**: Uses attacker methods and techniques to identify
  potential attacks
  - Purpose: design adequate controls for all possible threats
  - Objective: build defense-in-depth system controls
  - Example: "ping of death" attack analysis

- **Misuse case modelling**: Analysis of major errors, mistakes, and events
  affecting system functionality
  - Objective: ensure system resilience against errors and misuse
  - Examples: ICMP, NTP, DNS service abuse

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Enterprise threat analysis | Annually | Addresses new and emerging threats |
| Risk register update | Ongoing | When risk profile changes |
| Risk removal from register | When irrelevant | Risk no longer applicable |
| Risk addition to register | Activity initiation | When triggering activity begins |

### 2.3: Develop IT risk scenarios based on available data

Guide

#### Key concepts

##### CRISC All-in-One Exam Guide
- **Risk scenario**: A structured description of a potential risk event that
  combines threat, vulnerability, asset, and impact into a coherent narrative
  for analysis and communication.
  - Top-down scenarios derive from business objectives and strategic risks
  - Bottom-up scenarios emerge from operational and technical observations
  - Scenarios enable consistent likelihood and impact assessment

- **Risk scenario components**:
  - **Threat**: Anything that could impact an asset adversely (human actor,
    malicious code, bot, natural disaster)
  - **Threat actor**: Entity that materializes the threat
  - **Threat vector**: Path or route used to gain access to the target
  - **Vulnerability**: Weakness in design, implementation, operation, or
    internal control that exposes the system to threats
  - **Asset**: Resource being protected
  - **Impact**: Consequence if the scenario materializes

- **Event types per ISACA**:
  - **Threat event**: Occurrence involving a threat source
  - **Loss event**: Occurrence resulting in actual harm or loss
  - **Vulnerability event**: Occurrence involving exposure of a weakness

- **Top-down risk assessment approach**: Scenarios driven from management
  perspective, related directly to business objectives. Results are broader but
  easier to gain stakeholder buy-in.
  - Board considers strategic risks with revenue implications
  - Ethics and compliance reviews regulatory risks
  - Senior management evaluates departmental risks
  - Cyber reports inform system-specific risks

- **Bottom-up risk assessment approach**: Scenarios identified by individuals
  and teams, then cascaded up to department, business unit, and organization
  level. More detailed but harder to manage due to diverse perspectives.
  - System-level components analyzed first (data storage, access controls,
    logging, vulnerabilities)
  - Departments assess operational impact
  - Management connects risks to KPIs
  - Organization evaluates regulatory and strategic alignment

##### Doshi Review Manual
- **Risk scenario**: A visualization of a possible event that can have adverse
  impact on business objectives. Used to imagine what could go wrong and
  identify hurdles to achieving business goals.
  - Must be based on identified risks from the risk register
  - Developed from potential threats to business assets
  - Examples: network unavailability, system downtime, database breach

- **Risk scenario components**: Five elements that define a complete IT risk
  scenario:
  - Agent: Element generating the threat (internal or external)
  - Threat type: Nature of threat (natural, system failure, external attack,
    accidental)
  - Event: Incident type (data leakage, system down, theft)
  - Asset: What is impacted (IT infrastructure, reputation, data)
  - Time: Temporal impact (immediate vs. long-term effects)

- **Top-down approach**: Risk events identified from senior management
  perspective by starting with business objectives.
  - Addresses risks that directly impact business goals
  - Covers both IT and non-IT risk events
  - Easier to obtain management buy-in

- **Bottom-up approach**: Risk events identified from process owner/employee
  perspective by examining job functions in specific processes.
  - Addresses process-level operational risks
  - Captures risks visible only at execution level

- **Best approach**: Combine both top-down and bottom-up approaches. They are
  complementary and should be used simultaneously.

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| New EHR system deployment | Combine top-down (board strategic view) and bottom-up (department operational risks) | Ensures both strategic alignment and operational detail |
| Malware infection propagation | Map threat actor, threat vector (email/website), vulnerability (missing controls), and asset impact | Complete scenario enables targeted controls |
| Control deficiency in access management | Implement compensating controls while addressing root cause | Mitigates immediate risk while planning remediation |
| Mass login failures in short timeframe | Escalate from event to incident classification | Pattern indicates brute-force attack requiring response |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Developing scenarios for strategic risks | Top-down approach | Aligns with business objectives and senior management goals |
| Developing scenarios for operational risks | Bottom-up approach | Process owners understand execution-level risks |
| Comprehensive risk assessment | Combined approach | Top-down addresses objectives; bottom-up addresses process-level risks |
| Ensuring unbiased scenarios | Use representative and historical data | Reduces subjectivity in probability estimates |
| Estimating likelihood of events | Use risk scenarios | Scenario analysis examines possible futures and probabilities |

#### Data sources for scenario development

##### CRISC All-in-One Exam Guide
- **Vulnerability assessment scans**: Tools like Nessus and Qualys surface open
  vulnerabilities
- **Penetration test findings**: Annual or post-change tests reveal
  exploitable weaknesses
- **Static analysis**: Code pipeline tools flag logical and security defects
- **Dynamic analysis**: Runtime scanning identifies vulnerabilities during
  execution
- **Configuration checks**: Periodic scans detect misconfiguration issues in
  cloud environments
- **Risk assessments**: Historical assessments provide non-technical risk
  context
- **Threat modeling outputs**: STRIDE, DREAD, PASTA, and other frameworks
  identify attack vectors
- **Incident and event logs**: SIEM correlation reveals patterns from
  historical data
- **Industry risk catalogs**: Pre-built scenarios from standards bodies
  baseline the assessment program

##### Doshi Review Manual
- **Risk register**: Primary source containing potential threats. The most
  important information for developing scenarios is the documented potential
  threats.
- **Historical data**: Past incidents provide basis for scenarios. Using
  representative and historical data is the most effective method to avoid
  bias.
- **Emerging risks**: New and evolving threats beyond past incidents

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Threat versus vulnerability confusion**: Threats are external and
  uncontrollable; vulnerabilities are internal and can be addressed with
  controls. Scenarios must distinguish both.

- **Single approach limitation**: Using only top-down or bottom-up approaches
  produces incomplete scenarios. Best practice combines both simultaneously.

- **Event versus incident misclassification**: A single failed login is an
  event; thousands of failed logins in seconds is an incident requiring
  response. Scenarios must account for escalation thresholds.

- **Ignoring qualitative input for quantitative models**: Quantitative methods
  like FAIR require accurate historical data. Organizations without mature data
  should use qualitative or hybrid approaches initially.

- **Static scenarios**: The threat landscape changes continuously. Scenarios
  require regular review and updates as threats, vulnerabilities, and business
  context evolve.

##### Doshi Review Manual
- **Trap: Top-down OR bottom-up**: Always combine both approaches. Neither is
  sufficient alone. Exam may present options favoring one approach - choose the
  combination.

- **Trap: Incident analysis as most effective**: Risk scenarios are the most
  effective technique for risk assessment. Incident analysis only addresses
  historical events, not emerging risks.

- **Trap: Risk scenarios minimize response efforts**: Scenarios help estimate
  frequency and impact - they do not minimize response efforts.

- **Trap: Scenarios address all potential risks**: Scenarios help identify and
  analyze risks but do not guarantee all risks are captured.

- **First step confusion**: The first step in identification of risk scenarios
  is to identify the risk factors, not to create scenarios directly.

#### Risk analysis methodologies for scenarios

| Methodology | Characteristics | Best fit |
| ----------- | --------------- | -------- |
| Qualitative | Subjective, uses High/Medium/Low ratings, relies on experience | Organizations new to risk assessment |
| Quantitative | Objective, provides monetary value at risk, requires historical data | Mature organizations with reliable data |
| Semiquantitative/Hybrid | Combines qualitative ratings with numerical scales (1-5) | Bridging between approaches |

#### Risk assessment techniques supporting scenarios

| Technique | Description |
| --------- | ----------- |
| Bow-tie analysis | Displays links between causes, controls, and consequences |
| Brainstorming/Interview | Gathers potential risks from groups for ranking |
| Cause and effect analysis | Groups contributing factors into categories |
| Delphi method | Uses expert opinion through multiple questionnaire rounds |
| FAIR | Establishes probabilities for frequency and magnitude of loss events |
| Fault tree analysis | Examines possible means for an event to occur, top to bottom |
| Event tree analysis | Assesses probability of different events resulting in outcomes |
| Monte Carlo analysis | Uses repeated random sampling for quantitative risk analysis |
| SWIFT | Uses structured brainstorming with prompts and guide words |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk register**: Repository where all developed scenarios are documented
  with likelihood, impact, controls, and ownership
- **Threat modeling**: Structured approach providing input data for scenario
  development through methods like STRIDE, PASTA, and OCTAVE
- **Business impact analysis**: Complements risk scenarios by quantifying
  impact on business operations
- **Key risk indicators**: Metrics that signal when scenario likelihood or
  impact may be changing
- **Key control indicators**: Measures of control effectiveness that indicate
  potential risk scenario exposure

##### Doshi Review Manual
- **Risk register (2.8)**: Source of potential threats for scenario development;
  scenarios are documented back into the register with probability and impact
- **Threat modeling (2.3)**: Threat-based approach identifies risks by
  understanding attack methods, motivations, and techniques
- **Risk assessment techniques (2.6)**: Scenarios feed into qualitative and
  quantitative analysis
- **Qualitative risk assessment**: Uses different scenarios with threats and
  impacts for comprehensive outcome

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Primary purpose of scenarios | Estimate frequency and impact | Enables risk assessment process |
| Most effective assessment technique | Risk scenarios | Over risk-based audit, incident analysis, or response plans |
| Key risk register input | Potential threats | Not risk owner, response plan, or reported incidents |
| Scenario development approach | Combined top-down and bottom-up | Complementary methods |

#### Benefits of risk scenarios

- Easiest and most effective way to explain risk to business process owners
- Involvement of process owners makes information gathering more relevant
- Helps identify risks aligned with business objectives
- Used in threat and vulnerability assessments to estimate likelihood and
  impact

### 2.4: Identify key stakeholders for IT risk scenarios to establish accountability
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Stakeholder**: An individual or group affected by or having influence over
  organizational risk decisions. Stakeholders include board members, senior
  executives, business owners, risk practitioners, and external parties such as
  regulators.

- **Accountability**: The obligation to answer for risk outcomes. Accountability
  ensures a dedicated individual can be reached to approve risk response
  strategies and owns the loss if a risk scenario materializes.

- **Risk owner**: The individual accountable for a specific risk. The risk owner
  provides budget and resources, mandates risk response, and is recorded in the
  risk register. There should be a single risk owner per risk to avoid diluted
  responsibility.

- **Control owner**: The person who implements or oversees the effectiveness of
  a control. Unlike risk owners, control owners may not be identifiable at risk
  assessment time but should be documented once identified.

- **RACI model**: A tool for assigning roles and responsibilities:
  - Responsible: performs the risk management work
  - Accountable: provides resources and owns project success
  - Consulted: subject matter experts with domain knowledge
  - Informed: affected by outcomes but not directly involved

- **Three Lines of Defense (3LoD)**: Framework that segregates duties and
  establishes clear accountability:
  - First line (operational management): business owners who are ultimate risk
    owners, implement controls, and maintain day-to-day risk management
  - Second line (risk and compliance): develops frameworks, monitors first line,
    communicates KRIs to stakeholders
  - Third line (audit): provides independent assurance on first and second line
    effectiveness

##### Doshi Review Manual
- **Stakeholder identification**: Process of determining who has a vested
  interest in IT risk scenarios and who must be involved in managing those
  risks
  - Effectiveness of IT governance and risk management depends on involving all
    relevant stakeholders
  - Stakeholders include internal parties (board, management, process owners)
    and external parties (regulators, auditors, customers)

- **Risk ownership**: Assignment of accountability for managing specific risks
  to individuals with appropriate authority
  - Each risk must have an assigned owner for effective management
  - Risk owners should be senior officials who can select appropriate risk
    responses
  - Ownership is best established by mapping risks to specific business process
    owners
  - Details of risk owners must be documented in the risk register

- **Business process owners**: First line of defense; primary stakeholders for
  IT risk scenarios affecting their processes
  - Generally considered the risk owners for their respective processes
  - Responsible for risk identification, assessment, and reporting to board
  - Best source for determining system effectiveness and criticality
  - Own associated controls and ensure control adequacy

- **RACI model**: Framework for clarifying stakeholder roles in risk management
  - **Responsible**: Performs the work; the person(s) doing the risk management
    activities
  - **Accountable**: Single person who oversees and manages; answerable for the
    outcome; must be assigned to a specific individual
  - **Consulted**: Provides support and assistance; may include external sources
    or regulators
  - **Informed**: Notified of risk management efforts but not directly involved
    in execution

- **Three lines of defense**: Model clarifying essential roles of key
  stakeholders
  - First line: Business process owners who actively manage risk
  - Second line: Risk management and compliance functions that guide, assess,
    and monitor
  - Third line: Internal audit providing independent assurance
  - All three lines must have common goals and coordinated planning

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Risk impacts multiple business units | Assign owner who controls budget and resources for remediation | Single point of accountability prevents gaps |
| Risk owner and control owner are same person | Accept in small organizations but document segregation concern | Maintains visibility into potential conflict |
| New risk identified during assessment | Record risk owner in register immediately | Ensures accountability from identification through response |
| Business owner leaves organization | Reassign risk ownership before departure | Prevents orphaned risks without accountable party |
| Stakeholders disagree on risk response | Escalate to accountable party (e.g., CISO, executive sponsor) | Accountable role has authority to decide |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| New IT risk identified | Notify business process owners first, even with incomplete information | They own the risk and determine response |
| KRI reaches threshold | Report to process owner first | Owner determines risk response and evaluates existing controls |
| Designing IT controls | Gather requirements from stakeholders | Controls must address stakeholder requirements |
| Implementing risk treatment | Assign to individual employee with timeline | Individual accountability ensures follow-through |
| Unclear roles causing duplicate efforts | Implement three lines of defense model | Clarifies roles and responsibilities |
| Risk findings challenged by process owners | Indicates misalignment between risk practices and business strategies | Process owners understand business context best |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Confusing responsible with accountable**: Responsible parties perform the
  work; accountable parties own outcomes and provide resources. A risk manager
  is responsible for conducting assessments but the CISO is accountable for the
  program's success.

- **Multiple risk owners**: Each risk should have exactly one owner. When
  multiple business units are affected, select the leader who can provide budget
  and expertise for remediation.

- **Skipping the Informed role**: Board members and executives may not be
  directly involved but need visibility into risk status. Failing to keep them
  informed undermines governance oversight.

- **Orphan accounts analogy**: Just as database accounts without owners create
  security gaps, risks without designated owners go unaddressed. The 3LoD
  example of orphan accounts illustrates how accountability failures cascade
  across all three lines.

- **Governance vs. management confusion**: Governance (board/stakeholders) sets
  direction and provides oversight. Management (risk practitioners) executes.
  Stakeholder identification must respect this separation.

##### Doshi Review Manual
- **Group vs. individual accountability**: Assigning accountability to a
  department rather than a specific individual circumvents ownership and reduces
  effectiveness

- **Delegation vs. accountability**: Risk owners may delegate management tasks
  but remain ultimately accountable; "responsibility can be delegated,
  accountability cannot"

- **Outsourcing and accountability**: Outsourcing processes does not reduce or
  remove the organization's accountability for managing those risks

- **Three lines planning independently**: Each line conducting its own planning
  independently is a major concern; common goals and coordination are essential

- **Ultimate accountability**: Accountability for risk management ultimately
  lies with senior management and the board, not with risk practitioners or IT
  departments

- **Users as stakeholders**: Users of IT services are generally the application
  owners and risk owners; CTO, CFO, and CRO support but do not own business risk

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk owners per risk | 1 | Single point of accountability |
| RACI accountable parties | 1 per activity | Only one person can be accountable |
| Minimum stakeholder roles | 4 (RACI) | Responsible, Accountable, Consulted, Informed |
| Lines of defense | 3 | Operational, Risk/Compliance, Audit |
| Risk register required fields | Owner + Control owner | Both must be documented |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Accountable parties | Single individual | Never assign accountability to a group |
| Risk register documentation | Required for all risk owners | Must include ownership details |
| First line communication | Business process owners | Primary recipients of risk monitoring results |
| Audit trail purpose | Establish accountability | Captures transaction details to trace responsibility |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk register maintenance**: Stakeholder assignments are recorded in the
  risk register along with threats, vulnerabilities, and response strategies.

- **Three lines of defense**: Provides the structural framework for stakeholder
  accountability across operational, oversight, and assurance functions.

- **Risk appetite**: Stakeholders (board, executives) define acceptable risk
  levels that guide response decisions.

- **IT governance**: Establishes accountability for aligning IT investments with
  business objectives and generating stakeholder value.

- **Key Risk Indicators (KRIs)**: Second line develops KRIs and reports to
  stakeholders; effectiveness depends on actionability and audience relevance.

##### Doshi Review Manual
- **Risk register**: Documents risk ownership and serves as authoritative source
  for stakeholder identification per risk scenario
- **Risk communication**: Open communication provides transparency to external
  stakeholders and enables informed decisions by senior management
- **IT governance**: Primarily the responsibility of board and senior
  management; stakeholder involvement determines implementation effectiveness
- **Control monitoring**: Results should be communicated to risk owners who
  determine appropriate response actions

### 2.5: Create and maintain IT risk register with recognized risk scenarios
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Risk register**: Central repository for documenting all identified risks
  from risk assessments. Can be a sophisticated SaaS tool or a simple
  spreadsheet.
  - At minimum contains: threats, vulnerabilities, likelihood, impact, inherent
    risk, current controls, residual risk, countermeasures, and risk owner
  - Serves as a live document updated when risks change due to internal or
    external factors
  - The immediate result of a risk assessment

- **Risk scenario**: A description of a potential risk event with its causes
  and consequences
  - Top-down approach: Scenarios driven from management perspective, tied
    directly to business objectives
  - Bottom-up approach: Scenarios identified by individuals and teams,
    cascaded up to department, business unit, and organization level
  - Best practice: combine both approaches to address strategic and
    operational risks

- **Risk owner**: Manager or executive accountable for a specific risk
  - Provides budget, resources, and mandate for risk response
  - Each risk requires exactly one owner
  - When risk impacts multiple business units, owner should be the leader who
    can provide budget and expertise
  - Owns the loss incurred if the risk scenario materializes

- **Control owner**: Person who implements or oversees control effectiveness
  - May be different from risk owner to maintain segregation of duties
  - Smaller organizations may assign both roles to one person
  - Must be recorded in the risk register once identified

- **Corrective action plan (CAP)**: Created when a risk cannot be remediated
  immediately
  - Must include: owner, remediation timeline, specific corrective actions
  - Closed when remediation is implemented and risk marked as remediated

##### Doshi Review Manual
- **Risk register**: Centralized inventory that consolidates all identified risks
  in one place for driving risk response and tracking risk status across the
  organization
  - Maintenance process starts during risk identification phase
  - Primary purpose is to drive risk response planning, not just documentation
  - Enables prioritization by providing a complete view of organizational risk

- **Risk scenario**: Visualization of a possible event that can adversely impact
  business objectives
  - Based on identified risks and potential threats to business assets
  - Helps estimate frequency and impact of risk events
  - Most effective technique for assessing business risk

- **Risk scenario components**:
  - Agent: Element that generates the threat (internal or external)
  - Threat type: Natural, system failure, external attack, accidental
  - Event: Nature of incident (data leakage, system down, theft)
  - Asset: What is impacted (IT infrastructure, reputation, data)
  - Time: Temporal impact (immediate vs. long-term effects)

- **Risk register contents**: Each entry should include:
  - Risk scenario with description
  - Category
  - Probability
  - Impact
  - Risk score
  - Risk owner
  - Risk treatment

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| New risk identified in assessment | Enter into risk register with all required fields | Ensures tracking and accountability |
| Risk impacts multiple business units | Assign owner who controls budget and resources | Single point of accountability needed |
| Risk cannot be remediated immediately | Create CAP with owner, timeline, and actions | Documents commitment to future remediation |
| Risk environment changes | Update risk register to reflect new likelihood/impact | Register must remain current |
| Control owner unclear at assessment time | Note in register when identified | Control owner may emerge during implementation |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Risk identified but not yet mitigated | Capture in risk register and track remediation status | All risks must be documented regardless of mitigation state |
| Determining changes in risk profile | Review the risk register | Register provides current status of organizational risk profile |
| Ensuring register accuracy over time | Publish centralized register with periodic polling for risk assessors | Enables identification of new and emerging risks |
| Developing risk scenarios | Combine top-down and bottom-up approaches | Complementary methods: top-down addresses business objectives, bottom-up addresses process-level risks |
| New risk needs to be added | Add when the activity that triggers the risk is initiated | Proactive registration before risk materializes |
| Risk should be removed | Remove when risk is no longer relevant | Keeps register current and actionable |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Not all risks have equal priority**: Risk practitioner must dedicate time
  to prioritize which risks require immediate remediation versus later review.
  Discuss likelihood and impact with stakeholders during assessment.

- **Risk register scope limitation**: A risk register does not provide a
  comprehensive view of all organizational risks. Emerging risks or risks not
  yet identified may be absent. Register may cover only specific projects or
  initiatives.

- **Confusing risk owner with control owner**: Risk owner is accountable for
  the risk and approves response strategy. Control owner is responsible for
  implementing and maintaining specific controls.

- **Treating register as static**: The risk register must be a live document.
  Failing to update when internal or external factors change leads to
  inaccurate risk posture.

- **Omitting countermeasures**: Register should include future countermeasures
  that will reduce risk, not just current controls.

##### Doshi Review Manual
- **Register purpose misconception**: Primary objective is driving risk
  response, not merely documenting or capturing risks; documentation is a
  secondary aspect

- **Scenario development approach**: Neither top-down nor bottom-up alone is
  sufficient; the combination provides comprehensive coverage of strategic and
  operational risks

- **Register maintenance ownership**: Should not be outsourced or delegated
  solely to audit personnel; risk assessors across the organization must
  participate through periodic polling

- **Top-down focus**: In top-down scenario development, business objectives are
  the most important factor to identify, not IT infrastructure or critical
  processes

- **Scenario value**: Risk scenarios help estimate frequency and impact of
  risk; they do not minimize risk response efforts or guarantee all risks are
  identified

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Minimum risk register fields | 8 | Threats, vulnerabilities, likelihood, impact, inherent risk, controls, residual risk, risk owner |
| Risk owners per risk | 1 | Single point of accountability required |
| CAP components | 3 | Owner, timeline, corrective actions |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Register initiation | Risk identification phase | Must begin during identification, not later phases |
| Risk owner requirement | Senior official | Must have authority to make risk management decisions |
| Scenario data source | Potential threats in register | Most important information for developing scenarios |
| Bias prevention method | Representative and historical data | Ensures objectivity in scenario development |
| First step in scenario identification | Identify risk factors | Before developing detailed scenarios |

#### Types of risk in register

| Risk type | Definition | Use |
| --------- | ---------- | --- |
| Inherent risk | Risk level without considering controls | Baseline risk before mitigation |
| Residual risk | Risk remaining after controls implemented | Inherent risk minus control effectiveness |
| Current risk | Point-in-time risk at any given moment | Fluctuates based on threat landscape |

Formula: `Residual Risk = Inherent Risk - Implemented Controls`

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk assessment approaches**: Top-down and bottom-up methods inform which
  scenarios enter the register
- **Risk response strategies**: Mitigate, accept, transfer, avoid - documented
  in register as risk treatment decisions
- **Three lines of defense**: First line owns business risks, informs
  accountability model for risk ownership
- **Qualitative vs quantitative analysis**: Determines how likelihood and
  impact values are expressed in the register

##### Doshi Review Manual
- Risk identification: Feeds the risk register with initial entries and
  potential threats
- Risk prioritization: Register enables ranking of high, medium, and low risks
  for resource allocation
- Risk profile: Register reflects and tracks changes in organizational risk
  posture
- Risk ownership: Each risk in the register must have an assigned accountable
  owner
- Risk response planning: Register's primary purpose is to drive response
  actions

### 2.6: Determine risk appetite and tolerance aligned with business objectives
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Risk appetite**: The amount of risk an organization is willing to accept
  to achieve its objectives
  - Set by the board of directors or senior management
  - Documented in a risk appetite statement that guides the risk management
    team
  - Must be agreed upon with relevant stakeholders
  - Translated into standards and policies to contain risk within defined
    boundaries

- **Risk tolerance**: The acceptable level of variation that management is
  willing to allow to achieve its objectives
  - Represents a slight deviation from acceptable risk levels
  - An organization operating beyond risk appetite but within risk tolerance
    is manageable with compensating controls
  - Different from risk appetite--they are not interchangeable terms

- **Risk capacity**: The amount of risk an organization can afford to take
  without its continued existence being called into question
  - The absolute maximum threshold
  - Risk appetite and tolerance should always be less than risk capacity
  - Exceeding risk capacity threatens organizational survival

- **Risk profile**: The overall risk exposure of the organization to any type
  of risk
  - Factors affecting the profile: regulations, technology changes, business
    objective changes, mergers and acquisitions, competitors
  - IT risk profile: overall identified IT risk to which the enterprise is
    exposed
  - Ever-changing; requires continuous monitoring

- **Risk appetite statement**: A formal document from the board of directors
  stating the level of risk the organization is willing to accept
  - Guides risk mitigation strategies
  - Risk management team develops strategies that align with this statement
  - Should not be ignored or contradicted by risk management approaches

##### Doshi Review Manual
- **Risk capacity**: Maximum risk an organization can afford to take
  - Always greater than tolerance and appetite
  - Represents absolute upper limit of risk exposure
- **Risk appetite**: Amount of risk an organization is willing to take
  - Also referred to as acceptable risk
  - Must never exceed risk capacity
  - Defined and approved by senior management
- **Risk tolerance**: Acceptable deviation from risk appetite
  - Permissible variance above stated appetite level
  - Always lower than risk capacity
  - Can be equal to or greater than appetite

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Board sets moderate risk appetite for higher returns | Develop risk mitigation strategies that align with stated appetite | Risk appetite statement guides acceptable risk levels |
| Risk exceeds appetite but remains within tolerance | Accept with compensating controls in place | Tolerance allows slight deviation if controls mitigate exposure |
| Risk approaches capacity threshold | Immediate escalation and remediation | Exceeding capacity threatens organizational existence |
| Business conditions change | Review and adjust risk appetite boundaries | Boundaries must align with current business objectives |
| Third-party vendor data is not encrypted at rest | Perform cost-benefit analysis; accept if remediation cost exceeds potential loss | Risk acceptance requires business owner sign-off and compensating controls |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Critical application has high risk, organization has moderate appetite | Evaluate controls to mitigate risk | Bring risk within acceptable levels without changing appetite |
| Lack of sufficient resources to treat risk | Define risk priorities to support resource allocation | Prioritization ensures critical risks are addressed first |
| Risk exceeds tolerance | Address immediately through risk response | Risks exceeding tolerance require treatment |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Risk tolerance and risk capacity are not interchangeable**: Tolerance is
  acceptable variation from appetite; capacity is the maximum the organization
  can survive

- **Risk acceptance can exceed risk appetite and tolerance**: This is
  permissible with formal approval, but it must never exceed risk capacity

- **Low risk appetite with high tolerance is valid**: The organization prefers
  fewer risks but can accept moderate risk to achieve objectives

- **Risk appetite does not mean rejecting all risky proposals**: The risk
  management team develops strategies to manage risks within the appetite, not
  avoid all risk

- **Ignoring the risk appetite statement is incorrect**: Risk management must
  align with the board's stated risk appetite

##### Doshi Review Manual
- **Tolerance vs appetite confusion**: Tolerance is the deviation allowed from
  appetite, not a separate threshold
- **Senior management role**: Only senior management approves risk appetite
  and tolerance for information security
- **Residual vs inherent risk**: Compliance is measured against residual risk
  (after controls), not inherent risk
- **Resource prioritization**: High-risk objectives aligned with appetite should
  receive priority resources, not all objectives equally

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk acceptance review frequency | Annual minimum | All exceptions should be revisited at least annually |
| Risk appetite boundary review | With changing business conditions | Boundaries need regular adjustment or confirmation |
| Risk capacity threshold | Never exceed | Exceeding threatens organizational existence |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Approval authority | Senior management | Enterprise-level appetite decisions |
| Review frequency | Regular intervals | Triggered by strategy or environment changes |
| Risk acceptance limit | Within appetite | Never exceed capacity |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Three lines of defense (3LoD)**: Framework for risk governance; risk
  appetite applies across all three lines
- **Risk acceptance process**: Formal documentation of exceptions when risk
  exceeds appetite; requires business owner sign-off
- **Key risk indicators (KRIs)**: Metrics to monitor risk levels against
  appetite thresholds
- **GRC tools**: Systems for logging risk exceptions and tracking against
  appetite
- **Risk response strategies**: Mitigation, acceptance, transfer, and
  avoidance decisions informed by risk appetite
- **Change advisory board (CAB)**: Verifies changes do not negatively affect
  risk profile

##### Doshi Review Manual
- Risk assessment: Uses appetite/tolerance to evaluate risk levels
- Risk response: Determined by comparing residual risk to appetite
- Risk monitoring: Results communicated to risk owners who ensure tolerance
  compliance
- Risk culture: Primary factor in determining appropriate appetite levels

#### Relationship hierarchy

Risk capacity > Risk tolerance >= Risk appetite

Example: An investor has $1000 total savings (capacity), decides to invest up to
$700 (appetite), but is willing to go up to $750 if markets are favorable
(tolerance).

#### Alignment with business objectives

- **Purpose**: Ensures resources are directed toward areas of low risk tolerance
- **Critical processes**: Require thorough monitoring and tighter controls
- **Resource allocation**: Organizations deploy more resources to objectives
  with higher business impact
- **Control prioritization**: Build more controls where appetite and tolerance
  are low

#### Determining compliance with risk appetite

- Compare residual risk against acceptable risk level
- Residual risk must remain within risk appetite
- If residual risk exceeds appetite, additional risk response is required
- Compliance is achieved when residual risk <= acceptable risk

#### Factors affecting risk appetite

- **Risk culture**: Organizational attitudes toward risk taking
  - Risk-prone organizations have higher appetite
  - Risk-averse organizations have lower appetite
- **Predisposition toward risk taking**: Management inclination
- **Industry norms**: Sector-specific risk expectations
- **Business complexity**: More complex operations may require different
  appetite levels

#### Risk culture relationship

- Risk management methodology depends on organizational risk culture
- Risk-prone vs risk-averse organizations require different approaches
- Symptoms of problematic risk culture:
  - Gap between documented appetite and actual employee behavior
  - Blame-focused discussions instead of root cause analysis
- Poor communication leads to acceptance of risk exceeding appetite

#### Periodic review requirements

- Risk appetite and tolerance require regular review
- Triggers for reassessment:
  - New technology adoption
  - Organizational restructuring
  - Changes in business strategy
  - Shifts in risk portfolio

#### Benefits of defining appetite and tolerance

- Provides evidence of risk-based decision-making
- Shows how each enterprise component contributes to overall risk profile
- Supports prioritization and approval of risk response
- Identifies specific areas requiring risk response

### 2.7: Collaborate on risk awareness program and training for stakeholders
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Security awareness training**: A critical component of any cybersecurity
  strategy that educates employees on identifying and mitigating potential
  security risks and promotes a culture of security throughout the organization.
  - According to Verizon's 2022 Data Breach Investigations Report, 82% of
    breaches involved the human element (stolen credentials, phishing, misuse,
    or error).
  - Best control against insider threats is preventive: training combined with
    developing a security-conscious culture.

- **Risk culture**: The organizational attitude toward risk management,
  directly impacting employee behavior and policy adherence.
  - Five maturity levels: Vulnerable, Reactive, Compliant, Proactive, Resilient.
  - Nothing impacts organizational behavior toward risk more than its culture;
    nothing impacts culture more than senior management.
  - Resilient organizations have clear accountabilities established and
    communicated throughout, emphasizing risk management in everything they do.

- **Stakeholder collaboration**: Risk awareness requires participation from all
  business functions.
  - Second Line of Defense (risk and compliance functions) is responsible for
    communicating the risk management framework across the organization and
    obtaining buy-in from key stakeholders.
  - KRIs (Key Risk Indicators) should be actionable and reported to stakeholders
    to drive informed decision-making.
  - Reports and dashboards must be tailored to the audience's role and
    preferred format.

- **Training timing and frequency**:
  - Ideally within 30 days of onboarding.
  - At least annually thereafter.
  - Role-based and privileged user training in addition to general staff
    awareness training.

##### Doshi Review Manual
- **Security awareness training**: Most important element of the information
  security program. Technical controls alone cannot address all security risks;
  behavioral aspects require continuous education.
  - Training should be customized per target audience
  - Developers need secure coding training; data entry operators need
    function-specific security training
  - Compliance with security policy is best ensured through education

- **Risk culture**: Values, beliefs, knowledge, and attitudes about risk shared
  across the organization. Reflects senior management's tendency to embrace,
  accept, or avoid risk.
  - Risk culture drives risk appetite
  - Methodology selection depends on whether organization is risk-prone or
    risk-averse

- **Risk-aware culture benefits**:
  - Timely and accurate escalation of suspicious activity
  - More informed risk decisions by senior management
  - Greater stakeholder awareness
  - Transparency to external parties regarding risk posture

- **Top-down approach**: Security programs must have visible senior management
  commitment. This provides budget, authority, and legitimacy for the program.
  - Influential employees act as security ambassadors within departments

- **RACI model for risk management**:
  - Responsible: Performs actual work
  - Accountable: Single person who oversees and manages (must be specific
    individual)
  - Consulted: Provides support (may be internal, external, or regulators)
  - Informed: Notified but not directly involved in execution

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Employees falling for phishing attacks | Implement security awareness training focused on social engineering recognition | Social engineering exploits human behavior; training helps employees recognize and resist manipulation tactics |
| New data classification policy rollout | Conduct security awareness training for employees | Ensures employees understand the policy and can implement it properly |
| Mobile device risks in workforce | Combine MDM solution with security awareness training | Training alone is insufficient; technical controls plus awareness provide defense in depth |
| Building security culture | Obtain senior management sponsorship and visible support | No amount of training works if risk emphasis is not communicated from the top |
| Ensuring consistent security controls | Develop and enforce policies with training programs | Policies provide framework; training ensures understanding and consistent implementation |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Heavy increase in malware attacks | Conduct regular awareness training on end user roles and responsibilities | Education enables quick detection and prevention |
| Social engineering threats | Periodic simulated attacks with results communicated to staff | Tests maintain alertness; show threats are real |
| Internal security threats | Periodic awareness training for employees and third parties | Helps identify threat symptoms early |
| New employee onboarding | Complete training before data or system access | User must know secure handling before access |
| Promoting password policy compliance | Frequent security awareness programs | Gradual buy-in from users; more effective than penalties |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Training alone eliminates incidents**: Security awareness training reduces
  risk but cannot eliminate all security incidents. The goal is risk reduction,
  not elimination.

- **Technical controls replace training**: The best protection against internal
  threats is not tools or access restrictions but continuous education and
  upskilling of employees.

- **Risk manager determines all training content**: Business owners are the best
  assessors of what is critical to their operations. Risk practitioners
  collaborate with them to determine appropriate training content.

- **One-size-fits-all reporting**: Different stakeholders need different
  reporting formats. Tailor reports to the audience -- executives may need
  dashboards while operational teams need detailed metrics.

- **KRIs without actionability**: KRIs reported to stakeholders that are not
  actionable provide little value to senior management. All indicators should
  drive specific decisions or actions.

##### Doshi Review Manual
- **Increased incident reports indicate success, not failure**: More violation
  reports mean staff recognize and escalate issues. This is the best
  effectiveness metric.

- **Customization beats standardization**: Common messages tailored per group
  are more effective than generic content or industry-standard programs.

- **Training timing matters**: Must occur before access is granted, not after.
  Training is part of orientation for new joiners.

- **Ethics training targets monitors**: Ethics training is primarily for
  employees who monitor user activities, not general staff.

- **Problematic risk culture symptoms**:
  - Gap between documented risk appetite and actual behavior
  - Blame-focused discussions instead of root cause analysis
  - Poor collaboration across the enterprise

#### Key indicators for awareness programs

| Indicator type | Definition | Example |
| -------------- | ---------- | ------- |
| KPI (Key Performance Indicator) | Measures control performance | Reduction in phishing emails after implementing new tool |
| KRI (Key Risk Indicator) | Predicts risks that could breach thresholds | Group of employees not trained in security awareness and continuing to fall for phishing |
| KCI (Key Control Indicator) | Measures effectiveness of controls | Lack of implemented controls to block phishing emails |

#### Training program objectives

| Objective | Description |
| --------- | ----------- |
| Primary goal | Develop a security-conscious culture across the organization |
| Risk reduction | Reduce the likelihood of data breaches and security incidents |
| Social engineering defense | Help employees recognize and resist manipulation tactics |
| Policy compliance | Ensure employees understand and can implement security policies |
| Incident reporting | Enable employees to be proactive in reporting suspicious activities |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Organizational culture**: Risk culture maturity directly determines training
  effectiveness and employee adoption of security practices.
- **Three Lines of Defense**: Second LoD develops KRIs and keeps stakeholders
  informed of threats; first LoD implements training within their business units.
- **Risk reporting**: Dashboards, heat maps, and scorecards communicate training
  effectiveness and risk posture to stakeholders.
- **CISO responsibilities**: Ensuring all employees are trained on security
  awareness and best practices is a core CISO function.
- **Business continuity management**: Regular employee training and awareness
  programs are essential components ensuring employees understand their roles
  during disruptions.

##### Doshi Review Manual
- **Key Risk Indicators (KRIs)**: Installation of unlicensed software indicates
  need for additional training. KRIs help validate training effectiveness.
- **Risk register**: Training gaps may appear as control weaknesses in risk
  documentation.
- **Organizational culture (1.5)**: Risk culture assessment informs training
  approach and methodology selection.
- **Senior management support**: Required for budget, authority, and program
  legitimacy. Strategic view needed for sign-off on risk management.
- **Social engineering**: Primary reason to conduct enterprise-wide awareness
  programs; training reduces likelihood of successful attacks.
- **Data classification**: Classification policy content should be part of
  awareness program; policy ineffective without user training.

---

## Domain 3: Risk Response and Reporting

**Weight: 32%**

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Training frequency | Continuous/periodic | Threats and vulnerabilities change over time |
| Training owner | Information security department | Part of overall security program |
| Key success metric | Increase in security violation reports | Indicates awareness and proactive reporting |
| Ethics training scope | Employees monitoring user activity | Targeted, not organization-wide |

### 3.1: Consult with risk owners to align risk responses with organizational objectives
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Risk owner**: Manager or executive responsible for a specific risk who can
  provide budget, resources, and authority to mandate risk responses. The
  business owner is typically the risk owner under the Three Lines of Defense
  (3LoD) model.
  - Drives accountability for risk remediation
  - Must be recorded in the risk register
  - Should be able to speak with authority on risk response
  - Owns the loss incurred if the risk scenario materializes

- **Risk response alignment**: The process of ensuring risk treatment
  strategies support organizational goals and business objectives rather than
  operating in isolation.
  - Risk appetite must align with business objectives
  - High-risk areas providing more value should receive more resources
  - Response strategies should translate into standards and policies

- **Cost-benefit analysis**: Required evaluation comparing the cost of
  implementing controls against the cost of the associated risks.
  - Cost of mitigating a risk should be less than the effective risk
  - Example: A $1,000 lock on a $500 bicycle does not make sense

- **Return-on-investment thesis**: Business justification presented to senior
  management to support a proposed risk response strategy.

##### Doshi Review Manual
- **Risk ownership**: The assignment of accountability for managing a specific
  risk to a senior official with the authority to select and implement
  appropriate risk responses.
  - Risk should be assigned to an individual, not a department or group
  - Business process owners are the natural risk owners for their respective
    processes
  - Risk owners should also own associated controls and ensure their
    effectiveness
  - Details must be documented in the risk register

- **Risk practitioner's consultative role**: The risk practitioner advises risk
  owners on technologies, policies, procedures, and control effectiveness.
  - Ultimate decision authority for risk treatment resides with the risk owner
  - Risk practitioner provides analysis and guidance; risk owner makes decisions
  - When monitoring identifies noncompliance, the practitioner should discuss
    with the risk owner and recommend control review

- **Alignment with organizational objectives**: Risk responses must support
  business goals rather than being selected in isolation.
  - First consideration when selecting a risk response is whether it supports
    organizational goals and objectives
  - Risks that impact objectives should be prioritized and responded to first
  - Risk appetite should be aligned with business objectives to direct resources
    toward areas of low risk tolerance

- **Communication requirements**: Results of risk monitoring must be shared with
  risk owners.
  - Risk owners are accountable for maintaining risk within acceptable levels
  - Risk reporting provides a summary of assessment results so owners can
    initiate corrective action
  - Presentation should be tailored to the audience (e.g., dashboards for senior
    management)

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Risk impacts multiple business units | Assign single risk owner who can provide budget and expertise | Ensures clear accountability and decision authority |
| Cost of remediation exceeds asset value | Consider risk acceptance with documented compensating controls | Control cost should not outweigh protected asset value |
| Third-party vendor data not encrypted | Present cost-benefit analysis to business owner for acceptance decision | Allows informed risk-based decision aligned with objectives |
| Risk response requires significant resources | Prepare business case with ROI thesis for senior management | Enables informed decision on resource allocation |
| Risk exceeds risk appetite but within tolerance | Document exception with countermeasures and executive sign-off | Maintains governance while enabling business flexibility |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Multiple risk response alternatives exist | Conduct cost-benefit analysis and present options to risk owner | Risk owner must make informed decision based on organizational value |
| Control monitoring reveals noncompliance | Discuss with risk owner and recommend control review | Risk owner is accountable and must decide on corrective action |
| New vulnerability discovered in authentication system | Identify affected systems and notify business owners immediately | Business owners (risk owners) are responsible for responding to new risks |
| Determining if IT supports business objectives | Interview business process owners | They understand specific business requirements and whether IT serves them |
| Risk exceeds tolerance level | Prepare risk treatment plan with detailed actions, timelines, and responsible parties | Risk owner needs actionable plan to bring risk within acceptable levels |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Trap: Treating risk response as purely technical**: Risk response requires
  stakeholder buy-in and alignment with business objectives, not just
  implementing controls.

- **Trap: Eliminating risk entirely**: The goal of risk response is not to
  eliminate risk but to optimize it to acceptable levels where risk can become
  opportunity.

- **Trap: Risk tolerance equals risk capacity**: Risk tolerance is acceptable
  deviation from appetite; risk capacity is the maximum risk before
  organizational existence is threatened. Never exceed capacity.

- **Trap: Single response strategy**: Different risks demand different
  responses (mitigate, accept, transfer, avoid). A risk manager may combine
  strategies for optimization.

- **Trap: Same owner for risk and control**: While acceptable in smaller
  organizations, this should be avoided to maintain segregation of duties.

##### Doshi Review Manual
- **Assigning risk to departments instead of individuals**: Allocating
  accountability to a department circumvents ownership. Always assign to a
  specific person.

- **Risk practitioner making risk decisions**: The practitioner advises and
  recommends; the risk owner decides. Ultimate decision authority stays with
  the risk owner.

- **Delegating risk means transferring accountability**: When risk owners
  delegate management tasks to others, they remain ultimately responsible for
  monitoring and controlling the risk.

- **Responding to all identified risks**: Not required. Only risks that impact
  organizational objectives warrant response. Resource availability is not the
  prime consideration; alignment with objectives is.

- **Using industry good practices as the selection criterion**: Industry
  practices are secondary. The primary criterion is whether the response
  supports organizational goals and objectives.

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk acceptance review | Annual minimum | Revisit original asset value and current risk level |
| Risk register requirement | Single owner per risk | Each risk must have one accountable owner |
| Risk exception documentation | Required fields | Risk owner, countermeasures, duration, executive sign-off |
| Risk capacity boundary | Never exceed | Crossing risk capacity threatens organizational existence |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Ultimate accountability | Board of Directors | Senior management designs strategy; board oversees |
| Risk ownership documentation | Risk register | Must include likelihood, impact, priority, mitigation status, and owner |
| Monitoring results communication | Risk owner (mandatory) | Other functions receive as secondary recipients |
| Risk action plan contents | Start date, end date, responsible person, detailed action plan | Treat as a project with milestones |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk response strategies**: Four strategies (mitigate, accept, transfer,
  avoid) that risk owners must evaluate and approve for their risks.

- **Three Lines of Defense**: Framework defining risk ownership where first
  line (business owners) are ultimate risk owners, second line provides
  oversight, and third line provides independent assurance.

- **Risk appetite and tolerance**: Boundaries set by senior management that
  constrain acceptable risk responses and guide risk owner decisions.

- **Key Risk Indicators (KRIs)**: Metrics developed by second line of defense
  to communicate credible threats to stakeholders and inform risk response
  decisions.

- **Control ownership**: Separate from risk ownership; the person implementing
  or overseeing control effectiveness. Should be documented in risk register
  when identified.

##### Doshi Review Manual
- **Risk register**: The documented inventory containing risk ownership details,
  treatment status, and the foundation for consultation between practitioners
  and owners.

- **Risk appetite alignment**: When appetite is aligned with business objectives,
  resources are directed toward high-risk areas that matter to the organization.

- **Cost-benefit analysis**: The primary method for evaluating risk response
  alternatives during consultation with risk owners.

- **Accountability vs. responsibility**: Board of Directors holds ultimate
  accountability; risk owners are responsible for their assigned risks.

### 3.2: Assist risk owners in developing risk action plans
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Risk action plan**: A documented response strategy that outlines how an
  organization will address identified risks through specific controls,
  timelines, and accountable parties. Also referred to as a corrective action
  plan (CAP) or risk treatment plan.

- **Risk owner**: A manager or executive committee member accountable for a
  specific risk, with authority to provide budget, mandate responses, and
  accept residual risk.
  - Each risk should have a single risk owner
  - The risk owner provides resources and expertise to remediate risks
  - Owns the loss incurred if the risk scenario materializes
  - Must be recorded in the risk register

- **Control owner**: The individual responsible for implementing or overseeing
  the effectiveness of a specific control.
  - May differ from the risk owner to maintain segregation of duties
  - In smaller organizations, the same person may serve both roles
  - Should be documented in the risk register once identified

- **Risk response strategies**: The four methods for addressing risk:
  - Mitigate: Implement countermeasures and controls; cost must be less than
    effective risk
  - Accept: Document the decision when cost of treatment exceeds benefit;
    requires management sign-off
  - Transfer/Share: Assign risk through insurance or outsourcing; suited for
    low likelihood/high impact risks
  - Avoid: Terminate the risk source entirely; irreversible, requires senior
    management approval

- **Corrective action plan (CAP)**: Created when risks cannot be remediated
  immediately; must include an owner, timeline for remediation, and specific
  corrective actions.

##### Doshi Review Manual
- **Risk practitioner role**: Plays a consultative role in assisting risk owners
  with deciding and implementing risk treatment. Provides advice on
  technologies, policies, procedures, and control effectiveness. Ultimate
  decision authority resides with the risk owner.

- **Risk owner**: Senior official with authority and experience to select
  appropriate risk response. Owns associated controls and ensures their
  effectiveness and adequacy. Should be an individual employee, not a group or
  department.

- **Risk action plan**: Created once a risk response is finalized and documented
  in the risk register. Must include:
  - Start date
  - End date
  - Details about strategy
  - Responsible person or team

- **Risk treatment plan**: Structured approach to treating identified risks.
  Prepared for all risks exceeding tolerance levels. Monitored regularly to
  track progress. Should be treated as a project with measurable timelines,
  budget, and milestones.

- **Deciding factors for risk treatment selection**:
  - Risk appetite of the organization
  - Applicable laws and regulations
  - Management priorities
  - Current level of risk
  - Industry and market forces

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Risk impacts multiple business units | Assign owner who can provide budget and expertise | Single accountability prevents gaps |
| Cost of mitigation exceeds asset value | Document risk acceptance with management sign-off | Cost-benefit analysis drives response |
| Critical vendor has control deficiencies | Create CAP with agreed timelines and senior management sign-off | Formalizes remediation commitment |
| Risk cannot be addressed within tolerance | Propose risk avoidance to senior management | Last resort when other strategies fail |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Current risk exceeds risk appetite | Evaluate different risk response alternatives using cost-benefit analysis | Further response required to bring risk to acceptable level |
| Insufficient resources for treatment | Define risk priorities to support resource allocation | Prioritization enables effective use of limited resources |
| Mitigation action plan approved | Assign to responsible individual with deadlines | Individual accountability with timelines ensures implementation |
| Need to keep risk at acceptable level | Periodic review of controls per risk action plan | Regular review ensures ongoing control effectiveness |
| Selecting between response options | Conduct cost-benefit analysis | Implementation cost must be justified by benefit realized |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **"Treat" is not a response strategy**: Risk response and risk treat are used
  interchangeably in conversation, but only mitigate/accept/transfer/avoid are
  formal response strategies.

- **Response selection is not one-size-fits-all**: Organizations may combine
  multiple strategies to optimize a single risk.

- **Risk acceptance can exceed appetite but not capacity**: Accepting risk
  above tolerance requires executive approval; exceeding capacity threatens
  organizational existence.

- **Reputational damage does not transfer**: Insurance or outsourcing provides
  monetary indemnity, but reputational harm remains with the organization.

- **Annual review is mandatory**: Accepted risks must be reassessed at least
  annually to determine if the response remains appropriate.

##### Doshi Review Manual
- **Group assignment trap**: Assigning risk ownership to a department rather
  than an individual circumvents accountability. Always assign to a specific
  person.

- **Practitioner vs owner authority**: Risk practitioners advise; risk owners
  decide. The ultimate decision to adopt risk treatment resides with the risk
  owner, not the practitioner.

- **Incidents not in scope**: Already-occurred incidents (realized risks) are
  not in scope of risk treatment plans. Treatment plans address future risk
  mitigation.

- **Accepted risks excluded**: If risk is already accepted by risk owners, a
  risk treatment plan is not required.

- **Cost-benefit misconception**: If benefit from a control is less than
  implementation cost, the control is not justified. Selection of controls is
  primarily based on cost-benefit analysis.

- **Critical path monitoring**: Delays in critical path elements increase
  overall project risk. Action plans should be managed as projects with proper
  milestone tracking.

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Minimum CAP review frequency | Annual | Revisit accepted risks yearly |
| Risk register required fields | Threat, vulnerability, likelihood, impact, inherent risk, controls, residual risk, countermeasures, owner | Minimum data elements |
| Response selection factors | 11 | Category, cost, availability, skillsets, complexity, resources, alignment, compatibility, contractual, legal/regulatory requirements |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk treatment plan scope | Risks exceeding tolerance | Not required for accepted, avoided, or transferred risks |
| Ownership assignment | Individual employee | Not groups or departments |
| Plan review frequency | Regular/periodic | Ensures controls remain effective |
| Cost-benefit threshold | Benefit > Implementation cost | Control not justified if cost exceeds benefit |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Cost-benefit analysis**: Required component of the business case for any
  risk response; includes return-on-investment thesis.

- **Risk register**: Central repository where risk owners, control owners,
  response strategies, and CAPs are documented.

- **Three lines of defense (3LoD)**: First line (business owners) are ultimate
  risk owners; risk practitioners assist but do not own the risk.

- **Risk optimization**: The goal of response is not elimination but
  optimization to acceptable levels aligned with organizational strategy.

- **Risk reporting**: Business case presentations to senior management must
  clearly show risks and control implementation strategy to obtain approval.

##### Doshi Review Manual
- **Risk ownership (3.1)**: Establishes who is accountable for managing each
  risk and selecting appropriate responses
- **Cost-benefit analysis (3.3)**: Primary technique for evaluating and
  prioritizing risk response alternatives
- **Risk register**: Central documentation for risk action plans, ownership, and
  treatment status
- **Three lines model**: First line (business process owners) manages risks as
  risk owners; second line provides guidance
- **Control monitoring**: Results communicated to risk owners who are
  accountable for maintaining acceptable risk levels

### 3.3: Advise on design and deployment of mitigating controls
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Control**: A measure that reduces risk and improves organizational security
  posture. Can be technical (antivirus), physical (turnstile), or administrative
  (policy document).

- **Optimal control level**: The correct answer on control implementation is
  always "optimal" -- controls should match the risk posed and be evaluated for
  effectiveness, efficiency, and cost before implementation.

- **Proactive vs reactive controls**: Proactive controls (safeguards) prevent
  incidents from occurring. Reactive controls assist in detection and correction
  after an incident.

- **Compensating controls**: Used when primary controls cannot be implemented
  without impacting business. Example: privileged accounts with enhanced logging
  when segregation of duties is impractical.

- **Cost-benefit analysis**: Control implementation cost must not exceed asset
  value. A $1,000 lock on a $500 bicycle is inappropriate.

##### Doshi Review Manual
- **Proactive vs reactive controls**: Proactive controls (safeguards) prevent
  events from occurring; reactive controls (countermeasures) detect and recover
  after an incident
  - Example safeguard: security guard preventing unauthorized entry
  - Example countermeasure: fire extinguisher addressing fire risk

- **Stakeholder requirements**: The most important factor for designing IS
  controls
  - Controls must align with business process requirements
  - Process owners provide control requirements based on business needs
  - Internal controls should be incorporated at the design phase of SDLC

- **Unjustifiable control**: Control whose implementation cost exceeds the
  potential loss
  - Results in lower return on IT investment
  - Indicates misalignment between control cost and risk reduction

- **Risk practitioner role**: Advise on control selection and implementation
  - Evaluate adequacy of current controls
  - Recommend new controls when existing ones are insufficient
  - Assist in planning, reporting, and scheduling control tests

- **Cost-benefit analysis**: Primary basis for selecting and prioritizing risk
  responses
  - Conducted during risk response planning stage
  - Must include Total Cost of Ownership (TCO) across control lifecycle
  - If benefit is less than implementation cost, control is not justified

#### Control categories

##### CRISC All-in-One Exam Guide
| Category     | Purpose                          | Example                                    |
| ------------ | -------------------------------- | ------------------------------------------ |
| Preventive   | Stop security violations         | Antivirus, firewall blocking traffic       |
| Detective    | Identify policy violations       | IDS, audit logs, SIEM review               |
| Corrective   | Fix issues after detection       | Backup restore, incident remediation       |
| Deterrent    | Discourage malicious actors      | Security cameras, warning signs            |
| Compensating | Cover weakness in other controls | Password rotation for shared accounts      |

##### Doshi Review Manual
| Category     | Objective                           | Examples                                        |
| ------------ | ----------------------------------- | ----------------------------------------------- |
| Preventive   | Stop event from occurring           | Access controls, firewalls, segregation of      |
|              |                                     | duties, SOPs, edit checks                       |
| Detective    | Identify events after occurrence    | Log monitoring, audits, hash totals, variance   |
|              |                                     | analysis                                        |
| Corrective   | Minimize impact and restore normal  | BCP, DRP, incident response, backup procedures  |
| Deterrent    | Discourage through warning          | CCTV cameras, warning signs                     |
| Directive    | Mandate behavior                    | Acceptable use policies                         |
| Compensating | Offset weakness in another area     | Log review compensating for lack of segregation |

| Classification   | Description                              | Examples                             |
| ---------------- | ---------------------------------------- | ------------------------------------ |
| Administrative   | Oversight of processes, permitted        | Policies, procedures, audit reports  |
|                  | actions                                  |                                      |
| Technical        | Technology-based with minimal human      | Logical access, firewalls, antivirus |
|                  | intervention                             |                                      |
| Physical         | Control physical movement and access     | Guards, locks, fences, CCTV          |

#### Control implementation techniques

| Technique | When to use                                     | Risk level |
| --------- | ----------------------------------------------- | ---------- |
| Parallel  | Business-critical systems requiring no downtime | Lowest     |
| Phased    | Complex systems with independent modules        | Moderate   |
| Abrupt    | Minor changes with easy rollback                | Highest    |

- **Parallel changeover**: Old and new systems run simultaneously. Highest cost
  but safest -- allows training, validates reliability, enables easy rollback.

- **Phased changeover**: Gradual replacement of old system modules.
  Cost-effective, reduces full outage risk, but requires maintaining separate
  environments.

- **Abrupt changeover**: Instant switch from old to new. Fast and cheap but
  risky -- only appropriate when rollback is easy and impact is low.

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario                             | Correct approach                               | Why                                                       |
| ------------------------------------ | ---------------------------------------------- | --------------------------------------------------------- |
| Single-person application management | Propose compensating controls (enhanced logs)  | Cannot implement segregation of duties                    |
| Business-critical upgrade            | Recommend parallel changeover                  | Zero downtime requirement outweighs cost                  |
| Modular system with no dependencies  | Recommend phased changeover                    | Cost-effective, independent modules reduce rollout risk   |
| Minor non-critical change            | Abrupt changeover acceptable                   | Easy rollback, minimal business impact                    |
| Control cost exceeds asset value     | Recommend risk acceptance instead of mitigation| Cost of control should not exceed cost of asset           |

##### Doshi Review Manual
| Scenario                                     | Correct approach                        | Why                                           |
| -------------------------------------------- | --------------------------------------- | --------------------------------------------- |
| Control cost exceeds risk event cost         | Accept the risk                         | Unjustifiable control lowers ROI              |
| Identified control deficiency                | Review defined control objectives first | Must understand what control should achieve   |
| Implementing new control                     | Conduct cost-benefit analysis           | Ensures control expense does not exceed value |
| Segregation of duties not feasible           | Implement compensating controls         | Log review or audits offset the weakness      |
| Small organization cannot segregate duties   | Transaction log monitoring              | Compensatory control provides oversight       |
| Temporary staff access                       | Auto-expiring access with need-to-know  | Limits exposure and removes stale access      |

#### Post-implementation review

Risk practitioners must conduct post-implementation reviews regardless of
success or failure. Key questions:

- Did the project meet business objectives and user requirements?
- Was it completed on time and within budget?
- Were logical and business controls properly defined and implemented?
- What went well and what could be improved?
- Are dedicated resources available for continuous support?

The review document should be treated as a living document and updated as new
learnings emerge.

#### Control testing best practices

- Never use production data for testing -- create synthetic data or mask
  sensitive fields
- Maintain complete separation between test and production environments
- Use version control with approval workflows before code merge
- Implement code freeze before production deployment
- Restrict access to control who can push to production
- Perform unit, system, integration, performance, stress, and functional tests
- Conduct code reviews to find hardcoded secrets and logical errors

Testing types:
- **Progressive testing**: Starts from requirements, looks for flaws
- **Regressive testing**: Works backward from expected results and known issues

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Control owner vs risk owner**: Both should be identified in the risk
  register. Same person is acceptable but avoided to maintain segregation of
  duties.

- **Residual risk**: Risk mitigation does not eliminate risk -- it reduces risk
  to an acceptable level. Residual risk always remains.

- **Periodic review required**: Controls become outdated as threat landscape
  changes. Continuous monitoring and benchmarking is required.

- **Never skip CAB sign-off**: Final approval from Change Advisory Board
  required before rolling out changes.

##### Doshi Review Manual
- **Stakeholder requirements over technical specifications**: Technical
  requirements and security budget are secondary to addressing stakeholder needs

- **Residual risk is the measure**: Effective controls reduce residual risk to
  acceptable levels; if residual risk is unchanged, the control is ineffective

- **Control objectives before control cost**: To identify control deficiencies,
  review defined control objectives first, not cost or current state

- **Optimum control level**: Balance between control effectiveness and control
  cost; control is optimum when cost is less than perceived risk

- **Continuous monitoring placement**: Deploy where risk is highest (high
  impact and frequency incidents), not everywhere

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk response strategies**: Mitigate, accept, transfer, avoid --
  understanding when each applies informs control selection
- **Configuration management**: A preventative control ensuring baseline
  configurations and approved software
- **Change management**: Process controls ensuring tested changes with proper
  approval workflows
- **SIEM**: Detective control for log aggregation, analysis, and alerting

##### Doshi Review Manual
- **Risk register**: Documents all implemented controls and risk status; update
  when controls change
- **Post-implementation review**: Validates control met objectives and analyzes
  return on investment
- **Key Control Indicators (KCIs)**: Metrics that measure control effectiveness
- **Control monitoring**: Balance between control effectiveness and cost at
  optimum level

#### Control implementation methods

- **Parallel changeover**: Run old and new systems simultaneously
  - Lowest risk; validates new system before discontinuing old
  - Highest redundancy but most expensive

- **Phased changeover**: Implement new modules incrementally
  - Moderate risk; addresses complete failure risk
  - Requires maintaining two environments

- **Abrupt changeover (direct cutover)**: Immediate switch to new system
  - Highest risk; no rollback if new system fails
  - Only feasible when rollback is easy and impact is minimal

- **Fallback plan**: Required before any changeover
  - Enables rollback to prior system if migration fails
  - Organization must verify rollback capability before starting

#### Failure modes

- **Fail open**: System remains accessible when control fails
  - Risk: confidentiality and integrity may be compromised
  - Use when availability is critical

- **Fail closed**: System locks down when control fails
  - Risk: availability may be compromised
  - Exception: never prevent emergency exit (human safety first)

#### Limits and defaults

| Item                               | Value                             | Notes                                   |
| ---------------------------------- | --------------------------------- | --------------------------------------- |
| Control design priority            | Stakeholder requirements          | Not technical specs or budget           |
| Effectiveness measurement          | Residual risk reduction           | Primary indicator of control success    |
| Cost calculation scope             | Total Cost of Ownership           | Includes implementation and maintenance |
| Control incorporation timing       | SDLC design phase                 | Earliest practical point                |
| Highest risk changeover            | Direct cutover                    | No rollback capability                  |
| Highest redundancy changeover      | Parallel                          | Both systems run simultaneously         |

### 3.4: Establish accountability by assigning control ownership
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Control owner**: The individual responsible for implementing a control to
  mitigate risk or overseeing the control's effectiveness
  - Must be identified for each control in the organization
  - Should be recorded in the risk register as soon as identified
  - Unlike risk owners, control owners may not be determinable at the time of
    risk assessment
  - Responsible for ensuring controls remain current as risks evolve

- **Risk owner**: A manager or executive committee member accountable for risk
  treatment decisions
  - Provides budget and mandates risk response based on practitioner guidance
  - Owns the loss incurred if a risk scenario materializes
  - Must be a single individual who can speak with authority on risk response

- **RACI model**: Framework for establishing roles and responsibilities
  - **Responsible**: Individual or team performing the work
  - **Accountable**: Individual providing resources and answerable for success
  - **Consulted**: Subject matter experts with domain knowledge
  - **Informed**: Stakeholders affected by outcomes

- **Three Lines of Defense (3LoD)**: Model ensuring segregation and
  accountability
  - First line: Operational management (ultimate risk owners)
  - Second line: Risk monitoring and oversight functions
  - Third line: Internal and external audit

##### Doshi Review Manual
- **Control ownership assignment**: The formal allocation of responsibility for
  specific controls to individuals who ensure their effectiveness and adequacy.
  - Assign to specific individuals, not departments or groups
  - Owner must have authority and experience to select appropriate controls
  - Control ownership is essential for aligning controls with organizational
    goals
  - Without defined ownership, other risk artifacts (treatment plans, registers,
    profiles) will not be accurate or effective

- **RACI model for accountability**: Framework defining four roles in risk and
  control management.
  - Responsible: Performs the actual work to meet stated objectives
  - Accountable: Single person who oversees and manages those responsible;
    liable and answerable for the project
  - Consulted: Provides support and assistance to risk management efforts
  - Informed: Receives status updates and outcomes
  - Effective accountability must be assigned to a specific person, not a group

- **Process owner as control owner**: Business process owners are the natural
  candidates for control ownership within their domains.
  - First line of defense actively manages risk and monitors controls
  - Process owners provide control requirements based on business needs
  - They are responsible for ensuring controls address stakeholder requirements
  - Mapping controls to specific process owners is the best basis for
    establishing ownership

- **Risk owner vs. control owner relationship**: Risk owners select appropriate
  risk responses; control owners ensure controls function effectively.
  - Risk owners are accountable for risks within acceptable levels
  - Control owners monitor and report on control effectiveness
  - Both should be documented in the risk register
  - Results of control monitoring should be communicated to the risk owner

- **Three lines of defense model**: Clarifies essential roles and
  responsibilities for control ownership.
  - First line: Process owners who actively manage risk and monitor controls
  - Second line: Risk management and compliance departments that guide and
    assess
  - Third line: Internal audit that provides independent testing and attestation
  - All three lines must have common goals and planning for effectiveness

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Risk impacts multiple business units | Assign ownership to leader who can provide budget, resources, and expertise | Single point of accountability prevents confusion |
| Small organization with limited staff | Same person may serve as both risk owner and control owner | Acceptable when resources constrain separation |
| Control owner cannot be determined during assessment | Record in risk register as soon as identified post-assessment | Ensures eventual accountability even if delayed |
| Controls becoming outdated | Control owner monitors and updates as threat landscape changes | Prevents degradation of control effectiveness |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Roles and responsibilities undocumented | Recommend defining accountability for each critical function | Undefined responsibilities are a major risk in attaining objectives |
| Determining who should provide control requirements | Consult process owners | They understand business needs and can specify requirements |
| Identifying who is accountable for IS controls | Resource owner (data owner/system owner) | Owners are ultimately responsible for controls over their resources |
| Aligning controls with organizational goals | Assure ownership of key control activities first | Other control activities cannot be accomplished without defined ownership |
| Control monitoring reveals issues | Report results to risk owner | Risk owner is accountable for maintaining risk within acceptable levels |
| System owner function during accreditation | Select and specify security requirements | System owners determine security requirements for their systems |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Risk owner and control owner should be separate**: While acceptable for the
  same person to hold both roles, this should be avoided to maintain
  segregation of duties. Common in smaller organizations but creates potential
  conflict of interest.

- **Accountability versus responsibility**: The accountable party provides
  resources and answers for success; the responsible party performs the work.
  Confusing these leads to unclear ownership.

- **Control efficacy testing**: The control owner bears responsibility for
  periodic control testing and evaluation, not the risk owner. This includes
  both progressive testing (from requirements forward) and regressive testing
  (from results backward).

- **Risk ownership exists even without explicit assignment**: In the 3LoD
  model, business owners are inherently risk owners because they manage
  day-to-day operations. Failure to formally assign ownership does not
  eliminate accountability.

- **Risk transfer does not transfer accountability**: Outsourcing services or
  purchasing insurance transfers financial risk but reputational damage remains
  with the organization.

##### Doshi Review Manual
- **Assigning ownership to a department or group**: Allocating accountability to
  a department circumvents ownership. Always assign to a specific individual for
  effective accountability.

- **Confusing accountability with responsibility**: Board of Directors and senior
  management are ultimately accountable for risk policies and standards. Process
  owners are responsible for implementing and monitoring controls.

- **Outsourcing removes accountability**: Outsourcing processes mitigates various
  risks through service providers, but does not reduce or remove the
  organization's accountability for controls.

- **Generic accounts prevent accountability**: Shared or generic accounts impact
  nonrepudiation because no individual user can be held accountable for
  transactions performed under the shared account.

- **Clear accountability is primarily about compliance**: The most important
  reason for creating a clear chain of accountability is assigning risk and
  control ownership appropriately, not compliance or ensuring risk assessment
  is finished on schedule.

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk owners per risk | One | Single point of accountability required |
| Control review frequency | Annual minimum | Risk acceptance must be revisited at least yearly |
| Risk register fields for ownership | Risk owner, control owner | Both should be captured when known |
| 3LoD first line | Business/operational managers | Ultimate risk owners by default |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Ultimate accountability for enterprise risk | Board of Directors | Senior management implements; board oversees |
| Accountability for IS resources | Resource owner (data/system owner) | Must ensure relevant controls are in place |
| Control requirement specification | Process owners | Based on business needs and objectives |
| Primary documentation for ownership | Risk register | Contains details of risk, controls, and owners |
| Purpose of audit trail | Establish accountability | Captures who executed transactions and when |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk register**: Central repository where risk and control owners must be
  documented; serves as system of record for accountability
- **Segregation of duties**: Principle requiring separation of risk ownership
  from control ownership where feasible
- **Control testing**: Periodic evaluation responsibility falling to the
  control owner to ensure continued effectiveness
- **Risk response strategies**: Mitigate, accept, transfer, avoid -- decisions
  requiring risk owner approval
- **Post-implementation review**: Control owner responsibility to verify
  implemented controls function as intended

##### Doshi Review Manual
- **Risk register**: Documents both risk ownership and control ownership details,
  including likelihood, impact, priority, mitigation status, and responsible
  parties.

- **Three lines of defense**: Provides the structural framework for assigning
  control responsibilities across operational, risk management, and assurance
  functions.

- **Nonrepudiation**: Requires establishing accountability through mechanisms
  like digital signatures and certificate-based authentication; impossible with
  shared accounts.

- **Segregation of duties**: Related control mechanism that assigns different
  functions to separate individuals, supporting accountability by preventing any
  single person from completing high-risk transactions alone.

- **Control self-assessment**: Process where control owners evaluate their own
  control environment, reinforcing accountability for control effectiveness.

### 3.5: Support control owners in establishing procedures and documentation
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Control owner**: The person who implements a control to mitigate risk or
  oversees control effectiveness
  - Must be identified and recorded in the risk register
  - Responsible for determining efficacy of controls periodically
  - May be the same person as the risk owner in small organizations, though
    segregation of duties is preferred
  - Unlike risk owners, control owners are often identified after the initial
    risk assessment

- **Policy documentation hierarchy**: The structured relationship between
  governance documents
  - **Policies**: High-level statements of management intent; business
    decisions, not technical ones
  - **Standards**: Mandatory requirements for processes, actions, and
    configurations that satisfy control objectives
  - **Procedures**: Documented steps to perform tasks in conformance with
    standards; also called Standard Operating Procedures (SOPs)
  - **Guidelines**: Recommended practices allowing discretion in implementation

- **Procedures**: Critical documentation owned by process owners/asset
  custodians
  - Address how the organization operationalizes a policy, standard, or control
  - Provide defendable evidence of due care practices
  - Must include stakeholder oversight for compliance requirements
  - Should be maintained as living documents

- **RACI model**: Framework for establishing clear accountability
  - **Responsible**: Individual/team performing the work
  - **Accountable**: Individual ensuring success by providing resources
  - **Consulted**: Subject matter experts with domain knowledge
  - **Informed**: Stakeholders affected by success or failure

##### Doshi Review Manual
- **Control owner**: The first line of defense responsible for implementing and
  maintaining controls within their business unit. Typically the business
  process owner who manages daily operational activities and monitors control
  effectiveness on an ongoing basis.

- **Policies**: High-level statements of management direction. Approved by
  senior management or board of directors. Changed infrequently.

- **Standards**: Mandatory requirements that support policy compliance.
  Dynamic documents updated when control objectives are not achieved or based
  on risk assessment results. Provide detailed direction to comply with policy.

- **Procedures**: Detailed steps and actions that support policies and
  standards. Changed more frequently than policies or standards. Operational
  in nature.

- **Guidelines**: Support procedure implementation with examples, suggestions,
  and execution details.

- **Three lines of defense model**:
  - First line: Process owners who implement controls and monitor effectiveness
  - Second line: Risk and compliance functions that develop framework,
    policies, standards, and procedures
  - Third line: Audit function providing independent assurance

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| New control without documented procedures | Control owner develops SOPs with stakeholder oversight | Procedures provide evidence of due care and ensure consistent execution |
| Encryption policy implementation | Create standard (algorithm requirements), then procedure (step-by-step guidance) | Hierarchy ensures technical specifics support policy intent |
| Control owner and risk owner are the same person | Document justification; implement compensating oversight | Common in small organizations but weakens segregation of duties |
| Control gaps identified after implementation | Document in risk register; advise risk owner | Control owner responsible for ongoing efficacy evaluation |
| Policy exception required for business need | Raise exception, obtain explicit approval from business process owner, log centrally | Enables business while maintaining documented accountability |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Control owner needs exception to policy | Documented formal escalation process | Exceptions allowed only when risk is justified by benefit; prevents ad-hoc judgments |
| Process owner updating control procedures | Review at periodic intervals | Address new and emerging risks; maintain version history |
| New control implementation | Sign-off from system/process owner | Validates effectiveness before deployment |
| Security exception identified | Validate first | Rules out false positives before escalating |
| Multiple departments need same control | Align procedures with corporate policy | Prevents conflicting or overlapping procedures |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Control owners identified too late**: Unlike risk owners, control owners
  are often not identified during risk assessment; record them in the risk
  register as soon as identified

- **Procedures without stakeholder oversight**: Procedures built by process
  owners alone may miss compliance requirements; include stakeholder review

- **Confusing accountability with responsibility**: The accountable party
  provides resources and approves decisions; the responsible party executes the
  work

- **Static documentation**: Post-implementation review documents and procedures
  should be living documents, updated as new learnings emerge

- **Exception management failures**: Exceptions must be logged centrally and
  reviewed annually; undocumented exceptions create compliance gaps

##### Doshi Review Manual
- **Exception management is not based on judgment**: Exceptions require a
  documented escalation process, not approval by process owner or manager
  alone.

- **Procedures link to policies through standards**: Standards provide the
  minimum requirements; procedures detail how to meet those requirements.

- **First line conducts control adequacy review**: Process owners, not audit or
  risk management, are responsible for reviewing control environment adequacy.

- **Document currency matters**: The last review date confirms the documents
  meet current business environment. Version history must be maintained.

- **Third-party applicability**: Policies, standards, procedures, and
  guidelines must extend to third-party vendors and service providers.

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Exception review frequency | Annual minimum | More frequent for high-risk areas |
| Control testing approach | Progressive or regressive | Progressive starts from requirements; regressive works backward from results |
| Post-implementation review timing | After each major implementation | Regardless of success or failure |
| Risk register updates | Immediate for control owner changes | Document control owner as soon as identified |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Document hierarchy | Policy > Standard > Procedure > Guideline | Decreasing formality, increasing detail |
| Change frequency | Procedures > Standards > Policies | Procedures change most frequently |
| Exception approval | Policy approver | Not process owner or risk practitioner |
| Control sign-off | System/process owner | Required before implementation |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Control testing and evaluation**: Control owners determine efficacy through
  testing; risk practitioners advise risk owners on gaps
- **Exception management**: Formal process for policy deviations with approval,
  logging, and annual review
- **Risk and control monitoring**: Continuous process to ensure controls remain
  adequate as threat landscape changes
- **Key Control Indicators (KCIs)**: Metrics measuring control effectiveness to
  indicate weakness that may increase risk probability
- **Post-implementation reviews**: Document lessons learned and disseminate to
  stakeholders; questions should cover business objectives, user requirements,
  and resource allocation

##### Doshi Review Manual
- **Change management**: Structured process for implementing control changes;
  preventive control requiring formal approval, documentation, and testing

- **Configuration management**: Most susceptible to introducing vulnerabilities
  through misconfigurations and missing updates

- **Issue and finding management**: Procedures stipulate timelines for
  addressing issues; priority given to high-risk issues; root cause analysis
  prevents recurrence

- **Control monitoring**: Risk practitioner assists in planning, reporting, and
  scheduling tests; monitoring results discussed with risk owner (business
  process owner)

- **Control self-assessment (CSA)**: Process owners conduct self-assessment as
  part of control monitoring alongside periodic testing

#### Exam focus

| Question pattern | Key answer |
| ---------------- | ---------- |
| Who should approve policy exceptions? | The policy approver |
| Best approach for exception management? | Documented escalation process |
| First step when exception noted? | Validate to rule out false positive |
| Which document has high-level management direction? | Policy |
| Example of management control? | Policies and procedures |
| Primary concern with inadequate data/system ownership procedures? | Users may have unauthorized access to create, modify, or delete data |
| Who reviews control environment adequacy? | First line of defense (process owners) |

### 3.6: Update risk register to reflect changes in risk profile

Guide

#### Key concepts

##### CRISC All-in-One Exam Guide
- **Risk register**: A centralized repository documenting all identified risks.
  Can be a SaaS platform or spreadsheet. At minimum, it must contain:
  - Threats and vulnerabilities
  - Likelihood and impact ratings
  - Inherent risk (risk before controls)
  - Current controls in place
  - Residual risk (risk after controls)
  - Planned countermeasures
  - Risk owner assignment
- **Risk profile**: The overall risk exposure of an organization to any type of
  risk. Includes both enterprise risk profile (all business risks) and IT risk
  profile (identified IT risks to which the enterprise is exposed).
- **Risk register as a live document**: The register must be updated whenever
  risk changes due to internal or external factors. Stale registers fail to
  reflect actual organizational risk exposure.
- **Key Risk Indicators (KRIs)**: Highly probable indicators designed to
  predict risks that could breach defined thresholds. Essential for monitoring
  profile changes and triggering register updates.
- **Corrective Action Plan (CAP)**: Created when a risk cannot be remediated
  immediately. Requires an owner, timeline, and specific corrective actions.
  Once remediation completes, the CAP closes and the risk is marked as
  remediated.

##### Doshi Review Manual
- **Risk register**: Centralized inventory of all identified organizational
  risks. Consolidates risk data for driving risk response and tracking risk
  status across the enterprise.
  - Contains: risk scenarios, description, category, probability, impact, risk
    score, risk owner, and risk treatment status
  - Primary purpose: drive the risk response plan, not merely document risks
  - Starts with risk identification and continues through the risk lifecycle

- **Risk profile**: Aggregated view of the organization's overall risk
  exposure, including historical and emerging risks.
  - Provides current risk status for management decision-making
  - Enables risk-aware business decisions when kept current
  - Changes trigger evaluation of whether additional response is required

- **Factors that change risk profile**:
  - Implementation of new technologies
  - Changes in business processes
  - Changes in regulatory requirements
  - Changes in market demand and customer requirements
  - Changes in competitor policies
  - Cascading effects of minor changes

- **Periodic review requirement**: Risk practitioners must evaluate the
  organization's risk profile at regular intervals to identify changes and
  determine if additional response is needed.

#### Factors triggering risk profile changes

| Factor                        | Impact on profile                            |
| ----------------------------- | -------------------------------------------- |
| New regulations               | Adds compliance risks, changes requirements  |
| Technology changes            | Introduces new vulnerabilities or controls   |
| Business objective changes    | Shifts risk appetite and priority            |
| Mergers and acquisitions      | Expands attack surface, adds inherited risks |
| Emerging threats              | Increases likelihood of existing risks       |
| Incidents and breaches        | Demonstrates realized risk, triggers review  |
| New or acquired assets        | Adds to asset inventory requiring protection |
| Supply chain changes          | Introduces third-party dependencies          |
| Privacy framework updates     | Adds regulatory compliance requirements      |
| Control implementation        | Reduces residual risk                        |
| Control deprecation           | Increases residual risk                      |

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario                           | Correct approach                                            | Why                                                          |
| ---------------------------------- | ----------------------------------------------------------- | ------------------------------------------------------------ |
| New vulnerability discovered       | Update likelihood, reassess residual risk, assign CAP       | Threat landscape changed; existing controls may be bypassed  |
| Control implemented                | Reduce residual risk rating, document control owner         | Controls reduce risk; register must reflect current state    |
| Risk accepted by management        | Record acceptance decision, set annual review date          | Accepted risks require documented sign-off and periodic review |
| Vendor introduces new service      | Add risks to register, assign risk owner, assess controls   | Third-party changes expand risk profile                      |
| Audit finding identified           | Create CAP, assign owner, update residual risk if warranted | Findings indicate control gaps affecting risk                |
| KRI breaches threshold             | Escalate to stakeholders, update register with event        | KRI breach signals profile change requiring action           |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Identifying changes in organization's risk profile | Review the risk register | Risk register provides status of current risk profile; other documents lack this detail |
| New vulnerability discovered in application | Discuss with application owner and security manager, recommend addition to risk register | Documents the risk for tracking and response |
| Risk is no longer relevant | Remove from risk register | Keeps register accurate and actionable |
| Activity that triggers a risk is initiated | Add new risk to risk register | Captures emerging risks when they become relevant |
| Presenting current risk profile to senior management | Use risk register dashboard | Provides complete picture of organization's risk profile |
| Risk identified but not yet mitigated | Capture in risk register with remediation status | Enables monitoring of outstanding risks |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Trap: Treating the register as static**: The register is a live document
  requiring continuous updates as the threat landscape evolves. Firewall rules
  that blocked attacks last year may be ineffective against current attack
  patterns.
- **Trap: Missing risk owners**: Without assigned owners, risks go unnoticed
  and unaddressed. Each risk requires a single accountable individual recorded
  in the register.
- **Trap: No control owner**: Controls without owners become outdated with no
  oversight of their performance against changing risks. Control owners must
  be identified and documented.
- **Trap: Confusing residual and current risk**: Residual risk is
  calculated (inherent risk minus controls). Current risk is residual risk in
  a real-time threat scenario. Both require tracking.
- **Trap: Skipping annual review of accepted risks**: Accepted risks must be
  revisited at least annually to assess whether the original asset value and
  risk level still warrant acceptance or if a new response is needed.
- **Trap: KRIs that are not actionable**: KRIs reported to stakeholders but
  lacking actionable thresholds provide no value. Effective KRIs trigger
  register updates when breached.

##### Doshi Review Manual
- **Register vs. profile confusion**: The risk register is the document; the
  risk profile is the aggregated status. Changes in the profile must be
  reflected in the register.

- **Primary purpose misunderstanding**: The primary purpose of maintaining a
  risk register is to drive risk response, not merely to document risks.
  Documentation is a means to that end.

- **Accuracy maintenance**: Centralized publication with periodic polling by
  risk assessors is the most effective method to keep the register accurate
  over time. Outsourcing or relying on audit personnel alone is insufficient.

- **Industry benchmarks excluded**: Risk registers typically do not include
  industry benchmarks or communication plans. Focus is on risk-specific data:
  scenarios, impact, probability, score, owner, and treatment.

- **Determining current risk profile**: When evaluating current risk profile
  after addressing prior gaps, perform a new independent risk assessment.
  Reviewing previous controls alone will not identify new or emerging risks.

#### Minimum risk register fields

| Field              | Purpose                                      |
| ------------------ | -------------------------------------------- |
| Risk ID            | Unique identifier for tracking              |
| Threat             | Source of potential harm                     |
| Vulnerability      | Weakness that could be exploited             |
| Likelihood         | Probability of occurrence                    |
| Impact             | Consequence if risk materializes             |
| Inherent risk      | Risk level before controls                   |
| Current controls   | Existing mitigations                         |
| Residual risk      | Risk level after controls                    |
| Countermeasures    | Planned future controls                      |
| Risk owner         | Accountable individual                       |
| Control owner      | Person responsible for control effectiveness |
| Status             | Open, in remediation, accepted, closed       |
| Last review date   | When risk was last assessed                  |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk response strategies**: Mitigate, accept, transfer, avoid. The selected
  response determines how the register entry is updated.
- **Three Lines of Defense**: First line (business owners) are risk owners.
  Second line monitors controls and KRIs. Third line provides independent
  assurance.
- **Control assessment techniques**: Self-assessments, internal audits,
  vulnerability assessments, penetration tests, and third-party assurance all
  generate findings that update the register.
- **Risk and control monitoring**: Continuous monitoring ensures controls
  remain effective against changing risks. Exceptions trigger register updates.
- **Risk appetite and tolerance**: Define thresholds for acceptable risk.
  Profile changes may push risks outside tolerance, requiring register updates
  and escalation.

##### Doshi Review Manual
- **Key Risk Indicators (KRI)**: Monitored periodically to detect changes in
  risk profile. Primary reason for KRI monitoring is that risk profile changes
  over time.
- **Risk ownership**: Must be documented in the risk register. Risk owner is
  accountable for managing the risk within acceptable levels.
- **Inherent, residual, and current risk**: Risk register tracks the
  progression from inherent to residual risk as controls are implemented.
- **Risk appetite and tolerance**: Register updates must consider whether
  residual risk remains within acceptable levels.
- **Risk reporting**: Risk register dashboard provides the most comprehensive
  view for senior management reporting on organizational risk status.

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk register contents | Scenario, impact, probability, score, owner, treatment | Industry benchmarks and communication plans excluded |
| Risk removal timing | When risk is no longer relevant | Not when controls are implemented |
| Risk addition timing | When activity triggering the risk is initiated | Proactive capture of emerging risks |
| Review frequency | Periodic intervals | Defined by organizational policy |

### 3.7: Verify risk responses executed per approved action plans
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Risk response verification**: Confirming that implemented controls and
  countermeasures align with approved action plans and achieve intended risk
  reduction objectives
  - Requires comparing actual implementation against documented plans
  - Validates that controls operate as designed
  - Ensures risk levels remain within tolerance thresholds

- **Post-implementation review (PIR)**: Formal evaluation conducted after risk
  response implementation to assess effectiveness
  - Determines whether project met business objectives
  - Confirms user requirements were satisfied
  - Validates controls were appropriately defined and implemented
  - Documents lessons learned for future implementations
  - Should be treated as a living document, updated as new insights emerge

- **Corrective action plan (CAP)**: Documented plan for addressing identified
  risks that cannot be remediated immediately
  - Must include an owner accountable for completion
  - Specifies timeline for remediation
  - Details corrective actions to be taken
  - Closed only after remediation is implemented and verified

- **Control assessment**: Process of evaluating and examining effectiveness and
  adequacy of internal controls
  - Reviews control activities: segregation of duties, access controls,
    documentation, monitoring procedures
  - Determines if controls are designed and operating effectively
  - Addresses identified risks within organizational objectives

##### Doshi Review Manual
- **Risk mitigation plan**: Detailed document containing responsible officer, monitoring process, milestone achievement, and implementation timelines. Review of this plan verifies remediation of control deficiencies.

- **Risk treatment plan**: Structured approach to treating identified risks that includes:
  - Detailed action plan
  - Person responsible for implementation
  - Expected date of completion
  - Start date, end date, strategy details
  - Monitored regularly to track progress

- **Risk action plan**: Documented in risk register once risk response is finalized. Must include start date, end date, responsible person/team, and detailed action plan. Treated as a project with measurable timelines, budget, and milestones.

- **Accountability assignment**: For effective implementation, responsibility must be assigned to specific individuals with deadlines. Risk owner retains ultimate accountability even when management of risk is delegated.

- **Post-implementation review**: Determines efficiency and effectiveness of new controls; verifies system meets requirements, controls are properly deployed, ROI is achieved, and residual risk is within acceptable limits.

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Control implemented but effectiveness unknown | Conduct progressive or regressive testing | Validates control meets requirements and identifies gaps |
| Risk response completed but not documented | Perform post-implementation review with stakeholders | Captures lessons learned and confirms objectives met |
| Multiple controls across systems | Use configuration management baselines | Ensures consistent control implementation across enterprise |
| Vendor risk response pending | Track CAP with owner and timeline | Maintains accountability and visibility into remediation status |
| Control exceptions granted | Review annually for continued necessity | Prevents permanent deviations from accumulating |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Ensuring vulnerability is addressed | Assign action plans to responsible employee with timelines | Assigned responsibility with deadlines is most effective for timely implementation |
| Verifying control deficiencies remediated | Review risk mitigation plan | Contains responsible officer, monitoring process, milestones, and implementation timelines |
| Ensuring risk kept at acceptable level | Periodic review of controls per risk action plan | Control effectiveness must be verified continuously, not just documented |
| Supporting approved mitigation plan implementation | Assign action plans to individuals with deadlines | Centralized tracking software or root cause analysis alone is insufficient without assigned responsibility |
| New control implemented | Test the control to validate effectiveness | Each new control must be evaluated for additional vulnerabilities and verified to mitigate risk |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Testing requires non-production data**: Never use production data for
  control testing; generate synthetic data matching production characteristics.
  Mask sensitive fields if production data is absolutely required.

- **Control owner vs. risk owner confusion**: Control owner determines control
  efficacy; risk owner provides budget and mandates risk response. Both roles
  are distinct and required for verification.

- **Outdated controls appear effective**: Controls must be monitored
  continuously as threat landscape evolves. A control verified last year may no
  longer address current risks.

- **Self-assessment alone insufficient**: Self-assessments identify
  management-known issues but lack independence. Combine with internal audits,
  penetration testing, or third-party assurance for comprehensive verification.

- **CAP closure without validation**: A CAP should only be marked closed after
  confirming the remediation was implemented and the risk level reduced as
  expected, not merely when the deadline passes.

##### Doshi Review Manual
- **Delegation does not transfer accountability**: When local management mitigates risk owned by corporate management, corporate management remains responsible for monitoring and controlling the risk.

- **Documentation alone is insufficient**: Merely documenting risks in a register does not ensure they are addressed. Active periodic review of controls against the action plan is required.

- **Milestones without ownership fail**: Action plan monitoring software is ineffective without first assigning responsibility to specific individuals with deadlines.

- **Post-implementation review timing**: Must be conducted after sufficient time to determine effectiveness, efficiency, and adequacy - not immediately after deployment.

- **Incidents vs. risks**: Already-occurred incidents (realized risks) are not in scope of risk treatment plans. This is an area of major concern if overlooked.

- **Critical path monitoring**: Delays in critical path elements increase overall project risk. Risk action plans should be monitored as projects.

#### Verification techniques

| Technique | Purpose | Independence |
| --------- | ------- | ------------ |
| Self-assessment (MSII) | Engage key resources to identify overlooked issues | Low |
| Internal IS audit | Objective evaluation with auditor recommendations | Medium |
| Vulnerability assessment | Identify known weaknesses in controls | Medium |
| Penetration testing | Discover undocumented vulnerabilities through simulated attacks | High |
| Third-party assurance (SOC 2, ISO 27001, PCI DSS) | Independent attestation of control effectiveness | Highest |

#### Key indicators for verification

- **Key Performance Indicators (KPIs)**: Measure control performance against
  objectives (e.g., reduction in incidents after control implementation)

- **Key Risk Indicators (KRIs)**: Predict risks approaching thresholds; alert
  stakeholders when risk responses may be failing (e.g., employees repeatedly
  falling for phishing despite training)

- **Key Control Indicators (KCIs)**: Track control effectiveness relative to
  tolerance; identify weaknesses increasing risk probability (e.g., lack of
  controls blocking known attack vectors)

Indicators should follow SMART criteria: Specific, Measurable, Attainable,
Relevant, Timely.

#### Reporting verified responses

| Format | Use case | Characteristics |
| ------ | -------- | --------------- |
| Executive summary | Milestone completion with quantified metrics | 1-2 pages, concise |
| Heat maps | Risk position visualization | Qualitative, 2Ã—2 to nÃ—n grid |
| Scorecards | Aggregated performance grades | Qualitative, simplified view |
| Dashboards | Trend analysis and anomaly detection | Quantitative + qualitative, flexible |

Key reporting considerations: audience, actionability, format preference,
succinctness, data source integrity, tailoring, timeframe, cadence.

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk and control monitoring**: Continuous process ensuring controls remain
  relevant as risk profile changes; uses self-assessments and independent audits
- **Exception management**: Process for documenting and approving policy
  deviations; requires annual review of granted exceptions
- **Change management**: Formal CAB review and approval for system or
  configuration changes affecting risk responses
- **Configuration management**: Baseline standards ensuring consistent control
  implementation across all enterprise systems

##### Doshi Review Manual
- **Risk register**: Documents risk ownership, corrective actions, residual risk, and remediation status. Provides centralized view for tracking and verification.
- **Control testing**: Best method to verify control effectiveness. Role of risk practitioner is to assist in planning, reporting, and scheduling tests.
- **KRI monitoring**: Periodic monitoring identifies changes in risk profile; determines if additional response is required.
- **Exception management**: Exceptions to policy require documented escalation process and validation before reporting.
- **Project closeout**: Must include accountability assignment for outstanding issues, risk register updates, documentation archival, post-implementation review, and end-user sign-off.

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk treatment plan scope | Risks exceeding tolerance level | Not required for accepted, avoided, or transferred risks |
| Control review frequency | Periodic intervals | Ensures risk remains at acceptable level |
| Post-implementation participants | Development team, end users, risk practitioner | Joint review required |
| Project closeout accountability | Specific individuals for outstanding issues | Must include follow-up and closure responsibility |

### 3.8: Establish Key Risk Indicators (KRIs) and thresholds for monitoring
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Key Risk Indicator (KRI)**: A metric designed to predict risks that could
  breach defined thresholds. KRIs serve as early warning signals that alert
  stakeholders when risk levels approach or exceed acceptable limits.
  - Distinguished from KPIs (measure control performance) and KCIs (measure
    control effectiveness)
  - Must be actionable -- KRIs reported without clear remediation paths provide
    little value to management
  - Should trigger stakeholder notification when predefined thresholds are
    breached

- **Threshold**: A predefined limit that defines when a KRI moves from
  acceptable to concerning or critical status. Thresholds translate risk
  appetite into operational boundaries.
  - Tied to risk tolerance -- the acceptable variation management allows
  - Must remain below risk capacity (the point where organizational existence
    is threatened)
  - Should account for compensating controls that may allow temporary
    tolerance breaches

- **SMART criteria for indicators**: Key indicators should be:
  - **Specific**: Clearly understandable and concise
  - **Measurable**: Can be quantified
  - **Attainable**: Realistic and goal-based
  - **Relevant**: Connected to specific activities or objectives
  - **Timely**: Time-bound with defined measurement periods

- **Second Line of Defense (2LoD) responsibility**: The risk monitoring and
  oversight function is responsible for developing KRIs and keeping
  stakeholders informed of credible threats. This includes monitoring first
  LoD activities for compliance.

##### Doshi Review Manual
- **Key Risk Indicator (KRI)**: A measure used to determine the level of current
  risk for an activity. KRIs flag exceptions as they occur, providing opportunity
  to respond before damage is done.
  - Objective is to monitor risk levels and receive alerts when approaching
    unacceptable levels
  - Examples: unauthorized software count, system downtime hours, systems
    without antivirus

- **Threshold**: The minimum requirement or maximum limit within which a KRI is
  expected to operate.
  - Indicates whether controls are providing intended value
  - Must be aligned with risk appetite and risk tolerance
  - Requires periodic review as risk profile changes

- **Lead indicators**: Forward-looking; provide warning signals for emerging
  high risk (preventive controls)

- **Lag indicators**: Backward-looking; indicate past occurrences and provide
  trends and historical data to improve risk response

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Employees failing phishing tests repeatedly | Define KRI for untrained employees; set threshold for acceptable failure rate | Predicts breach risk before incident occurs |
| Orphan database accounts discovered | Monitor termination procedures via KRI; alert when gap threshold exceeded | Second LoD failed to detect in example case |
| Risk exceeds appetite but within tolerance | Accept with compensating controls; document in risk register | Tolerance allows slight deviation from appetite |
| Risk approaches capacity threshold | Immediate escalation and remediation required | Exceeding capacity threatens organizational existence |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Identifying when to establish KRIs | During risk response stage (before risk monitoring) | Controls are selected and implemented at this stage; KRIs measure control effectiveness |
| KRI reaches threshold | Report first to business process owner | Owner determines risk response and evaluates if additional controls are needed |
| Validating line manager's KRI monitoring | Independent review of reported results | Ensures unbiasedness and validates efficiency of monitoring efforts |
| Designing effective KRIs | Document end-to-end operational flow of business processes | Enables understanding of data flows, decision processes, risk appetite, and tolerance |
| Monitoring third-party risk | Use indicators with approved thresholds | Determines acceptable risk levels; exceeding thresholds triggers management alarm |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Actionability is mandatory**: KRIs that only inform but offer no
  remediation path are useless to senior management. Every KRI must have
  associated response procedures.

- **Tolerance vs. capacity confusion**: Risk tolerance is acceptable variation
  around appetite. Risk capacity is the absolute maximum before organizational
  survival is threatened. KRI thresholds should trigger well before capacity
  is reached.

- **Qualitative vs. quantitative balance**: Dashboards combining both types of
  metrics are preferred over purely qualitative heat maps or scorecards, which
  leave room for interpretation error.

- **False positive fatigue**: SIEM and alerting systems require regular
  fine-tuning of thresholds to reduce false positives. Too many alerts cause
  practitioners to ignore genuine warnings.

- **Threshold setting requires context**: IDS rules and monitoring thresholds
  must be appropriately calibrated. Setting thresholds too low generates
  thousands of false positive alerts; too high misses genuine threats.

##### Doshi Review Manual
- **KRI threshold must evolve with risk profile**: A threshold acceptable today
  (e.g., 10% defect rate) may become unacceptable later (e.g., 2%) due to
  changing market conditions

- **KRIs identified during risk response, not monitoring**: Controls are
  implemented first, then KRIs are developed to measure control effectiveness

- **Independent monitoring required**: KRIs should be measured by an
  independent team. If measured by line managers, results must be reviewed by
  independent authority

- **Threshold capability is critical for control lifecycle**: Without thresholds
  that identify when controls fail, organizations may believe ineffective
  controls are still working

- **Events below threshold do not require escalation**: If adverse events have
  negligible impact and remain within set thresholds, senior management may not
  need notification

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk appetite | Defined by organization | Amount of risk willing to accept for objectives |
| Risk tolerance | Slight deviation allowed | Acceptable variation around appetite |
| Risk capacity | Absolute maximum | Exceeding threatens organizational existence |
| Risk acceptance duration | Annual review minimum | Document in GRC tool; revisit regularly |
| Dashboard cadence | Recurring | Show trends, analysis, anomalies over time |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk appetite and tolerance**: KRI thresholds derive directly from
  appetite and tolerance definitions. Thresholds operationalize these abstract
  concepts into measurable limits.

- **Three Lines of Defense (3LoD)**: Second LoD develops and monitors KRIs.
  First LoD owns the risks. Third LoD (audit) evaluates KRI effectiveness.

- **SIEM integration**: Log aggregation tools collect data that feeds KRIs.
  Intelligent thresholds in SIEM systems automate breach detection and
  alerting.

- **Control assessment techniques**: Self-assessments, internal audits,
  vulnerability assessments, and penetration testing provide data that
  informs KRI values and threshold calibration.

- **Risk reporting formats**: KRIs are typically presented via dashboards
  (preferred for flexibility), heat maps, scorecards, or executive summaries
  depending on audience needs.

##### Doshi Review Manual
- **Risk profile**: Overall risk status the organization is exposed to; KRIs
  help keep this updated with new and emerging risks
- **Key Performance Indicators (KPIs)**: Measures performance of business
  targets; often used in combination with KRIs
- **Key Control Indicators (KCIs)**: Measures control effectiveness
- **Risk appetite and tolerance**: KRI thresholds must align with these
  organizational parameters
- **Continuous monitoring**: Process and technology used to monitor critical
  areas on an ongoing basis; typically applied to high-risk areas

#### SMART criteria for KRI selection

| Criterion | Requirement |
| --------- | ----------- |
| Specific | Clear, concise, easily understandable |
| Measurable | Quantifiable with no subjectivity |
| Attainable | Realistic targets |
| Relevant | Aligned with organizational goals and objectives |
| Time-bound | Achievable within a given time frame |

#### KRI design priorities

Design aspects in order of priority:

1. KRI should be linked to specific risk (most important)
2. KRI should be capable to predict a risk event
3. KRI should be complete and accurate
4. KRI should be easily measurable and comparable
5. KRI should be repeatable to be effective over time

#### KRI threshold example

| System downtime | Risk indicator |
| --------------- | -------------- |
| Less than 5 hours | Acceptable |
| Between 5-10 hours | Close monitoring |
| More than 10 hours | Unacceptable |

#### Advantages of KRIs

- Validates risk appetite and risk tolerance levels
- Identifies risk objectively
- Quantifies risk
- Enables continuous risk monitoring
- Triggers risk mitigation action
- Monitors regulatory compliance

#### Reporting and monitoring responsibilities

| Role | Responsibility |
| ---- | -------------- |
| Independent team | Measure and monitor KRIs to ensure unbiasedness |
| Line manager | Monitor KRIs (with independent review) |
| Senior official | Review and validate monitoring efforts |
| Business process owner | First recipient when KRI reaches threshold; evaluates control effectiveness |
| Senior management | Receives periodic KRI results to determine current state of risk |

### 3.9: Monitor and assess KRIs to detect IT risk profile shifts
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Key Risk Indicators (KRIs)**: Highly probable indicators designed to predict
  risks that could breach defined thresholds
  - Primary goal: monitor and analyze trends to detect risk profile changes
  - Enable informed decisions on current controls and planned countermeasures
  - Alert stakeholders when risk breaches predefined thresholds
  - Example: employees not trained in security awareness continuing to fall for
    phishing attacks

- **Risk profile**: Overall risk exposure of the organization to any type of
  risk
  - IT risk profile: overall identified IT risk to which the enterprise is
    exposed
  - Factors affecting IT risk profile: emerging threats, malicious actors,
    incidents, regulatory changes (privacy frameworks), new/acquired assets,
    supply chain risks
  - Risk profile is ever-changing; risks from a year ago may no longer be
    relevant

- **Actionable KRIs**: KRIs must be actionable to be useful to senior management
  - KRIs reported only for inferences without actionability provide little value
  - Goal: identify recurring and high risks for remediation as soon as practical

- **Thresholds and escalation**: KRIs predict risks that could breach thresholds
  - Risk tolerance threshold: acceptable deviation from risk appetite
  - Crossing risk tolerance enters risk capacity territory (threatens existence)
  - Automated alerts trigger when thresholds are exceeded

- **SMART metrics for KRIs**: Key indicators should follow SMART criteria
  - **Specific**: clearly understandable and concise
  - **Measurable**: can be measured and quantified
  - **Attainable**: realistic and based on goals
  - **Relevant**: tied to a specific activity or goal
  - **Timely**: time-bound, not open-ended

##### Doshi Review Manual
- **Key Risk Indicator (KRI)**: A measure used to determine the level of current
  risk for an activity. Flags exceptions when risk approaches unacceptable
  levels, providing opportunity to respond before damage occurs.
  - Primary purpose: early warning signal for emerging risks
  - KRIs are identified during the risk response stage, before risk monitoring
  - Threshold breaches indicate controls may be inadequate

- **Risk profile**: Overall risk status the organization is exposed to. Must be
  kept updated with new and emerging risks to ascertain current risk status.
  - KRIs answer: "How is our risk profile changing and is it within tolerance?"
  - Business environment changes constantly; periodic KRI monitoring addresses
    profile shifts

- **KRI thresholds**: Boundaries that indicate whether controls provide intended
  value. Without appropriate thresholds, organizations cannot determine control
  effectiveness.
  - Must align with risk appetite and tolerance
  - Should identify when controls no longer provide intended value
  - Require periodic revision as business conditions change

- **Lead vs lag indicators**:
  - Lead indicators: forward-looking, provide warning signals for emerging risk
  - Lag indicators: backward-looking, indicate past occurrences
  - Effective KRI programs balance both types
  - Lag indicators provide trends and historical data to improve risk response

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| New privacy regulation introduced | Update IT risk profile, adjust KRI thresholds | External factors shift risk exposure |
| Merger or acquisition completed | Reassess enterprise and IT risk profiles | New assets and systems change risk landscape |
| KRI shows employees failing phishing tests | Escalate to stakeholders, implement training | Indicates control gap before breach occurs |
| Risk tolerance threshold crossed | Evaluate compensating controls, report to management | Approaching risk capacity requires intervention |
| Multiple KRIs trending upward | Analyze correlation, adjust controls proactively | Pattern indicates systemic risk profile shift |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| KRI reaches threshold | Report to business process owner first | Owner evaluates control effectiveness and determines response |
| Adverse events not reported to management | Check if events exceeded KRI sensitivity threshold | KRIs only alert when threshold is breached |
| Product defect threshold outdated | Revise KRI to reflect new market conditions | Risk profile changes over time; 10% acceptable may become 2% |
| Line manager monitors KRI | Independent review of reported results | Validates efforts and ensures unbiasedness |
| High false positive rate on IDS | Adjust sensitivity settings | Tuning sensitivity impacts detection accuracy |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Confusing KRIs with KPIs**: KPIs measure control performance; KRIs predict
  risk threshold breaches. Use KRIs for forward-looking risk detection.

- **Non-actionable KRIs**: Reporting KRIs without remediation paths wastes
  management attention. Every KRI should have a response plan.

- **Static thresholds**: Thresholds must adjust as risk appetite, business
  objectives, and threat landscape change.

- **Ignoring trend analysis**: Individual KRI readings matter less than trends
  over time. Dashboards should show trend identification, analysis, and
  anomalies.

- **Risk tolerance vs. risk capacity**: Tolerance is acceptable variation;
  capacity is maximum risk before existence is threatened. Breaching capacity is
  critical; breaching tolerance is a warning.

##### Doshi Review Manual
- **KRI identification timing**: KRIs are identified during risk response stage,
  not risk monitoring stage. Controls must be selected and implemented first.

- **First escalation target**: When KRI threshold is breached, report to
  business process owner first, not IT, security, or senior management.

- **KRI vs KCI confusion**: KRIs measure risk profile; KCIs measure control
  effectiveness. They are inversely correlated: effective controls (KCI) mean
  risk within limits (KRI).

- **Periodic review purpose**: Primary reason for monitoring KRIs periodically
  is to address changes in risk profile, not to minimize cost or comply with
  policy.

- **Measurement independence**: KRIs should be measured by an independent team.
  If line managers measure, results must be reviewed by independent authority.

#### Reporting formats for KRI monitoring

| Format | Characteristics | Best use |
| ------ | --------------- | -------- |
| Executive summary | 1-2 pages, concise key risks | Milestone reporting with metrics |
| Heat maps | Visual 2x2 to nxn grid, color-coded | Qualitative impact vs. likelihood |
| Scorecards | Aggregated grades per area | High-level status across domains |
| Dashboards | Mixed quantitative/qualitative metrics | Trend identification and anomalies |

#### Control assessment techniques

| Technique | Description | Scope |
| --------- | ----------- | ----- |
| Self-assessments (MSIIs) | Internal workshops identifying overlooked issues | Known risks and controls |
| Internal IS audit | Independent review providing objective evidence | Control effectiveness |
| Vulnerability assessment | Tool-based identification of known weaknesses | Technical controls |
| Penetration testing | Simulated attacks finding unknown vulnerabilities | Business logic and cascading flaws |
| Third-party assurance | External attestation (SOC 2, ISO 27001, PCI DSS) | Stakeholder confidence |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk and control monitoring**: continuous evaluation of control environment
  against changing threat landscape (see objective 3.8)
- **Second line of defense**: responsible for developing KRIs and keeping
  stakeholders informed of credible threats
- **SIEM systems**: collect, analyze, and correlate logs; alert based on
  intelligent thresholds; require ongoing tuning to reduce false positives
- **Risk appetite and tolerance**: define acceptable boundaries that KRI
  thresholds enforce
- **Continuous monitoring**: ensures controls remain effective as risk profile
  shifts; required for detecting changes in risk status

##### Doshi Review Manual
- **KCI (Key Control Indicator)**: Measures control effectiveness; inversely
  correlated with KRI. If KCI shows controls working, KRI should be within
  limits.
- **Continuous monitoring**: Process and technology for ongoing critical area
  monitoring. First step is identifying high-risk areas.
- **Risk dashboard**: Most suitable format for reporting IT-related business
  risk to senior management.

#### SMART criteria for KRI selection

| Criterion | Requirement |
| --------- | ----------- |
| Specific | Clear, concise, easily understandable |
| Measurable | Quantifiable with no subjectivity |
| Attainable | Realistic and achievable |
| Relevant | Aligned to organizational goals and objectives |
| Time-bound | Achievable within defined time frame |

#### KRI design priorities

| Priority | Requirement |
| -------- | ----------- |
| 1 | Linked to specific risk (most important) |
| 2 | Capable of predicting a risk event |
| 3 | Complete and accurate |
| 4 | Easily measurable and comparable |
| 5 | Repeatable over time |

#### Examples of KRIs

| KRI | What it indicates |
| --- | ----------------- |
| Number of unauthorized software detected | Security awareness gaps |
| Hours of system downtime | Availability risk |
| Number of systems without antivirus | Endpoint protection gaps |
| Number of workstations vs employee count | Configuration management issues |
| Installation of unlicensed software | Need for security awareness training |

#### KRI reporting

- **Threshold breach**: First report to business process owner
- **Periodic results**: Place before senior management at regular intervals
- **IT-related KRIs for financial systems**: Report to IT management (they make
  risk-related decisions)
- **KRI results**: Most useful data for communicating current risk state to
  management

#### Advantages of KRIs

- Validates risk appetite and tolerance levels
- Identifies risk objectively
- Enables risk quantification
- Supports continuous risk monitoring
- Triggers risk mitigation actions
- Monitors regulatory compliance

### 3.10: Report IT risk profile changes and trends to management
#### Key concepts

##### CRISC All-in-One Exam Guide
- **IT risk profile**: The overall identified IT risk to which the enterprise is
  exposed
  - Depends on factors such as emerging threats, malicious actors, incidents,
    regulatory changes, new assets, and supply chain risks
  - Changes constantly due to internal and external factors
  - Must be monitored and reported to enable timely remediation

- **Key Risk Indicators (KRIs)**: Highly probable indicators designed to predict
  risks that could breach defined thresholds
  - Goal: monitor trends, determine control effectiveness, alert stakeholders
    when thresholds are breached
  - Must be actionable; non-actionable KRIs provide little value to senior
    management
  - Example: employees not trained in security awareness continuing to fall for
    phishing attacks

- **Key Performance Indicators (KPIs)**: Measures of control performance
  - Defined relative to organization's objectives and risk appetite
  - Example: reduction in phishing emails after implementing a new tool

- **Key Control Indicators (KCIs)**: Measures of control effectiveness
  - Indicate weaknesses that may increase probability of risk events
  - Track control performance relative to tolerance
  - Example: lack of controls to block phishing emails

- **SMART metrics**: Framework for selecting key indicators
  - Specific: clearly understandable and concise
  - Measurable: can be quantified
  - Attainable: realistic and goal-based
  - Relevant: tied to specific activity or goal
  - Timely: time-bound, not open-ended

##### Doshi Review Manual
- **Risk profile**: Overall risk status that the organization is exposed to;
  aggregates historical risk and emerging risk into a single view
  - Must be kept updated with new and emerging risks
  - Enables risk-aware business decisions by management
  - Changes should be recorded in the risk register

- **Risk register as source of truth**: Primary document for identifying changes
  in an organization's risk profile
  - Should provide current risk profile status
  - Updated when risk profile changes occur

- **Purpose of reporting changes**: Significant changes reported to senior
  management to:
  - Update management about current risk profile
  - Enable educated decision-making
  - Determine whether additional response is required

- **Key risk indicators (KRIs)**: Most useful data for communicating current
  state of risk to management
  - Periodic monitoring identifies changes in risk profile
  - Results placed before senior management at regular intervals
  - When KRI reaches threshold, first reported to business process owner

- **Lead vs lag indicators**:
  - Lead indicators: Forward-looking; provide warning signals for emerging risk
  - Lag indicators: Backward-looking; provide relevant trends and historical
    data to improve risk response

#### Reporting formats

##### CRISC All-in-One Exam Guide
| Format | Description | Best used for |
| ------ | ----------- | ------------- |
| Executive summary | Concise 1-2 page overview with quantified metrics | Project milestones, control effectiveness |
| Heat map | Graphical grid (2x2 to nxn) showing impact vs. likelihood | Visual risk severity comparison |
| Scorecard | Aggregated performance with grades per area | Simplified status communication |
| Dashboard | Collection of qualitative and quantitative metrics | Trend analysis, recurring reporting |

Dashboards are the preferred method due to flexibility in combining qualitative
and quantitative content and ability to show trends.

##### Doshi Review Manual
| Format | Best use |
| ------ | -------- |
| Dashboard | Senior management reporting; high-level overview |
| Risk register dashboard | Presenting current risk profile; complete picture |
| Heat maps | Visual risk severity representation |
| Scorecards | Performance tracking |
| KRI reports | Current state of risk; control effectiveness |

#### Reporting considerations

- **Audience**: Match report to the right stakeholders
- **Actionability**: Ensure metrics drive decisions
- **Format**: Know the audience's preferred format
- **Succinctness**: Show only key information relevant to audience
- **Source**: Verify data integrity
- **Tailoring**: Customize for primary stakeholders
- **Timeframe**: Present relevant time periods
- **Inferences**: Enable audience to draw conclusions
- **Cadence**: Agree on reporting frequency

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Phishing incidents increased 40% | Report trend with root cause (e.g., untrained employees) via dashboard | Enables actionable response; shows trend not just point-in-time |
| New regulatory requirement introduced | Update risk profile to reflect compliance risk; report to board | External factors change profile; governance needs visibility |
| Control implemented successfully | Report KPI showing measurable improvement | Demonstrates control effectiveness quantitatively |
| KRI threshold breached | Alert stakeholders immediately; include in recurring report | Enables timely intervention before risk materializes |
| Presenting to physical security lead | Exclude IT-specific metrics like phishing attempts | Tailor content to audience's domain |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Present current risk profile to senior management | Use risk register dashboard | Provides complete picture of organization's risk profile |
| Report risk to top management | Use dashboard | High-level overview easily tailored to senior management needs |
| Identify changes in risk profile | Review risk register | Risk register tracks profile changes and current status |
| Evaluate current risk profile after year-long gap | Conduct new risk assessment by independent expert | Identifies new or emerging risks that existing controls may not address |
| KRI reaches threshold | Report to business process owner first | Owner determines risk response and evaluates control effectiveness |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Non-actionable KRIs**: Reporting indicators that stakeholders cannot act on
  wastes management attention; every KRI should have a clear response path

- **Wrong audience**: Sending IT security metrics to stakeholders outside the
  IT domain (e.g., phishing statistics to physical security) reduces report
  relevance

- **Qualitative-only reporting**: Heat maps and scorecards alone leave room for
  judgment error; dashboards combining qualitative and quantitative metrics
  provide more reliable trend analysis

- **Static risk register**: The risk register must be a live document updated
  when risk changes due to internal or external factors; stale data produces
  misleading profile reports

- **Ignoring risk reporting phase**: Risk practitioners often skip reporting
  after completing risk treatment; this phase is critical for stakeholder
  awareness and decision-making

##### Doshi Review Manual
- **Reporting purpose misconception**: Main reason to report risk profile
  changes is NOT to update inventory, budget, or individual risk
  probability/impact--it is to update management about current overall risk
  profile

- **KRI monitoring objective**: Prime objective is to monitor change in risk
  profile, not to minimize cost or error rates

- **Dashboard vs other tools**: Work breakdown reports and Gantt charts are
  project management tools; balance scorecards monitor IT performance--neither
  is suitable for risk reporting to management

- **Report content driver**: Risk reports should be tailored to the target
  audience, not to risk severity or vulnerability counts

- **Independent review requirement**: KRI monitoring by line managers should be
  validated through independent review of reported results

#### Reporting cadence

| Report type | Typical frequency |
| ----------- | ----------------- |
| Dashboard with trends | Recurring (monthly/quarterly) |
| Executive summary | Per milestone or project |
| Board risk report | Quarterly |
| Risk assessment results | At least annually |
| KRI breach alerts | Immediate/as needed |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk appetite and tolerance**: Thresholds that define when risk profile
  changes require escalation
- **Risk register**: Source document for tracking identified risks and status
  changes
- **Three Lines of Defense**: Second line develops KRIs; third line provides
  independent assurance reported to governance
- **Control monitoring**: Continuous assessment that feeds trend data into
  reports
- **SIEM and log aggregation**: Technical foundation for generating metrics and
  detecting anomalies for reporting

##### Doshi Review Manual
- **Risk appetite and tolerance**: Basis for developing KRIs includes
  organization's risk appetite, metrics, and current risk profile
- **Risk monitoring**: Closely associated with risk reporting; results of
  monitoring feed into reports
- **Continuous monitoring**: Used for high-risk areas where impact and
  frequency of occurrence are high; first step is identifying high-risk areas
- **Control assessment**: Effectiveness depends on accurate data, timely
  reporting to management, and skilled risk practitioners

#### Factors driving risk profile changes

| Factor | Notes |
| ------ | ----- |
| New technologies | Implementation introduces new threat vectors |
| Business process changes | Alter risk exposure and control requirements |
| Regulatory requirements | Create new compliance obligations |
| Market demand and customer requirements | Shift operational priorities |
| Competitor policies | Industry changes affect risk landscape |
| Cascading effects | Minor changes may compound into significant impact |

### 3.11: Facilitate identification of KPIs for control performance assessment
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Key Performance Indicators (KPIs)**: Metrics used to understand and enable
  measurement of control performance
  - Performance levels differ by organization
  - Risk managers define KPIs aligned with organizational objectives and risk
    appetite
  - Example: reduction in phishing emails after implementing a new tool

- **Key Risk Indicators (KRIs)**: Highly probable indicators designed to predict
  risks that could breach defined thresholds
  - Monitor and analyze trends
  - Determine effectiveness and efficiency of controls
  - Alert stakeholders when risk breaches predefined thresholds
  - Example: employees not trained in security awareness continuing to fall for
    phishing attacks

- **Key Control Indicators (KCIs)**: Measure of control effectiveness indicating
  weaknesses that may increase probability of risk events
  - Track performance of control actions relative to tolerance
  - Provide insight into control effectiveness for keeping risk within
    acceptable levels
  - Example: lack of implemented controls to block phishing emails

- **SMART criteria for indicator selection**: Indicators should be:
  - **S**pecific: clearly understandable and concise
  - **M**easurable: can be measured and quantified
  - **A**ttainable: realistic and based on goals
  - **R**elevant: relevant to a specific activity or goal
  - **T**imely: timebound and not open-ended

##### Doshi Review Manual
- **Key Performance Indicator (KPI)**: Indicator that measures how well a process
  is doing in terms of its goals and objectives
  - Provides warning when values approach or exceed thresholds
  - Used in combination with KRIs and KCIs to measure performance and mitigate
    risk
  - Senior management is predominantly interested in KPIs

- **Key Control Indicator (KCI)**: Indicator that measures the effectiveness of
  controls
  - Also called control effectiveness indicators
  - Provides insight into ongoing adequacy of a control to keep risk at
    acceptable levels
  - Tolerance levels are designed considering criticality of assets the control
    protects
  - KCI and KRI are inversely correlated: effective controls mean risk stays
    within limits

- **Threshold**: Minimum requirements or maximum limit within which KPI, KRI,
  and KCI are expected to operate
  - Values within threshold indicate acceptable performance
  - Values outside threshold require immediate attention

- **SMART characteristics**: Criteria for effective metrics
  - Specific: clear, concise, easily understandable
  - Measurable: quantifiable without subjectivity
  - Attainable: realistic and achievable
  - Relevant: aligned with organizational goals and objectives
  - Time-bound: achievable in a given timeframe

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Measuring vulnerability management program | Count vulnerabilities found and remediated | Indicates success at identifying and addressing security risks |
| Evaluating new security program effectiveness | Track percentage reduction in data breaches | Provides clear metric to measure program success over time |
| Defining KPIs for phishing control | Measure reduction in successful phishing attempts post-control | Directly ties control implementation to measurable outcome |
| Stakeholder reporting needs vary | Tailor indicators to audience | Technical metrics for security team; business impact metrics for executives |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Evaluating disaster recovery readiness | Results of tests and exercises | Demonstrates actual capability, not just documentation |
| Measuring control management effectiveness | Measure control effectiveness against business objectives | Shows whether controls achieve intended purpose |
| Assessing processing environment | User satisfaction survey | Indicates how well operations meet user expectations |
| Monitoring user access administration | Percent of accounts complied with configuration | Reflects overall impact of access controls |
| Validating control effectiveness | Key Control Indicator (KCI) | Specifically designed to measure control performance |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **KPIs vs KRIs vs KCIs confusion**: KPIs measure control performance; KRIs
  predict threshold breaches; KCIs indicate control weaknesses. Each serves a
  distinct purpose in risk monitoring.

- **Non-actionable indicators**: The most important aspect of effective
  indicators is that they should be actionable. Indicators reported but not
  actionable provide little value to senior management.

- **Misalignment with risk appetite**: KPIs must make sense to the
  organization's objectives and risk appetite. Generic industry KPIs may not
  reflect actual organizational risk tolerance.

- **Confusing risk tolerance with risk capacity**: Risk tolerance is acceptable
  deviation from risk appetite; risk capacity is the maximum risk before
  threatening organizational existence. KPI thresholds should respect both.

- **Static indicator selection**: Risks are ever-changing, so the risk profile
  changes. Controls recently implemented may become outdated. Continuously
  monitor, benchmark, and improve the control environment.

##### Doshi Review Manual
- **KPI vs KCI confusion**: KPIs measure business performance targets; KCIs
  measure control effectiveness. Many organizations incorrectly label everything
  as "KPI"

- **Threshold interpretation**: A KPI requires immediate attention when its
  value is outside the threshold, not when fluctuating or below average

- **Metric recipient relevance**: The most important criterion for metric
  effectiveness is that it is meaningful to the recipient. Completeness,
  accuracy, and cost-effectiveness are secondary

- **Lead vs lag indicators**: Lead indicators provide forward-looking warning
  signals; lag indicators show historical trends. Both are needed for effective
  risk response

- **KCI-KRI relationship**: KCI acts as a leading indicator for associated KRIs.
  A single control may affect multiple risk areas, so KCI may have broader
  implications than KRIs

#### Control assessment techniques for KPI validation

| Technique | Purpose | Notes |
| --------- | ------- | ----- |
| Self-assessments (MSIIs) | Internal risk workshops | Engage key resources; non-judgmental; identify overlooked issues |
| Internal IS audit | Independent internal evaluation | Auditor recommendations presented objectively to management |
| Vulnerability assessment | Identify known weaknesses | Only finds known vulnerabilities; cannot discover new ones |
| Penetration testing | Simulate real attacks | White/gray/black box; finds undiscovered vulnerabilities |
| Third-party assurance | External attestation (SOC 2, ISO 27001) | Carries more weight for stakeholder trust |

#### Reporting formats for KPIs

| Format | Characteristics | Best for |
| ------ | --------------- | -------- |
| Executive summary | Brief, high-level | Senior leadership quick review |
| Heat map | Color-coded risk visualization | Qualitative risk overview |
| Scorecard | Grades assigned to areas | Performance tracking |
| Dashboard | Qualitative and quantitative metrics combined | Trend identification, anomaly detection, recurring reporting |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk and control monitoring**: Continuous assessment of control environments
  using KPIs to verify control adequacy as threat landscape changes

- **Risk appetite and tolerance**: KPI thresholds must align with organizational
  risk appetite; deviations within tolerance are acceptable, beyond tolerance
  requires action

- **Three lines of defense**: Second line develops KRIs and keeps stakeholders
  informed of credible threats; KPIs help monitor first line activities

- **Control design and implementation**: KPIs validate that implemented controls
  achieve intended risk reduction objectives

##### Doshi Review Manual
- **Key Risk Indicators (KRI)**: Measures level of risk; threshold should align
  with risk appetite and tolerance
- **Control monitoring**: Ongoing validation that controls address risk; more
  effective than ad-hoc control testing
- **Dashboard reporting**: Most effective method for reporting metrics to senior
  management
- **Optimum control level**: Balance between control effectiveness and cost of
  maintaining the control

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Error rate threshold example | 10% | Above threshold requires escalation |
| System uptime target example | >99% | KPI for availability |
| Tolerance definition timing | Before KCI creation | Tolerances must be established first |

#### KPI examples by domain

| Domain | KPI example |
| ------ | ----------- |
| Availability | Network uptime percentage |
| Disaster recovery | Results of tests and exercises |
| Operations | User satisfaction survey results |
| Access management | Percent of accounts compliant with configuration |

#### KCI examples

- Percentage of phishing emails blocked by filtering software
- Percentage of audit findings closed within specified time
- Instances of malicious traffic bypassing the firewall

### 3.12: Monitor and evaluate KPIs to measure control efficiency
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Key Performance Indicators (KPIs)**: Metrics used to understand and enable
  measurement of control performance
  - Performance levels differ by organization; define KPIs aligned with
    organizational objectives and risk appetite
  - Example: reduction in phishing emails after implementing a new tool

- **Key Risk Indicators (KRIs)**: Highly probable indicators designed to
  predict risks that could breach defined thresholds
  - Goal: monitor trends, determine control effectiveness and efficiency, alert
    stakeholders when risk breaches thresholds
  - Example: group of employees not trained in security awareness continuing to
    fall for phishing attacks

- **Key Control Indicators (KCIs)**: Measure of control effectiveness to
  indicate weakness that may increase probability of risk events
  - Goal: track performance of control actions relative to tolerance and
    provide insight into control effectiveness
  - Example: lack of implemented controls to block phishing emails

- **Control assessment**: Process of evaluating and examining the effectiveness
  and adequacy of internal controls within an organization
  - Review control activities: segregation of duties (SoD), access controls,
    documentation, monitoring procedures

- **Control owner**: Person who implements a control or is responsible for
  oversight of its effectiveness
  - Should be recorded in the risk register
  - Maintains oversight of control performance with respect to changing risks
  - Without a control owner, controls may become outdated

- **Continuous monitoring**: Ongoing benchmarking and improvement of the
  control environment to meet organizational objectives
  - Risks and risk profiles are ever-changing
  - Controls implemented for latest risks may already be outdated

##### Doshi Review Manual
- **Key Performance Indicator (KPI)**: Metric that measures how well a process
  is doing in terms of its goals and objectives
  - Operates similarly to risk indicators but focuses on performance rather
    than risk
  - Provides warning when values exceed defined thresholds
  - Used in combination with KRIs to measure performance and mitigate risk

- **KPI vs KRI vs KCI distinction**: Critical for exam success
  - KPI: Monitors business performance targets ("Are we achieving desired
    performance levels?")
  - KRI: Monitors risk profile changes ("Is risk within tolerance?")
  - KCI: Monitors control effectiveness ("Are controls working?")
  - Senior management focuses primarily on KPIs; risk teams and auditors focus
    on KRI and KCI

- **Thresholds**: Define acceptable operating ranges for indicators
  - Values within threshold indicate acceptable performance
  - Values outside threshold require immediate attention and escalation
  - Most important aspect when developing metrics to monitor control
    effectiveness

- **Control efficiency monitoring objective**: Ensure desired metrics are
  achieved
  - Not risk management (that's KRI)
  - Not control effectiveness (that's KCI)
  - Not business goals (that's KGI)

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Measuring vulnerability management effectiveness | Track number of vulnerabilities found and remediated | Provides clear metric for program success at identifying and addressing risks |
| Evaluating security program over time | Track percentage reduction in data breaches | Measures actual risk reduction, not just activity |
| Control became outdated | Assign control owner to monitor and update | Prevents control drift and ensures ongoing effectiveness |
| Risk breaches threshold | KRI triggers alert to stakeholders | Enables proactive response before risk materializes |
| Reporting to different audiences | Tailor format and content per audience | Technical details irrelevant to non-technical stakeholders |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Error rate reaches 10% threshold | KPI provides warning for escalation | KPI monitors performance against defined limits |
| Evaluating disaster recovery readiness | Review results of tests and exercises | Demonstrates actual capability, not just documentation |
| Measuring control management effectiveness | Measure control effectiveness against business objectives | Primary KPI for control performance |
| Operational review of processing environment | User satisfaction survey | Indicates how well processes meet user expectations |
| KPI value outside threshold | Attend immediately | Leading indicator requires remedial action |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **KPIs vs KRIs vs KCIs**: KPIs measure control performance, KRIs predict
  future risks, KCIs indicate control weaknesses. Each serves a distinct
  purpose in monitoring.

- **Activity vs outcome metrics**: Counting completed activities (training
  sessions held) differs from measuring outcomes (reduction in incidents).
  Prioritize outcome-based KPIs.

- **Qualitative limitations**: Heat maps and scorecards are qualitative,
  leaving room for judgment error. Dashboards combining qualitative and
  quantitative metrics provide more comprehensive view.

- **Risk owner vs control owner**: May be same person in small organizations,
  but should be segregated when possible. Risk owner accountable for
  remediation; control owner accountable for control effectiveness.

- **Threshold confusion**: Risk tolerance threshold differs from risk appetite.
  A little beyond appetite is still within tolerance if compensating controls
  exist.

##### Doshi Review Manual
- **KPI requires immediate attention when outside threshold**: Not when
  fluctuating, within threshold, or below average

- **Most important criteria for metric effectiveness**: Must be meaningful to
  the recipient, not just complete, accurate, consistent, or cost-effective

- **Attainable feature of KPI**: Determines that KPI is realistic and based on
  important objectives (not cost-effective, repeatable, or relevant)

- **Organizations often conflate KPI, KRI, and KCI**: In practice everything
  may be called "KPI" but exam requires precise distinction

- **Optimum control level**: Balance between control effectiveness and cost of
  maintaining the control, not just highlighting ineffectiveness

#### SMART metrics for selecting key indicators

| Attribute | Definition | Application |
| --------- | ---------- | ----------- |
| Specific | Clearly understandable and concise | Avoid vague metrics like "improve security" |
| Measurable | Can be measured and quantified | Use numerical values, percentages, counts |
| Attainable | Realistic and based on goals | Set achievable targets given resources |
| Relevant | Related to specific activity or goal | Align with organizational objectives |
| Timely | Timebound and not open-ended | Define measurement periods and deadlines |

#### Control assessment techniques

| Technique | Purpose | Limitation |
| --------- | ------- | ---------- |
| Self-assessment | Engage key resources to identify overlooked issues | Subject to internal bias |
| Internal IS audit | Determine control effectiveness through independent review | Limited to known control scope |
| Vulnerability assessment | Identify known weaknesses in design, implementation, or operation | Only finds already-known vulnerabilities |
| Penetration testing | Simulate real attacks to find undiscovered vulnerabilities | Point-in-time assessment |
| Third-party assurance | Independent attestation (ISO 27001, SOC 2, PCI DSS) | More weight in building stakeholder trust |

#### Reporting formats

| Format | Best for | Characteristics |
| ------ | -------- | --------------- |
| Executive summary | Project milestones, quick updates | 1-2 pages, quantified metrics |
| Heat map | Impact vs likelihood visualization | Qualitative, 2x2 to nxn grid |
| Scorecard | Aggregated performance grades | Qualitative, simplified view |
| Dashboard | Comprehensive risk overview | Quantitative and qualitative, trend analysis |

#### Related topics

##### CRISC All-in-One Exam Guide
- Log aggregation: Provides data sources for control monitoring metrics
- SIEM systems: Enable automated correlation and alerting on control
  thresholds
- Risk register: Records control owners and KPI assignments
- Risk tolerance: Defines acceptable thresholds for KRI alerting

##### Doshi Review Manual
- **Control testing (3.11)**: Best way to determine control effectiveness is
  to test controls; testing identifies design flaws, failures, and redundancies
- **KRI monitoring (3.16)**: KRI thresholds indicate whether controls provide
  intended value; periodic monitoring addresses new risks
- **Key Control Indicators (3.19)**: KCI measures control effectiveness; KRI
  and KCI are inversely correlated
- **Risk reporting**: Enables risk owner to initiate appropriate risk response;
  should be tailored to target audience

#### SMART characteristics of good KPIs

| Characteristic | Requirement |
| -------------- | ----------- |
| Specific | Linked to a specific business goal |
| Measurable | Comparable over a period of time |
| Achievable | Realistic and based on important objectives |
| Relevant | Provides value to process owner and management |
| Timely | Enables timely response when thresholds exceeded |

Additional requirements:
- Simple enough for stakeholders to understand
- Meaningful to the recipient
- Agreed upon by relevant stakeholders and approved by senior management

#### Control monitoring and reporting

- **Role of risk practitioner**: Assist in planning, reporting, and scheduling
  tests of IS controls
  - Not responsible for implementing or operating controls
  - Not responsible for approving monitoring policy
  - Discusses noncompliance with risk owner and recommends corrective action

- **Control monitoring sources**:
  - Security Operations Centre (SOC) and Network Operations Centre (NOC)
  - Tools and software for continuous control monitoring
  - Periodic control testing
  - Control self-assessment

- **Control assessment effectiveness depends on**:
  - Accuracy of data used to evaluate controls
  - Timely reporting to management for corrective action
  - Skill set of risk practitioner to properly evaluate controls

- **Reporting formats**: Heat maps, scorecards, and dashboards
  - Risk dashboard is most suitable for senior management reporting
  - Provides high-level overview that can be easily tailored

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Performance threshold action | Outside threshold | Requires immediate escalation |
| KRI threshold revision | Periodic | As risk profile changes over time |
| Continuous monitoring scope | High-risk areas | Where impact and frequency are high |

### 3.13: Review control assessment findings for effectiveness

Guide

#### Key concepts

##### CRISC All-in-One Exam Guide
- **Control assessment**: Process of evaluating and examining the effectiveness
  and adequacy of internal controls within an organization
  - Internal controls are policies, procedures, and practices that mitigate
    risks, ensure compliance, safeguard assets, and achieve organizational
    objectives
  - Assessment determines whether controls are designed and operating
    effectively to address identified risks
  - Reviews control activities such as segregation of duties (SoD), access
    controls, documentation, and monitoring procedures

- **Control effectiveness**: Measure of how well controls achieve their
  intended purpose
  - Current risk is a more accurate measure of control effectiveness than
    inherent risk
  - Effectiveness must be evaluated periodically as threats and environments
    change
  - The control owner is responsible for determining efficacy of controls
    periodically

- **Progressive vs regressive testing**: Two approaches to control testing
  - Progressive testing begins with requirements and looks for flaws
  - Regressive testing works backward from expected results and known issues to
    identify causes

- **Key Control Indicators (KCIs)**: Metrics measuring control effectiveness
  - Indicate weaknesses that may increase probability of risk events
  - Track performance of control actions relative to tolerance
  - Provide insight into effectiveness of controls to keep risk within
    acceptable levels

##### Doshi Review Manual
- **Control assessment**: Process of evaluating controls through testing, audit,
  or self-assessment to determine whether they meet their intended objectives
  - Prime objective: evaluate effectiveness, efficiency, and adequacy
  - Advise risk owner of any gaps identified
  - Test at frequent intervals to verify ongoing performance

- **Control effectiveness**: Degree to which a control achieves its stated
  objectives in reducing likelihood or impact of risk
  - Best determined by reviewing test results against desired objectives
  - Must balance effectiveness with control cost (optimum level)
  - Changes in effectiveness directly impact the organization's risk profile

- **Result of control assessment**: Effectiveness depends on three parameters:
  - Accuracy of data on which controls are evaluated
  - Timely reporting to management for corrective action
  - Skill set of risk practitioner to properly evaluate controls

- **Key Control Indicators (KCI)**: Metrics measuring control effectiveness
  - Also called control effectiveness indicators
  - Provide insight into ongoing adequacy of controls
  - Inversely correlated with KRI (effective controls = risk within limits)
  - Tolerance levels based on criticality of protected assets

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Determine control effectiveness over time | Continuous monitoring | Ongoing monitoring identifies issues as they arise and tracks trends |
| Identify control deficiencies | Internal audit | Comprehensive review of controls, policies, and procedures to find gaps |
| Identify issues shortly after implementation | Ad hoc vulnerability scans | Quick identification of problems when control is newly deployed |
| Verify control logs for unauthorized access | Review control logs | Best way to determine if control is working as intended |
| Evaluate overall control environment | Third-party assurance (SOC 2, ISO 27001) | Independent assessment carries more weight with stakeholders |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Monitoring indicates noncompliance | Discuss with risk owner; recommend review of controls and additional controls if needed | Risk owner responsible for ensuring risk managed to acceptable level |
| Security exception identified | Validate exception first to rule out false positives | Prevents wasted effort on non-issues |
| Audit finding identified | Create risk mitigation plan with corrective action | Addresses root cause and closes finding |
| Control deficiency suspected | Review defined control objectives first | Objectives define success criteria; unmet objectives indicate deficiency |
| New control implemented | Test to validate effectiveness | Each new control must be evaluated for both effectiveness and additional vulnerabilities |

#### Control assessment techniques

- **Self-assessments (MSIIs)**: Workshops with key resources to identify
  overlooked issues
  - Engage personnel involved in regular system operations
  - Facilitate open discussion without judgment or finger-pointing
  - Can adopt industry standards (NIST, COBIT, ISO 27001) or brainstorm
    organization-specific risks

- **Internal IS audit**: Collaborate with auditors to provide evidence;
  recommendations are objectively presented to management

- **Vulnerability assessment**: Identifies weaknesses in design,
  implementation, or internal controls
  - Uses tools to find misconfigurations or missing updates
  - Limitation: only identifies known vulnerabilities, not undiscovered ones

- **Penetration testing**: Simulates real attacks to find business logic errors
  and cascading vulnerabilities
  - White-box: all information provided to testers
  - Gray-box: some information provided (e.g., user credentials)
  - Black-box: no information provided to testers

- **Third-party assurance**: Independent external auditor reviews controls
  against standards (ISO 27001, PCI DSS, HITRUST CSF, SSAE 18 SOC 2/3)
  - Provides certificate or attestation report with findings
  - Carries more weight due to independence

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Annual reviews are insufficient for high-risk controls**: Continuous
  monitoring is required for controls addressing high-risk threats

- **Vulnerability assessments have blind spots**: They only detect known
  vulnerabilities; penetration testing is needed to find undiscovered issues

- **Self-assessments require psychological safety**: Without judgment-free
  environments, participants may not disclose overlooked issues

- **Control testing is the control owner's responsibility**: The risk
  practitioner advises but the control owner determines efficacy

##### Doshi Review Manual
- **Test results vs. other metrics**: Cost of implementation, failure
  notification capability, or number of vulnerabilities addressed do not
  determine effectiveness--only test results against desired objectives

- **Optimum vs. maximum control**: Optimum control balances effectiveness with
  cost; cost should be less than perceived risk. Maximum control may be
  cost-prohibitive

- **Control monitoring vs. testing**: Monitoring is ongoing and continuous;
  testing is generally ad hoc. Both serve different purposes in assessing
  effectiveness

- **KPI vs. KRI vs. KCI confusion**: KPIs measure business performance, KRIs
  monitor risk profile changes, KCIs measure control effectiveness. Risk team
  and internal audit focus on KRI and KCI

- **Decreased cost does not indicate effectiveness**: Reduced control cost
  alone does not prove the control works; test results required

#### Managing assessment findings

| Approach | Purpose | Notes |
| -------- | ------- | ----- |
| Configuration management | Maintain baseline/standard controls | Reduces complexity; verify teams follow baselines |
| Release management | Coordinate development to production moves | Includes end user testing before release |
| Exception management | Document policy deviations | Review exceptions at least annually |
| Change management (CAB) | Formal review and approval of changes | Verifies changes don't negatively affect risk profile |

#### Reporting considerations

- **Audience**: Match report content to recipient's role and concerns
- **Actionability**: Ensure metrics are actionable, not just informational
- **Format**: Use appropriate format (executive summary, heat map, scorecard,
  dashboard) based on audience preference
- **Source integrity**: Verify confidence in data sources before reporting
- **Cadence**: Establish agreed reporting frequency

#### Related topics

##### CRISC All-in-One Exam Guide
- **Key Risk Indicators (KRIs)**: Predict risks that may breach thresholds;
  complement KCIs in monitoring effectiveness
- **Key Performance Indicators (KPIs)**: Measure control performance; example
  is reduction in phishing emails after implementing a new tool
- **SMART metrics**: Indicators should be Specific, Measurable, Attainable,
  Relevant, and Timely
- **Three Lines of Defense**: Third LoD (internal/external audit) provides
  independent assessment of control effectiveness

##### Doshi Review Manual
- **Risk profile**: Control effectiveness changes directly impact the
  organization's overall risk status; must be kept updated

- **Three lines of defense**: Third line (audit) provides control testing and
  attestation; second line provides consulting and monitoring

- **Risk register**: Documents control status, corrective actions, and residual
  risk; updated based on assessment findings

- **Internal audit function**: Role is monitoring, evaluating, examining, and
  reporting on controls; provides recommendations for enhancement

- **Risk reporting**: Must include control effectiveness because changes impact
  risk profile; dashboards, heat maps, and scorecards are common formats

- **Corrective action**: Risk owner receives findings and initiates appropriate
  response; risk mitigation plan used to address audit findings

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Control assessment frequency | Periodic intervals | Determined by risk level and regulatory requirements |
| KCI tolerance levels | Asset-specific | Based on criticality of information assets being protected |
| Continuous monitoring | High-risk areas | Where impact and frequency of occurrence are both high |
| First step for exceptions | Validate to rule out false positives | Before escalating or remediating |

### 3.14: Report on risk profile, control performance, and trends to stakeholders
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Risk profile**: The overall risk exposure of an organization to any type
  of risk. Factors affecting the risk profile include new regulations, changes
  in underlying technology, business objective shifts, mergers and
  acquisitions, and competitive landscape changes.
  - IT risk profile specifically covers identified IT risks including emerging
    threats, malicious actors, incidents, privacy framework changes, new or
    acquired assets, and supply chain risks
  - Risk profiles are ever-changing; risks from a year ago may no longer be
    relevant while recently implemented controls may become outdated

- **Key indicators**: Metrics reported in dashboards that drive stakeholder
  decisions
  - **Key Performance Indicators (KPIs)**: Measure control performance; should
    align with organizational objectives and risk appetite (e.g., reduction in
    phishing emails after implementing a new tool)
  - **Key Risk Indicators (KRIs)**: Predict risks that could breach defined
    thresholds; monitor trends, determine control effectiveness, alert
    stakeholders when risk exceeds thresholds (e.g., employees repeatedly
    failing phishing tests)
  - **Key Control Indicators (KCIs)**: Measure control effectiveness to
    indicate weaknesses that may increase risk probability (e.g., lack of
    controls to block phishing emails)

- **SMART metrics**: Criteria for selecting key indicators
  - Specific: Clearly understandable and concise
  - Measurable: Can be quantified
  - Attainable: Realistic and based on goals
  - Relevant: Tied to specific activity or goal
  - Timely: Time-bound and not open-ended

- **Reporting considerations**: Key aspects to address when preparing reports
  - Audience: Identify the right recipients
  - Actionability: Ensure metrics are actionable
  - Format: Use the audience's preferred format
  - Succinctness: Show only key information relevant to the audience
  - Source: Verify data source integrity
  - Tailoring: Customize for primary stakeholders
  - Timeframe: Present relevant time periods
  - Inferences: Enable audience to draw key conclusions
  - Cadence: Agree on reporting frequency

##### Doshi Review Manual
- **Risk reporting**: Process of communicating risk assessment results to risk
  owners and stakeholders to enable informed decisions and corrective action
  - Objective: help people make informed decisions and take necessary action
  - Content should be tailored to the target audience
  - Closely associated with risk monitoring

- **Risk profile**: Overall risk status the organization is exposed to
  - Must be kept updated with new and emerging risks
  - Updated in the risk register to reflect current status
  - Changes should be reported to senior management for educated
    decision-making
  - Factors that change risk profile: new technologies, business process
    changes, regulatory changes, market demand, competitor policies

- **Control performance reporting**: Communicating control effectiveness
  through KRIs
  - KRIs within threshold indicate controls are effective
  - KRIs exceeding threshold indicate additional controls may be required
  - Control monitoring is ongoing; control testing is ad hoc

- **Lead and lag indicators**:
  - Lead indicators: forward-looking, provide warning signals for emerging risk
  - Lag indicators: backward-looking, provide trends and historical data
  - Both are required to improve risk response

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Presenting risk to board of directors | Use executive summary or dashboard with qualitative and quantitative metrics | Board needs concise, actionable information aligned with business objectives |
| Tracking control effectiveness over time | Create dashboards with trend identification and anomaly detection | Dashboards combine qualitative and quantitative metrics on recurring cadence |
| Communicating security posture to non-technical stakeholders | Translate technical risks to business impact using risk appetite context | Senior management needs risks framed in terms of business objectives |
| Reporting on specific project milestone | Use executive summary with quantified metrics | Showcases effectiveness without excessive detail |
| Comparing risk levels across business units | Use heat maps or scorecards | Visual representation enables quick comparison of impact and likelihood |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Report risk to senior management | Use dashboard | Provides high-level overview that can be easily understood and tailored |
| Present current risk profile | Use risk register dashboard | Gives complete picture of organization's risk profile |
| Communicate current state of risk | Use KRI measurement results | Most useful data for management to determine current risk state |
| Tailor report content | Consider target audience | Ensures information is presented in understandable and usable form |
| Report KRI reaching threshold | Alert business process owner first | Owner determines risk response and evaluates control effectiveness |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **KRIs without actionability are useless**: KRIs that provide inferences but
  are not actionable will not be useful to senior management. Always develop,
  socialize, and report actionable KRIs.

- **Qualitative formats have limitations**: Heat maps and scorecards are
  qualitative, which leaves room for interpretation error. Dashboards are
  preferred because they combine qualitative and quantitative metrics.

- **Wrong audience equals wasted effort**: Reporting phishing attempts to the
  head of physical security provides no value. Always match reports to the
  stakeholder's area of responsibility.

- **Risk profile is dynamic**: The risk profile changes continuously; reports
  must reflect current state, not historical snapshots that no longer apply.

- **Confusing KPIs, KRIs, and KCIs**: KPIs measure performance, KRIs predict
  risk events, KCIs measure control effectiveness. Each serves a distinct
  purpose in reporting.

##### Doshi Review Manual
- **Dashboard vs balanced scorecard**: Dashboard is for risk reporting;
  balanced scorecard monitors IT performance but is not suitable for reporting

- **Risk register vs risk profile**: Risk register is the document that tracks
  risks; risk profile is the overall status derived from it

- **Control monitoring vs testing**: Monitoring is ongoing and validates
  controls continuously; testing is ad hoc. Exam questions prefer monitoring
  for ongoing validation

- **KRI alerts go to process owner first**: When KRI reaches threshold, report
  to business process owner before senior management. Owner evaluates and
  determines response

- **Risk reporting objective**: Primary objective is to provide information to
  risk owner for responding to risk, not compliance or assurance purposes

#### Reporting formats

| Format | Characteristics | Best use |
| ------ | --------------- | -------- |
| Executive summary | 1-2 pages, concise, often sent in email body or attachment | Project milestones with quantified metrics |
| Heat maps | Graphical 2x2, 3x3, or nÃ—n grid; color-coded; y-axis shows impact, x-axis shows likelihood | Qualitative risk comparison |
| Scorecards | Aggregated performance with grades per area | Qualitative assessment across domains |
| Dashboards | Collection of metrics and indicators; qualitative + quantitative; recurring cadence | Trend identification, analysis, anomalies; preferred format |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Risk appetite and tolerance**: Reports should contextualize risk profile
  against defined appetite and tolerance thresholds to enable decision-making
- **Control assessment techniques**: Self-assessments, internal audits,
  vulnerability assessments, penetration testing, and third-party assurance
  feed data into risk reports
- **SIEM systems**: Translate logs into management reports and dashboards;
  support compliance requirements for log retention
- **Three lines of defense**: Reporting structure should align with governance
  model where first line owns risk, second line monitors, third line provides
  assurance

##### Doshi Review Manual
- **Risk register**: Primary document for tracking risk profile changes and
  driving risk response (Objective 2.8)

- **Key risk indicators**: Measure control effectiveness and alert when
  controls fail to provide intended value (Objective 3.18)

- **Control monitoring**: Validates controls on ongoing basis; results feed
  into risk reporting (Objective 3.15)

- **Risk culture**: Open communication on risk provides transparency to
  stakeholders and enables informed decisions (Objective 1.4)

- **Control assessment types**: IS audit, vulnerability assessment, and
  penetration testing provide data for control performance reporting
  (Objective 3.16)

---

## Domain 4: Information Technology and Security

**Weight: 20%**

#### Limits and defaults

| Item | Value | Notes |
| ---- | ----- | ----- |
| Heat map axes | Probability x Impact | Score = probability weight x impact weight |
| Common report formats | Heat maps, scorecards, dashboards | Used for risk reporting |
| KRI monitoring frequency | Periodic intervals | Risk profile changes over time |
| KRI review by | Independent team or independent reviewer | Ensures unbiasedness |

### 4.1: Enterprise architecture and IT operations management
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Enterprise architecture (EA)**: Foundation for running a business
  effectively by ensuring people, processes, technology, and data work
  together to produce value
  - Four major domains: business, application, data, and technology
    architecture
  - Technology architecture shows current IT state, establishes future
    vision, and assists transition with minimal disruption

- **Technology architecture**: Describes underlying infrastructure needed to
  run business applications
  - Components: networking devices, storage systems, hardware, software
  - Goal for risk managers: ensure transitions happen with minimal disruption
    since IT systems are interdependent

- **EA frameworks**: Common examples include:
  - The Open Group Architecture Framework (TOGAF)
  - Zachman Framework
  - Department of Defense Architecture Framework (DODAF)
  - Federal Enterprise Architecture Framework (FEAF)
  - Sherwood Applied Business Security Architecture (SABSA)

- **Capability Maturity Model (CMM)**: Structured approach for assessing and
  improving process maturity
  - Developed in 1986 based on US Department of Defense contractor data
  - Five maturity levels from ad hoc to optimized
  - CMMI (2006) enhanced version developed by Carnegie Mellon SEI

- **Change management**: Ensures changes to IT systems are controlled and
  systematic
  - Minimizes impact on users and systems
  - Maintains record of changes
  - Change Advisory Board (CAB) reviews and approves changes
  - Verifies changes will not negatively affect risk profile or security

- **IT asset management**: Process of identifying and tracking hardware and
  software assets
  - Includes inventory, performance monitoring, and effective utilization
  - Critical for managing IT resources effectively

- **Incident management**: Restoring normal service as quickly as possible
  after an incident
  - Identify, prioritize, and resolve incidents
  - Minimize impact on users and systems
  - Distinct from problem management (root cause analysis)

##### Doshi Review Manual
- **Enterprise Architecture (EA)**: Defines the structure and operations of an
  organization, analogous to how conventional architecture defines rules for
  building construction
  - Determines how an organization achieves current and future objectives
  - Helps risk practitioners identify linkages between IT and organizational
    objectives
  - Components include network, hardware, software, human roles, data flows,
    and IT infrastructure

- **EA objectives**:
  - Understand the current state of IT
  - Understand vision for a future state of IT
  - Design strategy to move from current state to future state
  - A complete EA must include future-state description

- **EA contents**: Goals of the architecture, input/process/output definitions,
  required skill sets, training, and governance

- **Common EA frameworks**:
  - **TOGAF**: The Open Group Architecture Framework
  - **Zachman Framework**: General-purpose EA framework
  - **DODAF**: Department of Defense Architecture Framework (military)
  - **FEAF**: Federal Enterprise Architecture Framework (civilian agencies)

- **Security architecture**: Provides overview and relationships between
  systems; primary purpose is to align security strategy between functional
  areas and external parties
  - Most useful for managing complex security deployments
  - Enables risk practitioners to evaluate control appropriateness

- **Capability Maturity Model (CMM)**: Methodology for developing and refining
  processes, focusing on continuous improvement
  - Level 0 (Incomplete): Process not implemented or does not achieve purpose
  - Level 1 (Performed): Process achieves intended purpose
  - Level 2 (Managed): Process is planned, monitored, and controlled
  - Level 3 (Established): Well-defined, documented process management exists
  - Level 4 (Predictable): Process operates within defined parameters/limits
  - Level 5 (Optimized): Continuous improvement toward current and future goals

- **Configuration management**: Process of managing and updating system
  features, parameters, and functional settings
  - Most susceptible to introduction of vulnerabilities
  - Misconfiguration and missing updates are primary risk vectors

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| New software deployment across organization | Configuration management to set baseline controls | Preventative control ensures no unapproved software installed |
| Production code changes | Change management with CAB approval | Changes must be tested in non-production before rollout |
| Ensuring data integrity during system changes | Implement change management procedures | Controls unauthorized or malicious changes |
| Security vulnerability in one system | Assess all interconnected system components | IT systems are interdependent; one issue can affect others |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Installing new equipment | Conduct risk assessment first | Identifies potential vulnerabilities before deployment |
| Managing complex security deployments | Develop security architecture | Provides system overview and relationships |
| Third-party application development | Conduct security code review for entire application | Detects malware including backdoors |
| Untested patch must be deployed | Have reliable rollback plan | Enables recovery if patch causes interoperability issues |
| Missing validation checks on data input | Implement input validation | Prevents SQL injection and similar attacks |
| Assessing risk management process maturity | Use Capability Maturity Model | Identifies gaps between current and desired state |
| BYOD environment with data security concerns | Implement virtualized desktop | Prevents data copying to personal device space |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Incident vs. problem management**: Incident management restores service
  quickly; problem management identifies and resolves root causes. Do not
  confuse them.

- **CMM vs. CMMI**: CMM is the original 1986 framework; CMMI (2006) is the
  enhanced version that largely replaced it. Exam may reference either.

- **Technology architecture scope**: Includes physical entities (wires,
  devices, storage, hardware) and software, not just digital infrastructure.

- **Configuration management vs. change management**: Configuration sets
  initial baselines; change management controls modifications after baseline
  is established.

- **Defined process maturity**: The "Defined" level is proactive, well
  characterized, and organization-wide. "Unpredictable" is not a property of
  the Defined level.

##### Doshi Review Manual
- **Uncertified hardware = unknown risk**: Hardware not certified by vendor or
  manufacturer represents unknown risk, not low or high risk
- **Performance is the key CMM dimension**: When using a capability maturity
  model, performance (achieving the process objective) is the most important
  criterion
- **Maturity model vs audit**: Maturity models enable peer review of risk
  management; internal audit is less effective for benchmarking against peers
- **Patch testing vs rollback**: Testing is most important before deployment,
  but rollback plans mitigate untested emergency patches
- **Error messages should not reveal details**: Error messages must use codes
  understandable only by IT staff; revealing details aids attackers

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Domain 4 exam weight | 22% | Approximately 33 questions |
| CMM development year | 1986 | Based on US DoD contractor study |
| CMMI development year | 2006 | Carnegie Mellon SEI enhancement |
| CMM maturity levels | 5 | Initial through Optimized |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| CMM levels | 0-5 | 0=Incomplete, 5=Optimized |
| Mature organization traits | Prevent, detect sooner, recover rapidly | Key outcomes of high maturity |
| Security code review scope | Entire application | Required for third-party developed applications |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Network architecture**: TCP/IP model (5 layers), OSI model (7 layers),
  networking devices (repeaters, bridges, switches, routers, gateways)
- **Security infrastructure**: Firewalls, IDS/IPS, VPNs, wireless security
  (WPA2)
- **Cloud computing**: IaaS, PaaS, SaaS service models; public, private,
  hybrid, community deployment models
- **SDLC**: System Development Life Cycle phases connect to IT operations
  through implementation and maintenance
- **COBIT and ITIL**: BAI06 Managed IT Changes (COBIT) equivalent to ITIL
  Change Management

##### Doshi Review Manual
- **Patch management**: Rollback plans address untested emergency patches;
  testing is required before production deployment
- **Secure coding practices**: Input validation, data masking, encryption,
  digital certificates, middleware isolation
- **Platforms and operating systems**: Trusted vendors, default account
  changes, licensed software, OS hardening
- **SDLC integration**: Risk assessment at each phase is most cost-effective
  approach; internal controls incorporated during design phase
- **Legacy systems**: Control through middleware, network isolation, and secure
  communication channels

### 4.2: Project and program management principles
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Project risk**: Risk associated with achieving project objectives --
  delivering on time, within budget, and meeting stakeholder requirements
  - External factors: market condition changes
  - Internal factors: development delays, unforeseen technical issues
  - Management approach: identify potential risks, assess likelihood and
    impact, develop mitigation plans

- **Program/project risk**: Risk of failure due to lack of commitment and
  accountability from project stakeholders

- **IT program and project delivery risk**: Projects not delivered as agreed
  with internal and external stakeholders, leading to inconsistency with
  overall strategy

- **RACI matrix**: Tool for determining roles and responsibilities across
  project stakeholders
  - **Responsible**: Individual or team performing the work
  - **Accountable**: Individual providing resources and answerable for project
    success; only one person per task
  - **Consulted**: Subject matter experts with domain knowledge; two-way
    communication
  - **Informed**: Stakeholders affected by outcomes; one-way communication

- **Change Advisory Board (CAB)**: Cross-functional body that reviews and
  approves changes to production systems
  - Includes representatives from IT, security, engineering, and other
    relevant departments
  - Verifies changes will not negatively affect risk profile or security
  - Ensures changes are formally requested, justified, and approved
  - Balances required changes with system reliability and stability
  - Emergency changes follow the same process for visibility

- **Business case**: Required justification for risk response decisions
  - Includes cost-benefit analysis of proposed approach
  - Contains return-on-investment (ROI) thesis for senior management
    decision-making

##### Doshi Review Manual
- **Project**: A sequence of activities to achieve a required outcome; unique,
  time-bound, and produces something that did not previously exist
- **Program**: A collection of related projects; a project is a subset of a
  program delivering a tangible single output
- **Project management**: Formal process of organizing, administering, and
  implementing a project to deliver value through specific deliverables

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Complex system migration | Parallel changeover | Safe rollback, training opportunity, minimal downtime despite higher cost |
| Independent modular update | Phased changeover | Reduced risk of full outage, modular rollback possible |
| Minor non-critical change | Abrupt changeover | Fast and cost-efficient when rollback is easy |
| Emergency production fix | Submit to CAB with expedited review | Maintains visibility and stakeholder awareness |
| Unclear project requirements | Address during initiation phase | Prevents downstream failures from inadequate foundation |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Determining project progress in scope, schedule, budget | Use Earned Value Analysis | EVA provides comprehensive variance analysis and forecasting |
| Preventing scope creep | Define requirements during feasibility/design phase | Early requirement freeze prevents constant changes |
| Go/no-go decision making | Conduct risk analysis of alternatives | Project team selects best approach based on risk analysis |
| Implementing risk-based approach | Involve business representative | Ensures accurate risk assessment and appropriate mitigation |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Project risk vs SDLC risk confusion**: Project risk focuses on meeting
  objectives (time, budget, requirements); SDLC risk focuses on the
  development process itself (coding errors, testing gaps). Both are
  interrelated -- SDLC issues like insufficient testing cause project delays.

- **Abrupt changeover appears efficient but is riskiest**: Should never be
  used when changes affect critical business processes; complete rollback is
  required if issues occur.

- **Post-implementation review timing**: Must be conducted timely with all
  relevant stakeholders, not just developers or risk managers. Document should
  remain live and be updated as new learnings emerge.

- **CAB composition**: Must include all relevant stakeholders, not just IT.
  Security, engineering, and business representatives are required for
  effective change governance.

- **Parallel changeover hidden cost**: Data consistency between old and new
  systems creates ongoing maintenance overhead beyond infrastructure costs.

##### Doshi Review Manual
- **Risk assessment timing**: Must be conducted at every SDLC stage, not just
  once before the project
- **Internal controls**: Incorporate during design phase, not later stages
- **Business case retention**: Retain until end of application life, not just
  until implementation
- **CPM vs PERT**: CPM uses single scenario; PERT uses three scenarios and is
  more accurate
- **Gantt vs EVA**: Gantt charts track progress; EVA provides cost and schedule
  variance analysis
- **User sign-off**: Required before changeover; user department assumes
  ownership

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| RACI accountable role | 1 per task | Only one person can be accountable |
| Exception review frequency | Annual minimum | Granted exceptions must be reverified at least annually |
| Test environment requirement | Match production | Must reflect production as closely as possible |
| Code freeze timing | Before production push | Reduces likelihood of untested code in production |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Minimum critical paths per project | 1 | Every project has at least one critical path |
| Slack time on critical path | 0 | No buffer available for critical path activities |
| PERT scenarios | 3 | Optimistic, pessimistic, most likely |

#### Related topics

##### CRISC All-in-One Exam Guide
- **SDLC phases**: Initiation, development/acquisition, implementation,
  operation/maintenance, disposal -- each phase has specific project risks
  requiring different management approaches
- **Control implementation techniques**: Parallel, phased, and abrupt
  changeover methods directly affect project risk profiles
- **Post-implementation reviews**: Key questions include whether business
  objectives were met, requirements satisfied, and project completed on time
  and within budget
- **Three Lines of Defense**: Project governance aligns with 3LoD model where
  first line owns risk, second line monitors compliance, third line audits
- **Enterprise risk management**: Project risk management must integrate with
  ERM program under senior management sponsorship

##### Doshi Review Manual
- **Risk tolerance**: Acceptable deviation from defined project budget
- **Change management**: Process to handle requirement changes; define during
  feasibility phase
- **Configuration management**: Baseline for system features including security

#### SDLC models

- **Waterfall**: Sequential approach best suited when requirements are
  well-defined and stable
  - Most commonly adopted for business applications
  - Identifies mistakes early rather than during final acceptance testing
  - Useful when prototypes are needed to understand design and requirements
- **Agile**: Iterative approach producing releasable software in short cycles
  - Minimal emphasis on formal documentation
  - Systematic review after each iteration to identify improvements
  - Risk: Insufficient documentation; lack of formal paper-based deliverables

#### SDLC phases

| Phase | Description | Risk considerations |
| ----- | ----------- | ------------------- |
| Initiation/Feasibility | Define objective, purpose, scope; finalize design; define change management process | Prevent scope creep; freeze requirements early |
| Development/Acquisition | Evaluate alternatives; develop or acquire system | Address skilled resource availability |
| Implementation | Testing, migration, security configuration | Address migration risk; verify security features |
| Operations/Maintenance | Regular updates and system upkeep | Ongoing monitoring and control |
| Disposal | Discard obsolete systems; archive, sanitize, destroy | Data sanitization; hardware/software disposal |

#### Success factors for effective project management

- Clear definition of required outcome
- Clearly defined scope and objectives to prevent scope creep
- Accountable individual with appropriate experience and authority
- Resource identification during planning stage for cost efficiency
- Monitoring and control procedures at different milestones

#### Project risks

- **Scope creep**: Unclear or ever-changing requirements; most common cause of
  project failure
- Unavailability of adequate resources
- Unrealistic deadlines impacting quality
- Lack of monitoring and controlling processes
- Insufficient senior management support

#### Risk assessment considerations

- Confidentiality and availability requirements
- Regulatory and legal impact (privacy laws)
- Architectural and technological risks
- Secure development process usage
- Security training for developers and staff

#### Project management tools

| Tool | Purpose | Key feature |
| ---- | ------- | ----------- |
| Earned Value Analysis (EVA) | Monitor scope, schedule, budget | Forecasts completion date and final cost; analyzes variances |
| Critical Path Method (CPM) | Estimate project duration | Identifies longest path of dependent activities; zero slack time |
| PERT | Estimate project duration | Uses three scenarios: optimistic, pessimistic, most likely; more accurate than CPM |
| Gantt Chart | Track progress and milestones | Shows whether project is delayed, ahead, or on schedule |

#### Project closeout

- Record all deliverables
- Centralize documentation
- Hand over to operations team
- Evaluate project performance
- Document lessons learned for future projects

#### Changeover techniques

| Technique | Description | Risk level |
| --------- | ----------- | ---------- |
| Parallel | Run old and new systems simultaneously until confidence in new system | Lowest; greatest redundancy |
| Phased | Implement changes gradually, replacing old phases with new | Moderate |
| Abrupt (direct cutover) | Implement new system from cut-off date, discontinue old immediately | Highest; no rollback option |

### 4.3: Disaster recovery and business continuity management
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Business continuity (BC)**: Ability of an organization to continue
  operating critical business functions during and after a disruption
  - Purpose: identify potential threats to operations and develop strategies
    to ensure critical processes continue or resume quickly
  - Encompasses entire organization: staffing, facilities, supply chain,
    communication with stakeholders

- **Business continuity plan (BCP)**: Formal plan prepared against disruption
  or disaster
  - Inputs result from Business Impact Analysis (BIA)
  - Resiliency is the overarching goal
  - Must be tested regularly to assess effectiveness

- **Disaster recovery (DR)**: Ability to restore data and applications that
  run the business
  - Focuses on IT infrastructure: data centers, servers, technology
  - Measures how quickly data and applications can be recovered
  - DR is a subset of BC planning

- **Enterprise resiliency**: Ability to withstand threats and disruptions with
  minimum impact and recover quickly
  - Three components: business continuity planning, disaster recovery
    planning, crisis management planning
  - Resiliency prevents or mitigates failure; recovery restores after failure
  - Reliability is an outcome of a resilient system

- **Recovery point objective (RPO)**: Maximum acceptable data loss following
  an unplanned event
  - Backward-looking metric (measures data loss before the event)
  - Lower RPO requires more frequent backups

- **Recovery time objective (RTO)**: Maximum time a business process can
  remain unavailable before significant impairment
  - Forward-looking metric (measures downtime after the event)
  - Lower RTO requires redundant infrastructure or parallel systems

- **Maximum tolerable downtime (MTD)**: Total time stakeholders will accept
  for a business process outage, including all impact considerations

##### Doshi Review Manual
- **Business continuity plan (BCP)**: Documented processes to prevent, mitigate,
  and recover from disruption. BCP is a continuous process of implementing
  controls to prevent or mitigate incident impact.
- **Disaster recovery plan (DRP)**: Subset of BCP focused on restoring
  operations after business processes are impacted. Activated only when
  preventive measures have failed.
- **Business impact analysis (BIA)**: Process to determine critical assets and
  processes by analyzing disruption impact over time. Must be conducted before
  developing detailed BCP. Determines incremental cost of losing different
  systems.
- **Recovery time objective (RTO)**: Extent of acceptable system downtime. A 2-hour
  RTO means the organization will not be overly impacted if systems are down
  for up to 2 hours.
- **Recovery point objective (RPO)**: Extent of acceptable data loss. A 2-hour
  RPO means the organization can tolerate losing up to 2 hours of data.
- **Disaster tolerance**: Organization's tolerance for IT facility
  non-availability. Low RTO/RPO indicates low disaster tolerance.

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Data center hit by hurricane | Activate DR plan to restore from backups or offsite storage | DR handles IT infrastructure recovery |
| Power outage prevents system access | Activate BC plan with remote work or secondary site procedures | BC maintains entire organization operations |
| Prioritizing recovery between applications | Compare RTOs; shorter RTO means higher priority | RTO indicates business criticality |
| Determining backup frequency | Use RPO as guide; 4-hour RPO needs backups at least every 4 hours | RPO defines acceptable data loss window |
| Developing recovery strategy | Start with BIA to identify RPO, RTO, MTD for critical systems | BIA provides inputs for recovery planning |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| RTO 72 hours, RPO 0 hours | Warm site with synchronous backup | Meets both requirements cost-effectively |
| Critical monitoring system | Low RTO (zero or near-zero) | Cannot afford downtime |
| Widespread natural disaster | Allocate resources at different geographic locations | Avoids single point of failure |
| BCP not tested | Test results not documented | Cannot evaluate BCP effectiveness |
| Annual risk assessment completed | Review existing BCP for adequacy | Ensure BCP aligns with latest risk assessment |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **DR and BC are not interchangeable**: DR focuses on IT systems; BC focuses
  on entire organization operations including people, facilities, and
  communication

- **Cannot prevent all disasters**: BCM goal is continued operation during
  disruption, not prevention of all possible risks

- **Lower recovery objectives cost more**: Maintaining low RPO/RTO requires
  expensive infrastructure (frequent backups, redundant servers)

- **Risk practitioner does not set RPO/RTO**: Business owners determine what
  is critical; risk practitioner works with them but does not make these
  decisions independently

- **Determining RPO/RTO is only the start**: Must conduct DR tests such as
  restoring databases from backup and serving production traffic to validate
  backups work

- **RPO looks backward, RTO looks forward**: RPO measures acceptable past data
  loss; RTO measures acceptable future downtime

##### Doshi Review Manual
- **DRP vs BCP scope**: DRP is a subset of BCP, not separate. BCP covers
  prevention and mitigation; DRP covers restoration after failure.
- **Human life priority**: Protection of human life takes precedence over all
  other BCP elements. Evacuation plans are critical.
- **Outdated BCP**: An outdated plan is the greatest concern for BCP
  effectiveness - it may not support current business goals or reflect current
  technology.
- **BIA before DRP**: Developing DRP without BIA is a major risk - critical
  assets may not be covered.
- **Testing purpose**: Main reason for testing BCP is to identify limitations,
  not to train employees or ensure all scenarios are covered.
- **Process owner involvement**: Most important factor for successful BCP
  development - they identify critical processes, dependencies, and RTO
  requirements.
- **Crisis declaration**: BCP must define who can declare a disaster and under
  what conditions. Without this, DRP execution is adversely impacted.
- **Integrated testing**: BCP and DRP testing should be integrated to validate
  assumptions (e.g., work-from-home capability).

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| RPO direction | Backward-looking | Measures data loss before event |
| RTO direction | Forward-looking | Measures downtime after event |
| MTD relationship | MTD >= RTO | MTD includes total outage tolerance |

Example application comparison:

| Application | RPO | RTO | MTD | Priority |
| ----------- | --- | --- | --- | -------- |
| App A | 4 hours | 8 hours | 12 hours | Higher (shorter RTO) |
| App B | 6 hours | 12 hours | 16 hours | Lower |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Critical system RTO | Zero or near-zero | Cannot afford downtime |
| Critical data RPO | Zero or near-zero | Cannot afford data loss |
| BCP review frequency | After each risk assessment | Ensures alignment with current risks |
| Backup site distance | Different geographic zone | Avoids shared disaster risk |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Business impact analysis (BIA)**: Identifies RPO, RTO, MTD for critical
  applications; serves as initial point for DR planning; supports risk
  practitioner in recommending risk response

- **Risk assessment**: Identifies threats and likelihood; distinct from BIA
  which focuses on recovery speed rather than threat identification

- **Incident response**: Related but separate; focuses on responding to
  security incidents rather than recovering from disasters

- **Data backup and restoration**: Technical implementation supporting RPO/RTO
  requirements; must be tested regularly

- **Resiliency vs recovery**: Resiliency keeps systems from complete failure;
  recovery restores after failure has occurred

##### Doshi Review Manual
- **Risk assessment**: BCP should be reviewed for adequacy after each risk
  assessment to incorporate worst-case scenarios.
- **Information security during recovery**: BCP must specify required security
  level during recovery - may be same, lower, or higher than normal operations.
- **Incident management**: Structured incident response complements BCP/DRP by
  providing detection, escalation, and root cause analysis.
- **Cloud service providers**: Evaluate CSP's disaster recovery and business
  continuity arrangements as part of due diligence.

#### Recovery site types

| Site type | Characteristics | Best for |
| --------- | --------------- | -------- |
| Hot site | Fully operational, immediate failover, costly | Low RTO, critical systems |
| Warm site | Partially equipped, moderate recovery time | Moderate RTO (e.g., 60 hours) |
| Cold site | Basic infrastructure only, longest recovery | High RTO, non-critical systems |

#### BCP phases

1. Conduct risk assessment and business impact analysis
2. Develop and document response and recovery strategy
3. Train staff on response and recovery procedures
4. Test response and recovery plans
5. Audit response and recovery plans

#### BCP content requirements

- Written in simple, understandable language
- Clear responsibilities and accountability for each individual
- Designated person responsible for declaring a disaster
- Uniform structure across unit-level plans
- Offsite copy of the plan
- Backup procedures for critical operations
- Shadow file processing for time-sensitive data

#### RTO and RPO relationships

| Condition | Implication |
| --------- | ----------- |
| Low RTO | Critical systems, requires hot site, higher maintenance cost |
| High RTO | Non-critical systems, cold site acceptable, lower cost |
| Low RPO | Critical data, requires data mirroring/synchronization, higher backup cost |
| High RPO | Less critical data, periodic backups sufficient |
| Zero RPO | Synchronous data replication required |

#### BIA objectives

- Determine critical processes for prioritized prevention/response
- Determine disruption impact over time
- Raise employee awareness of business continuity requirements

#### Cost factors in BIA

- Foregone profits: drop in sales, cost of idle resources, interest costs
- Additional operating expenses: activation of BCP and recovery costs

### 4.4: Data lifecycle management and data protection
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Data lifecycle**: The six stages data passes through from creation to
  destruction
  - Creation: data comes into existence or is synthesized from other sources
  - Storage: data becomes available for use
  - Use: data is processed for material output
  - Sharing: data is distributed to other users or entities
  - Archiving: data no longer in use is retained for regulatory/contractual
    requirements
  - Destruction: data is permanently removed using industry-standard practices

- **Data classification**: Categorizing data based on sensitivity and
  organizational value
  - Determines robustness of required controls
  - Classification factors: regulatory requirements, business impact, data
    type, access control needs, storage location
  - Common levels: Critical, Sensitive, Internal, Public

- **Data labeling**: Tagging data with its classification
  - Data owner (creator) is responsible for labeling
  - Essential for Data Leakage Prevention (DLP) tools
  - DLP tools use pattern-based classification (e.g., nine digits for SSN) or
    user-applied labels

- **Data governance vs data management**:
  - Data governance: strategic and policy aspects (ownership, quality,
    security, compliance)
  - Data management: technical aspects of data handling throughout the
    lifecycle

- **Encryption**: Converting plaintext to ciphertext using algorithms and keys
  - Symmetric: single key for encryption/decryption; faster but requires
    secure key sharing
  - Asymmetric: public/private key pair; slower but more secure; commonly used
    to exchange symmetric keys

- **Data retention**: Policies specifying how long data is kept and when it is
  disposed of
  - Must align with business and regulatory requirements
  - Consider data type, sensitivity, and organizational value

- **Data privacy vs data security**:
  - Privacy: protects individual rights; focuses on consent, access, and
    control over personal information
  - Security: protects data from unauthorized access, modification, or
    disclosure
  - Security enables privacy

##### Doshi Review Manual
- **Data lifecycle phases**: All data moves through six phases requiring
  protection at each stage:
  - Creation: data input through multiple channels; controls ensure integrity
    and confidentiality
  - Storage: data held before use; requires access controls and encryption
  - Processing: data in active use
  - Sharing: data exchanged with authorized users only
  - Archival: inactive data retained with appropriate protection
  - Destruction: data disposed when archival period ends; retention policy
    governs timing

- **Data ownership**: Most important prerequisite for data protection. Without
  assigned ownership, criticality cannot be determined, leading to over or
  under protection. Data owner reviews and monitors protection levels.

- **Data classification policy**: Determines appropriate protection level for
  information assets based on criticality. Includes:
  - Categories for asset classification (confidential, private, public)
  - Protection level for each category
  - Roles and responsibilities of end users
  - Roles and responsibilities of system and data owner

- **Data retention policy**: Defines retention period based on:
  - Business requirements
  - Legal and regulatory requirements
  - Contractual obligations

- **Data Loss Prevention (DLP)**: Specialized software that controls data
  movement and sharing per classification policy. DLP capabilities:
  - Monitors end device activities
  - Controls data flow to prevent unauthorized access
  - Generates automatic alerts for unauthorized attempts
  - Facilitates compliance reporting
  - Maps data flow to understand processes

- **Data protection controls**: Risk practitioner ensures:
  - Access on need-to-know basis (least privilege)
  - Defined termination process for immediate access revocation
  - Periodic review of user access rights
  - Encryption for critical data at rest and in transit (TLS preferred; SSL no
    longer secure)
  - Network segmentation via firewall, VLANs for isolation
  - Anti-malware with daily signature updates

- **Data integrity controls**:
  - Automatic reconciliation (input count to output count)
  - Maker-checker process and segregation of duties
  - Monitoring for abnormal processing levels
  - Validation checks: range, format, special character, size, reasonableness

- **Data validation approaches**:
  - Whitelist: only predefined values allowed; preferred for static data
  - Blacklist: all values except prohibited ones allowed; used when valid range
    is broad

- **Data destruction methods**:
  - Overwriting
  - Degaussing
  - Physical destruction

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Migrating to cloud | Classify sensitive data first | Determines required controls and provider compliance requirements |
| Implementing DLP | Ensure data is labeled by owners | DLP tools rely on classification tags to enforce policies |
| Third-party stores unencrypted data | Assess actual risk based on data type | Deidentified data may pose lower risk than initially assumed |
| Sensitive data no longer needed | Destroy using approved deletion techniques | Meets regulatory requirements and reduces exposure |
| New data classification policy | Conduct security awareness training | Ensures employees understand and implement the policy |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Protecting data on USB or mobile device | Encrypt the data | Encryption makes data unreadable without the key; most effective control |
| Information no longer needed | Follow retention policy | Policy considers business, legal, and regulatory requirements |
| Implementing DLP solution | Analyze business case first | Determines cost-benefit feasibility before other evaluation |
| Protecting data in transit | Use encryption and data encapsulation | Provides confidentiality during transmission |
| Granting data access | Obtain data owner authorization | Data owner responsible for formal authorization |
| Detecting fraudulent transactions | Reasonableness checks | Identifies data deviating from normal business patterns |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Classification without labeling is incomplete**: Defining classification
  categories means nothing if employees don't actually tag data they create

- **Data privacy and data security are not synonymous**: Privacy focuses on
  individual rights and consent; security focuses on technical protection.
  Security enables privacy but does not guarantee it

- **Archival is not destruction**: Archiving retains data for
  regulatory/contractual compliance; destruction permanently removes it

- **Asymmetric encryption is not used for bulk data**: It's slower and
  typically used only to exchange symmetric keys, not encrypt large datasets

- **Data classification drives control costs**: More sensitive classifications
  require more robust (and expensive) controls throughout the lifecycle

##### Doshi Review Manual
- **Encryption scope**: Encryption protects data at rest and in transit, but
  data is in plaintext during use. Role-based access control is the primary
  control for data in use.

- **SSL vs TLS**: SSL is no longer considered secure. TLS should be used for
  web browser encryption.

- **DLP prerequisite**: Business case analysis must precede DLP implementation.
  Benchmarking, vendor evaluation, and risk register updates come after
  feasibility is established.

- **Data owner vs data custodian**: Data owner (business manager) determines
  classification and authorizes access. Data custodian maintains technical
  controls.

- **Retention policy scope**: Covers archival AND destruction. Records must be
  retained as long as required by law, regulation, or contract--not just
  business preference.

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Data lifecycle stages | 6 | Creation, Storage, Use, Sharing, Archiving, Destruction |
| Encryption types | 2 | Symmetric (single key), Asymmetric (key pair) |
| Symmetric key usage | Encryption + decryption | Same key for both operations |
| Asymmetric key usage | Public encrypts, private decrypts | Or vice versa for signatures |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Anti-malware signature updates | Daily | Minimum update frequency |
| Encryption standard for web | TLS | SSL deprecated |
| Strongest wireless encryption | WPA-2 | WEP no longer secure |
| Data validation preference | Whitelist | When input data is static |

#### Related topics

##### CRISC All-in-One Exam Guide
- **GDPR/HIPAA/PCI DSS**: Regulatory frameworks that mandate specific data
  classification and handling requirements
- **Business impact analysis**: Informs data classification based on loss
  impact
- **DLP (Data Leakage Prevention)**: Technical control that enforces data
  handling policies based on classification
- **Access control**: Implements restrictions based on data classification
  levels
- **Key management**: Critical for encryption; keys must be protected
  throughout their lifecycle

##### Doshi Review Manual
- **Data classification (4.17)**: Prerequisite for determining protection
  levels; must identify data owners first
- **Database security**: Encryption, restricted access, secured protocols,
  backup, referential integrity, input validation
- **BYOD policy**: Requires user awareness of acceptable practices for
  effectiveness
- **Acceptable Usage Policy (AUP)**: Written acknowledgement required from
  employees and contractors

### 4.5: System development life cycle (SDLC) and change management
#### Key concepts

##### CRISC All-in-One Exam Guide
- **System Development Life Cycle (SDLC)**: Systematic process outlining
  steps for developing software applications or information systems
  - Five sequential phases: initiation, development/acquisition,
    implementation, operation/maintenance, disposal
  - Each phase has specific deliverables and objectives
  - Designed to ensure software is delivered on time, within budget, and meets
    stakeholder requirements

- **Phase 1 - Initiation**: Project feasibility is evaluated and goals defined
  - Identifies stakeholders and gathers requirements
  - Creates project charter with scope, timeline, budget, and risks
  - Sets foundation for project success
  - Risks: unclear goals, lack of stakeholder support, inadequate budget,
    inaccurate requirements

- **Phase 2 - Development/Acquisition**: Actual coding or software selection
  - Development team creates software based on specifications
  - If acquiring, select and implement best solution for requirements
  - Requires robust testing and quality assurance
  - Risks: poor-quality code, missed deadlines, budget overruns, software not
    meeting user needs

- **Phase 3 - Implementation**: Installing software and training users
  - Includes configuring, enabling, testing, and verifying security
  - Requires well-defined implementation plan and clear stakeholder
    communication
  - Risks: system not meeting requirements, delays, budget overruns

- **Phase 4 - Operation/Maintenance**: System deployed and maintained
  - Focus on ensuring system functions as intended
  - Activities: monitoring, bug fixes, updates, enhancements
  - Requires well-defined maintenance plan
  - Risks: security breaches, data loss, system failures

- **Phase 5 - Disposal**: Final stage where system is decommissioned
  - Secure destruction of data and hardware/software components
  - Must ensure sensitive data is destroyed securely
  - Legal and regulatory requirements (data privacy laws) must be met
  - Risks: data breaches, unauthorized access, regulatory penalties

- **Project risk vs. SDLC risk**: Two distinct risk types that are interrelated
  - Project risk: associated with achieving project objectives (time, budget,
    stakeholder requirements)
  - SDLC risk: associated with the development process itself (requirements
    gathering, software design, coding errors, testing)
  - SDLC issues (like lack of testing) can lead to project delivery delays or
    failure

- **Change management**: Formal review and approval process for system changes
  - Change Advisory Board (CAB) includes representatives from IT, security,
    engineering, and other departments
  - Primary goal: balance required changes with preserving system reliability
    and stability

- **CAB verification requirements**: Before approving changes, CAB verifies:
  - Change will not negatively affect risk profile or security
  - Change is formally requested, justified, approved, and documented
  - Change is scheduled at convenient time for business and IT
  - Change will not result in undue impact or major downtime
  - All relevant stakeholders are informed beforehand
  - Change has followed implementation guidelines, testing, and has rollback
    plan
  - Change will not compromise security baselines

- **Configuration management**: Baseline/standard set of controls for all
  enterprise systems
  - Reduces complexity by simplifying planning, testing, implementation,
    maintenance
  - Risk practitioner verifies configurations are established, documented, and
    followed
  - Baselines must be updated per software upgrades or control requirement
    changes
  - Example: CIS benchmarks for hardening systems

- **Release management**: Coordinated movement from development to production
  - Substantial changes go through formal release cycle
  - Coordinates with production team and end user testing
  - Enables releases with minimal downtime and fewer errors

- **Exception management**: Documented deviations from policy for business
  reasons
  - Exceptions must be approved by appropriate teams
  - Exceptions bring unknown risk to organization
  - Risk practitioner must review exceptions at least annually

##### Doshi Review Manual
- **System Development Life Cycle (SDLC)**: Structured methodology for
  designing, developing, and implementing systems
  - Three models: waterfall, agile, and hybrid approaches
  - Risk practitioners should be involved in all SDLC phases
  - Security requirements must be integrated into every phase

- **SDLC phases**:
  - Phase 1 - Initiation/Feasibility: Define objective, purpose, scope; approve
    system design; establish change management process to prevent scope creep
  - Phase 2 - Development/Acquisition: Evaluate alternatives; develop or
    acquire system
  - Phase 3 - Implementation: Test system; conduct migration; configure and
    verify security features
  - Phase 4 - Operations/Maintenance: Regular updates and system upkeep
  - Phase 5 - Disposal: Discard obsolete systems; archive or destroy data;
    sanitize hardware and software

- **Change management**: Process for requesting, planning, implementing,
  testing, and evaluating changes to systems
  - Primary objective: Support processing and traceability of changes in a
    controlled manner
  - Classified as a preventive control
  - Requires formal approval, documentation, and testing

- **Regression testing**: Part of change management; prevents introduction of
  new security exposures during modifications

- **Changeover techniques**:
  - Parallel: Run old and new systems simultaneously; provides greatest
    redundancy but requires more resources
  - Phased: Implement changes in stages; gradual replacement
  - Abrupt (direct cutover): Immediate switch with no rollback; highest risk

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| New software project starting | Define project charter in initiation phase | Sets scope, timeline, budget, and risks upfront |
| Threat modeling timing | Perform in earlier SDLC stages (after requirements) | Cannot model in requirements phase; too late in later phases |
| Production environment changes | Submit to CAB for formal approval | Unapproved changes could expose organization to unidentified risks |
| Emergency changes needed | Follow same CAB process as standard changes | Ensures visibility to all relevant stakeholders |
| Employee needs policy deviation | Document as exception with annual review | Exceptions bring unknown risk; must be tracked and revalidated |
| Defining baseline laptop settings | Configuration management | Sets initial standard before deployment |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Preventing scope creep | Define change process in feasibility/design phase | Requirements must be frozen early |
| Addressing resource availability | Handle during design phase | Resource planning occurs before development |
| Migration risk | Address during implementation phase | Migration occurs at implementation |
| Internal controls | Incorporate during design phase | Controls are harder to add later |
| Emergency change | Bypass scheduling, not authorization | Authorization and documentation remain mandatory |
| Verifying all patches used change control | Start from patch logs, trace to change requests | Starting from change requests misses unauthorized patches |
| Determining if modifications introduced vulnerabilities | System users perform acceptance testing | Users best positioned to identify functional issues |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Project risk vs. SDLC risk distinction**: Project risk relates to project
  objectives (time, budget, requirements); SDLC risk relates to development
  process objectives. They are interrelated but not the same.

- **Threat modeling timing**: Cannot be performed in requirements phase since
  team is still gathering requirements. Must occur after requirements are
  defined but in earlier SDLC stages.

- **Configuration vs. change management**: Configuration management establishes
  initial baselines; change management controls modifications after baselines
  exist. Do not confuse the two.

- **Accreditation vs. certification**: Accreditation can be internal or
  external. Certification is always performed by an external third-party
  auditor.

- **Exception review frequency**: Exceptions must be reviewed at least annually
  to confirm they are still required. More frequent review is acceptable.

- **CAB approval scope**: Even emergency changes should go through the CAB
  process to ensure visibility and proper documentation.

- **Disposal phase risks**: Often overlooked, but inadequate decommissioning
  can lead to data breaches, regulatory penalties, and unauthorized access to
  sensitive information.

##### Doshi Review Manual
- **Risk assessment timing**: Must be conducted at every SDLC stage, not just
  once before or after the project

- **Business case retention**: Retain until the application's end of life, not
  just until implementation

- **Change management classification**: Preventive control, not detective or
  corrective; it prevents unauthorized changes before they occur

- **Security team involvement**: Must be included in change control board for
  major changes; they do not need to handle the entire process

- **Agile risk**: Lack of documentation is the primary risk, not testing or
  requirements gathering

- **End User Computing (EUC)**: Applications may bypass testing and IT general
  controls; requires documented policy and inventory

- **Waterfall vs. Agile**: Waterfall suits well-defined, stable requirements;
  Agile suits rapid development with less documentation emphasis

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| SDLC phases | 5 | Initiation through Disposal |
| Exception review frequency | Annual (minimum) | Risk practitioner responsibility |
| Domain 4 exam weight | 20% | Information Technology and Security |
| Budgeting phase | Initiation | Project charter includes budget |
| User training phase | Implementation | Part of system deployment |
| Final SDLC phase | Disposal | System decommissioning |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Emergency change bypasses | Scheduling only | Authorization, documentation, impact analysis still required post-implementation |
| Risk practitioner involvement | All SDLC phases | From planning/initiation through disposal |
| Changeover with greatest risk | Abrupt/direct cutover | No rollback capability |
| Changeover with greatest redundancy | Parallel | Both systems run simultaneously |
| Who determines new vulnerabilities | System users | Through user acceptance testing |

#### Related topics

##### CRISC All-in-One Exam Guide
- **System accreditation and certification**: Processes ensuring quality and
  reliability of systems; accreditation verifies standards compliance,
  certification issues formal attestation
- **Threat modeling**: Should be integrated into earlier SDLC phases to ensure
  threats are mitigated promptly
- **Third-party risk management**: Vendor change management practices should be
  evaluated during due diligence
- **COBIT and ITIL alignment**: BAI06 Managed IT Changes (COBIT) corresponds to
  ITIL Change Management process
- **Enterprise architecture**: Technology architecture shows current IT state
  and assists transition with minimal disruption during SDLC
- **Emerging technologies**: BYOD, IoT, AI, blockchain introduce new risks that
  must be considered during development

##### Doshi Review Manual
- **Configuration management**: Most vulnerable area from security perspective;
  misconfiguration and untimely updates pose high risk
- **Release management**: Separate function from change management
- **Project management**: Uses EVA for scope/schedule/budget monitoring; CPM
  and PERT for duration estimates; Gantt charts for milestone tracking
- **Scope creep**: Most common cause of project budget overruns; prevented by
  freezing requirements in feasibility phase
- **User acceptance testing**: Best test to ensure application readiness for
  implementation; signoff required before changeover

### 4.6: Emerging technologies (AI/LLM, quantum computing, Zero Trust)
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Emerging technology risk**: Risk of negative or adverse impact from
  implementing new technology that has not been fully adopted in the industry
  - Risk managers must stay abreast of technological innovations to support
    business decisions
  - Balance between technical revolution and safe, responsible deployment

- **Artificial intelligence (AI)**: Science of developing intelligent machines
  that perform tasks typically requiring human intervention
  - Current applications: autonomous vehicles, customer service chatbots, fraud
    detection systems
  - GPT-4 referenced as revolutionary advancement in AI industry
  - Key risk areas: data privacy and security, algorithmic bias, transparency
    and explainability to humans
  - Potential to transform healthcare, finance, and transportation through
    efficiency and accuracy gains

- **Quantum computing**: Nascent discipline leveraging quantum mechanics
  principles for computation
  - Uses quantum bits (qubits) that exist in superposition of multiple states
    simultaneously
  - Qubits can be entangled to perform intricate computations faster than
    classical computing
  - Primary risk: potential to decrypt current encryption methods
  - Cryptography is the most significant impact area for quantum computing

- **Blockchain**: Distributed ledger technology enabling secure, transparent
  transactions without intermediaries
  - Originally developed for cryptocurrencies (Bitcoin)
  - Expanding to healthcare, supply chain management, finance
  - Challenges: scalability, energy consumption, regulatory uncertainty

- **Internet of Things (IoT)**: Devices with sensors and software collecting and
  transmitting data over the internet
  - Enables real-time monitoring and control without human intervention
  - Privacy concerns: incidents with Amazon Alexa, Google Nest
  - Vulnerable to cyber-attacks; collected data often sensitive and personal

- **Bring Your Own Device (BYOD)**: Policy allowing employees to use personal
  devices for company resources
  - Benefits: flexibility, convenience, cost savings, productivity
  - Risks: data protection, security when accessing from personal devices
  - Required controls: policies, technical controls, employee training

##### Doshi Review Manual
- **Emerging risk management**: Risk environment changes as business processes
  and technology evolve. No system remains secure perpetually. Risk assessment
  must be performed at regular intervals to address emerging risks.
  - Main benefit of consistent risk assessments: understanding trends in risk
    profile
  - Technological changes require proper assessment and testing before
    implementation
  - Risk practitioners must ensure new technology undergoes risk assessment

- **Artificial Intelligence (AI)**: Intelligence demonstrated by machines that
  adopt cognitive functions such as learning and problem solving.
  - Examples: web search engines adapting to user behavior, recommendation
    systems (YouTube, Amazon, Netflix), voice assistants (Siri, Alexa),
    self-driving cars, strategic games
  - AI relies on algorithms including formal logic, artificial neural networks,
    statistics, probability, psychology, and economics
  - Risk consideration: organizations need appropriate oversight for algorithms
    used in AI systems
  - Algorithms must be tested against current business processes and environment
  - Example risk: IDS/IPS heuristic systems need periodic testing to ensure
    malicious traffic is not classified as normal

- **Neural network-based systems**: Self-learning systems that monitor activity
  patterns and update their databases automatically.
  - Most effective when considering large numbers of input variables
  - Applied in intrusion detection systems (IDS) for anomaly detection
  - Advantage over signature-based systems: can detect new attack methods

- **Deepfakes**: AI-generated convincing images, audio, and video.
  - Combines deep learning with fake content creation
  - Can replicate voice tone to match target's voice features
  - Organizational risks:
    - Procedures relying on video or voice authorization become vulnerable
    - False information can damage organizational reputation
  - Mitigations: administrative controls, periodic security awareness,
    callback verification on dedicated phone lines, predefined incident
    response procedures

- **Quantum computing and decryption**: Quantum computers enable more powerful
  brute force attacks with less time consumption.
  - Makes unauthorized decryption of encrypted files a realistic threat
  - Risk mitigation: use high-level encryption standards for sensitive data
    protection

- **Zero Trust architecture**: While not explicitly detailed in source
  material, the principles align with:
  - Role-based access control (RBAC) - access on need-to-know basis
  - Continuous verification of identity and authorization
  - Never assume internal network traffic is trusted
  - Principle of least privilege

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Organization adopting AI for customer service | Assess data privacy, bias prevention, transparency requirements before deployment | AI risks include biased algorithms and opaque decision-making |
| Evaluating quantum-resistant cryptography | Plan migration strategy for encryption methods | Quantum computing threatens current encryption algorithms |
| Implementing IoT sensors in manufacturing | Prioritize data privacy and security measures | IoT devices are vulnerable to attacks and collect sensitive data |
| BYOD policy implementation | Build policies, technical controls, and training program | Personal devices accessing company data require security controls |
| Blockchain for supply chain | Address scalability, energy, and regulatory concerns | Technology is early-stage with unresolved operational challenges |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Implementing new AI/ML system | Conduct risk assessment, establish algorithm oversight, test against business processes | Untested algorithms may misclassify critical events |
| Verbal authorization via phone susceptible to deepfake | Implement callback verification on dedicated phone lines | Confirms identity through secondary channel |
| Quantum computing threatens current encryption | Implement high-level encryption standards | Stronger encryption increases computational requirements for brute force |
| IDS using heuristic/neural network detection | Periodic testing of detection algorithms | Ensures malicious traffic is not misclassified as normal |
| New technology promising cost savings | Monitor adoption, perform risk assessment before implementation | Cost savings may introduce new vulnerabilities |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Quantum computing will not break all cryptography immediately**: The
  technology is nascent; risk managers should plan for gradual migration to
  quantum-resistant algorithms rather than panic
- **AI transparency is a requirement, not optional**: Ensuring AI is
  understandable to humans is critical for responsible deployment, not just a
  nice-to-have
- **BYOD is not just a technical problem**: Requires organizational policies and
  employee training, not just technical controls
- **Emerging technology risk differs from infrastructure risk**: Emerging
  technology risk relates to unproven adoption, while infrastructure risk
  relates to support capacity for business needs

##### Doshi Review Manual
- **AI algorithm oversight is not optional**: Organizations must have
  appropriate oversight mechanisms; algorithms require testing in accordance
  with current business processes.

- **Deepfake risks extend beyond video**: Voice replication is equally
  dangerous for phone-based authorizations.

- **Quantum computing is a future threat requiring current action**: Encryption
  standards must be evaluated now for quantum resistance.

- **Neural network IDS can still fail**: While self-learning, they require
  periodic validation to ensure baseline patterns remain accurate.

- **Emerging threat indicators are often ignored**: Unusual patterns, frequent
  alarms, and increased log activity may signal emerging threats but logs are
  often not monitored timely.

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| CRISC Domain 4 weight | 20% | Information Technology and Security |
| AI risk categories | 3 | Privacy/security, bias, transparency |
| Quantum computing threat | Encryption | Can potentially decrypt current algorithms |
| BYOD control areas | 3 | Policies, technical controls, training |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Risk assessment frequency | Annual minimum + significant changes | Also triggered by new technology, business process changes |
| Risk profile factors | Historical + emerging risk | Aggregated view of enterprise risk exposure |
| Lead indicators | Warning signals | Provide warning for emerging risk before impact |
| Lag indicators | Historical trends | Provide data for improving risk response |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Cryptography and encryption**: Quantum computing directly threatens current
  symmetric and asymmetric encryption methods; AES-256 and RSA are vulnerable to
  future quantum attacks
- **Data privacy principles**: AI and IoT both raise significant privacy
  concerns requiring privacy-by-design approaches
- **Control frameworks**: Emerging technologies require compensating controls
  when traditional controls are insufficient
- **Risk assessment**: Emerging technology risk is a distinct risk category in
  IT risk catalogs requiring specific evaluation criteria
- **System Development Life Cycle (SDLC)**: Emerging technologies should be
  evaluated during the initiation and design phases for security implications

##### Doshi Review Manual
- **Managing emerging risks (3.6)**: Framework for identifying and responding
  to new threats from technological change
- **Intrusion detection systems (4.7)**: Neural network and statistical-based
  IDS for anomaly detection
- **Big data risks**: Privacy law compliance, data aggregation creating PII
  from non-PII
- **IoT risks**: Health/safety impact, regulatory compliance, privacy, device
  vulnerabilities, hardcoded passwords
- **Blockchain**: Decentralized, irreversible ledger technology with
  implications for data integrity
- **BYOD and virtualized desktops**: Emerging technology controls for personal
  device access

#### Exam-critical points

1. Quantum computing can break current encryption algorithms - this is the
   primary security concern
2. AI challenges include: data privacy, algorithmic bias, and transparency
3. BYOD requires three control types: policies, technical controls, and training
4. IoT devices are vulnerable to cyber-attacks and raise privacy concerns
5. Blockchain challenges: scalability, energy consumption, regulatory
   uncertainty
6. Risk managers must stay current on emerging technologies to advise business
   decisions
7. Emerging technology risk is the risk of adverse impact from implementing
   unproven technology
### 4.7: Information security frameworks and standards
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Control**: A measure that reduces risk and improves security posture.
  Controls can be technical (antivirus software), physical (turnstiles),
  or administrative (policy documents).

- **COBIT 2019**: ISACA's governance framework bridging governance,
  technical requirements, business objectives, risks, and control
  requirements.
  - Four publications: Introduction and Methodology, Governance and
    Management Objectives, Design Guide, Implementation Guide
  - Core Model contains 40 governance and management objectives across
    five domains: Evaluate/Direct/Monitor (EDM), Align/Plan/Organize
    (APO), Build/Acquire/Implement (BAI), Deliver/Service/Support (DSS),
    Monitor/Evaluate/Assess (MEA)
  - Identifies *what* IT should do; ITIL prescribes *how*

- **NIST Cybersecurity Framework (CSF)**: Divides cybersecurity into five
  functions: Identify, Protect, Detect, Respond, Recover.
  - COBIT has custom frameworks for implementing NIST CSF

- **NIST Special Publications**:
  - SP 800-30: Risk management for general information systems
  - SP 800-37: Risk management for federal information systems
  - SP 800-88: Media sanitization and data destruction standards
  - SP 800-161: Supply chain risk management

- **ISO/IEC standards**:
  - ISO 27001: Information security management certification
  - ISO 27002: Security controls implementation guidance
  - ISO 27005: Risk management for information systems
  - ISO 31000: Organizational risk management
  - ISO 31010: Risk management for IT governance

- **SOC reports** (AICPA Trust Principles):
  - SOC 2: Assesses controls for security, availability, processing
    integrity, confidentiality, privacy
  - SOC 3: Publicly distributable summary of SOC 2
  - Based on SSAE 18 attestation standards

- **HITRUST CSF**: Healthcare-specific security framework combining
  requirements from HIPAA, PCI DSS, ISO 27001, and NIST.

- **PCI DSS**: Payment Card Industry Data Security Standard for
  organizations handling cardholder data.

- **Control categories by function**:
  - Preventive: Block threats before damage occurs
  - Detective: Identify incidents after occurrence (e.g., SIEM log review)
  - Corrective: Remediate after an incident
  - Deterrent: Discourage threat actors (e.g., security cameras)
  - Compensating: Offset weaknesses in other controls

- **Control categories by implementation**:
  - Technical/Logical: Software and hardware (firewalls, encryption, ACLs)
  - Physical: Environmental measures (locks, turnstiles, cameras)
  - Administrative: Policies and procedures (security awareness training)

##### Doshi Review Manual
- **Control framework**: A structured set of guidelines for designing,
  implementing, and monitoring controls. Provides a baseline for evaluating
  control adequacy and effectiveness.
  - Primary basis for selecting security technology is ability to mitigate risk
    to enterprise's goals, not compliance with international certifications
  - Control frameworks should address defined control objectives before
    implementation

- **IT governance (EGIT)**: Process to monitor and control IT activities,
  ensuring IT provides value to business and risks are appropriately addressed.
  - Primarily the responsibility of the Board of Directors
  - Main objective: optimal use of technology resources
  - Effectiveness determined by ensuring involvement of all stakeholders
  - IT plan should be consistent with organization's business plan

- **Third-party assurance**: Certification or attestation for compliance with
  industry-recognized standards, provided by independent third parties.
  - Helps earn confidence of shareholders, customers, and stakeholders
  - Cloud service providers commonly seek third-party assurance

- **Security architecture**: Provides overview and relationship between systems.
  - Primary purpose: align security strategy between functional areas of
    organization and external parties
  - Most useful for managing complex security deployments

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Third-party vendor evaluation | Request SOC 2 report or ISO 27001 certification | Independent attestation provides objective assurance of control design and effectiveness |
| US healthcare organization needs security framework | Implement HITRUST CSF | Combines HIPAA requirements with ISO and NIST; favored for US healthcare |
| EU/UK organization needs certification | Pursue ISO 27001 | More recognized in European markets than SOC 2 |
| Federal agency information systems | Follow NIST SP 800-37 | Specifically designed for federal system risk management |
| Supply chain risk management | Reference NIST SP 800-161 | Purpose-built for supply chain security |
| Quantitative risk analysis needed | Use FAIR framework | FAIR is designed for quantitative risk management; NIST 800-30 and ISO 27005 are primarily qualitative |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Ensuring service provider complies with security requirements | Conduct periodic audit | Verifies actual compliance with agreement requirements |
| Determining if security framework meets organization's needs | Conduct process assessment | Evaluates framework suitability against current processes |
| Managing complex security deployments | Develop security architecture | Provides overview and relationship between systems |
| Evaluating IT equipment supplier value | Comparative analysis of cost and performance | Enables objective assessment against alternatives |
| Addressing audit findings | Create risk mitigation plan | Takes corrective action to close findings |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Legal controls are not a control category**: The three categories of
  information security controls are technical, physical, and
  administrative. "Legal controls" is a distractor.

- **COBIT vs ITIL confusion**: COBIT covers enterprise-wide governance
  (what to do); ITIL focuses specifically on IT service management (how
  to do it). They complement each other but serve different purposes.

- **SOC 2 vs ISO 27001**: SOC 2 is an attestation report (point-in-time
  assessment); ISO 27001 is a certification (ongoing management system).
  Both demonstrate control effectiveness but through different mechanisms.

- **Framework selection depends on context**: No single framework is
  universally correct. Selection depends on industry, regulatory
  requirements, and geographic region.

- **Control sequence matters**: Ideal order is deterrent first
  (discourage attack), then preventive (block if attempted), then
  detective (identify if succeeded), then corrective (remediate damage).

##### Doshi Review Manual
- **Framework selection vs. technology selection**: Selecting security
  technology should be based on ability to mitigate risk to enterprise goals,
  not compliance with frameworks alone.

- **IT governance ownership**: IT governance is the responsibility of the Board
  of Directors, not IT management or the CIO.

- **Information security policy review**: Senior management must review
  information security policy. Lack of senior management review is a critical
  weakness in the governance model.

- **Stakeholder involvement**: Effectiveness of IT governance implementation is
  determined by stakeholder involvement, not just management approval.

- **Control framework vs. risk register**: A control framework provides the
  structure for control design, while a risk register documents identified
  risks. Both are needed but serve different purposes.

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| COBIT Core objectives | 40 | Across 5 domains |
| COBIT 2019 domains | 5 | EDM, APO, BAI, DSS, MEA |
| NIST CSF functions | 5 | Identify, Protect, Detect, Respond, Recover |
| SOC 2 trust principles | 5 | Security, Availability, Processing Integrity, Confidentiality, Privacy |
| ISO 27001 external audit frequency | Annual | Minimum for maintained certification |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Information security policy review | At least annually | Address new and emerging risks |
| IT risk management program scope | Critical functions minimum | Need not cover all functions |
| Continuous monitoring deployment | High-risk areas | Where incidents have high impact and frequency |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Three Lines of Defense**: Third line (internal/external auditors)
  performs audits per frameworks such as ISO 27001, SOC 2, or HITRUST CSF

- **Third-party risk management**: External certifications (ISO 27001,
  SOC 2, HITRUST) streamline vendor assessments by providing independent
  control assurance

- **Control assessment techniques**: Self-assessments can adopt industry
  standards (NIST, COBIT, ISO 27001) as the control framework for
  evaluation

- **Risk register**: Framework alignment helps categorize and prioritize
  risks consistently across the organization

##### Doshi Review Manual
- **Control categories**: Preventive, detective, corrective, deterrent,
  directive, and compensating controls work within the framework structure
- **Administrative, technical, and physical controls**: Three-layer control
  classification aligned with framework requirements
- **Enterprise risk management (ERM)**: Overarching risk management approach
  that frameworks support
- **Policies, standards, and procedures**: Hierarchy linking governance
  intentions to operational controls
  - Standards are minimum requirements to comply with security policy
  - Procedures link to security policy through standards
- **Third-party risk management**: Frameworks provide basis for evaluating
  vendor compliance

#### Widely recognized standards and frameworks

| Framework | Purpose |
| --------- | ------- |
| ISO 27001 | Information security management system (ISMS) certification |
| PCI DSS | Payment card industry data security standard |
| COBIT 5 | IT governance and management framework |
| SSAE 16 | Attestation standard for service organizations |
| TOGAF | Enterprise architecture framework |
| Zachman | Enterprise architecture classification schema |
| DODAF | Department of Defense architecture framework |
| FEAF | Federal enterprise architecture framework |

### 4.8: Security awareness training programs
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Security awareness training**: A critical component of an organization's
  cybersecurity strategy designed to educate employees on identifying and
  mitigating potential security risks and threats
  - Promotes a culture of security throughout the organization
  - Targets the human element, which is involved in 82% of breaches (Verizon
    2022 Data Breach Investigations Report)
  - Best preventive control against insider threats

- **Training frequency requirements**:
  - Initial training within 30 days of onboarding
  - Annual refresher training thereafter at minimum
  - Additional role-based training for specific job functions
  - Privileged user training for those with elevated access

- **Security-conscious culture**: The primary goal of security awareness
  training
  - Employees understand the importance of security
  - Staff adopt best practices proactively
  - Personnel report suspicious activities without hesitation
  - Security reinforced at all organizational levels

- **Control classification of security awareness training**:
  - Deterrent control: discourages malicious actions before they occur
  - Administrative control: relies on policies and procedures rather than
    technical measures
  - Preventive control when addressing insider threats

##### Doshi Review Manual
- **Security awareness training**: Most important element of information
  security program; technical controls alone cannot address all security risks
  - Addresses behavioral aspects through continuous awareness and education
  - Compliance with security policy best ensured through education
  - Continuous activity starting from employee onboarding

- **Customization by audience**: Most effective success factor for training
  programs
  - System developers: enhanced training on secure coding practices
  - Data entry operators: security aspects related to their specific functions
  - Common messages tailored for different groups

- **Training content focus areas**: Password selection, acceptable use of
  information resources, social engineering attacks, email safety, web browser
  safety

- **Top-down approach**: Senior management commitment required for program
  success
  - Provides resources and organizational support
  - Influential employees act as security ambassadors within departments

- **Training timing for new employees**: Must occur before system or data
  access is granted; part of orientation program

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Employees falling for phishing attacks | Implement security awareness training | Social engineering attacks rely on human behavior; training helps employees recognize and resist manipulation |
| New online banking platform deployment | MFA is most important control, but training supplements | Technical controls address transaction risk; training addresses user behavior |
| Implementing new data classification policy | Conduct security awareness training for employees | Ensures staff understand the policy and can implement it properly |
| Managing mobile device risks | MDM solution is primary; training is supplementary | Training alone is insufficient; technical controls required for comprehensive mobile security |
| Protecting against social engineering | Provide security awareness training to employees | Social engineering exploits human psychology, making education the most effective defense |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Heavy increase in malware attacks | Conduct regular awareness training on user roles and responsibilities | Educated employees detect attacks quickly and prevent adverse impact |
| Need to reduce social engineering risk | Enterprise-wide security awareness program | Users educated to recognize manipulation attempts |
| Improving password policy effectiveness | Frequent security awareness programs | Obtains buy-in from end users; more effective than audits or penalties |
| Addressing internal security threats | Periodic awareness training for all employees and third parties with data/system access | Helps identify threat symptoms and take timely action |
| Changing organizational security culture | Security awareness campaigns | Gradual process requiring frequent employee training |
| Employees installing unlicensed software | Additional security awareness training | KRI indicates awareness gap |
| Ethics concerns in monitoring activities | Ethics awareness training for employees involved in monitoring | Primary target audience for ethics training |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Primary purpose misconception**: The primary purpose of security awareness
  training is to develop a security-conscious culture, not merely to teach
  employees to recognize threats or use security tools

- **Control type confusion**: Security awareness training is classified as a
  deterrent control and administrative control, not a preventive or technical
  control

- **Standalone effectiveness**: Training alone is insufficient for some risks
  (mobile devices, technical vulnerabilities); must be combined with technical
  controls

- **Not a compensating control**: Encryption is a compensating control;
  security awareness training is not

- **Not a risk management component**: Conducting vulnerability scans is a key
  risk management activity; security awareness training is part of the broader
  security program

##### Doshi Review Manual
- **Increase in incident/violation reports indicates success**: More reporting
  means staff recognize and report issues; decrease may indicate lack of
  awareness
- **Human element is weakest link**: Staff have most chances of failure
  compared to software, processes, or hardware; vulnerable to error and fraud
- **Social engineering tests more effective than just training content**:
  Periodic simulated attacks maintain alertness and remind users threats are
  real
- **DLP cannot fully compensate for awareness gaps**: Attackers can use social
  engineering to obtain credentials and bypass DLP solutions
- **Awareness training is not a one-time event**: Continuous activity at
  frequent intervals; culture change is gradual

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Initial training deadline | 30 days | From employee onboarding date |
| Minimum recurring frequency | Annually | At least once per year |
| Breach involvement (human element) | 82% | Verizon 2022 DBIR statistic |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| HR department primary security responsibility | Security awareness training | Not budget, recruitment, or risk assessment |
| Effectiveness measure | Increase in violation reports | Not training count, budget spent, or helpdesk requests |
| Primary program objective | Influence employee behavior toward security consciousness | Decrease security incidents |
| New employee training timing | Before any system/data access | Part of orientation program |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Social engineering attacks**: Training is the primary defense against
  phishing, pretexting, and baiting
- **Insider threats**: Malicious insiders pose the greatest threat; training is
  the best preventive control
- **Key risk indicators (KRIs)**: Employees untrained in security awareness
  continuing to fall for phishing is an example KRI
- **NIST Cybersecurity Framework Protect function**: Security awareness
  training is a core activity within the Protect function
- **Administrative vs. technical controls**: Training is administrative; access
  control lists are technical
- **Data classification policies**: Training ensures employees understand and
  implement classification requirements

##### Doshi Review Manual
- **Social engineering**: Primary reason for enterprise-wide awareness programs;
  attacks manipulate users into divulging credentials
- **BYOD risks**: Requires periodic awareness training on proper use of personal
  devices
- **Deepfake risks**: Administrative controls and periodic security awareness
  needed for procedures using video/voice authorization
- **Password policy**: Effectiveness improved through frequent awareness
  programs rather than audits or penalties
- **Classification policy**: Content should be part of security awareness
  program; without user awareness, policy implementation fails
- **Compensating controls**: Awareness training is secondary to log review when
  segregation of duties cannot be implemented
- **Outsourcing risk**: Annual awareness training for service provider employees
  is one mitigation option but audit verification is more effective

### 4.9: Authentication, encryption, and access control principles
#### Key concepts

##### CRISC All-in-One Exam Guide
- **CIA triad**: The three pillars of information security --
  confidentiality, integrity, and availability -- guide all security
  decisions.
  - Confidentiality: Information accessible only to authorized individuals
  - Integrity: Data accuracy and completeness maintained without tampering
  - Availability: Information accessible to authorized users when needed

- **Non-repudiation**: Ability to prove message origin and authenticity;
  sender cannot deny sending a message. Achieved through digital signatures.

- **IAAA framework**: Four pillars of access management:
  - Identification: Unique ID (username, email, user ID) identifies the user
  - Authentication: Verifies identity through factors (knowledge, possession,
    biometric)
  - Authorization: Determines resource access based on role or privileges
  - Accountability: Logging and auditing of resource access

- **Authentication factors**:
  - Something you know: PIN, password
  - Something you have: Security token, proximity card
  - Something you are: Biometric (retinal scan, fingerprint)

- **Multi-factor authentication (MFA)**: Combines two or more factors to
  establish strong authentication. Reduces reliance on single factor
  (password).

- **Credential**: Combination of identification (username) and authentication
  (password).

- **Least privilege principle**: Minimum access required to perform job
  functions.

- **Need-to-know principle**: Access only to information needed for job
  functions.

- **Role-based access control (RBAC)**: Authorization based on user role
  within the organization.

- **Segregation of duties (SOD)**: Prevents single individual from having
  complete control over critical data or applications. Mitigates insider
  fraud. Required by SOX, PCI DSS.
  - Compensating controls when SOD not feasible: activity log monitoring,
    periodic user access reviews, external audits.

- **Symmetric encryption**: Single key for encryption and decryption. Faster
  but requires secure key sharing.

- **Asymmetric encryption**: Public/private key pair. Slower but more secure;
  different keys for encryption and decryption. Common use: share symmetric
  keys securely.

- **Hashing**: One-way function converting input to fixed-size output
  (digest). Used for password storage and data integrity. Minor input changes
  produce significantly different hashes.

- **Digital signatures**: Provide authenticity, integrity, and non-repudiation
  of messages. Created by encrypting message hash with sender's private key.
  Do not provide confidentiality on their own.

- **Message states**:
  - Encrypted only: Confidentiality, no integrity or non-repudiation
  - Signed only: Integrity and non-repudiation, no confidentiality
  - Signed and encrypted: All three properties

- **Certificate authority (CA)**: Trusted third party that issues digital
  certificates linking public keys to owners.

- **X.509**: Standard format for digital certificates ensuring cross-system
  compatibility.

- **Certificate revocation list (CRL)**: CA-maintained list of revoked
  certificates.

- **Public key infrastructure (PKI)**: Implementation of certificates and CAs
  to establish, manage, distribute, and revoke digital certificates. Used for
  HTTPS connections.
  - Private key compromise at CA creates single point of failure (SPOF).

##### Doshi Review Manual
- **Authentication factors**: Three types used for granting access:
  - Something you know (password, PIN, personal information)
  - Something you have (token, OTP, smart card)
  - Something you are (biometric features: fingerprint, iris, voice)
  - Two-factor authentication combines two of these methods for stronger
    security

- **Authentication types**:
  - By knowledge: password or passcode validation
  - By ownership: token or OTP possession
  - By characteristics: biometric features
  - By node: device identification via IP or MAC address

- **Biometric accuracy measures**:
  - False Acceptance Rate (FAR): unauthorized person granted access
    (fail-unsafe)
  - False Rejection Rate (FRR): authorized person denied access
  - Cross Error Rate (CER): point where FAR equals FRR; lower CER indicates
    more effective system
  - FAR and FRR are inversely proportional; retina scan is most accurate
    biometric identifier

- **Single Sign-On (SSO)**: One set of credentials accesses multiple
  applications. Advantage: reduced password management overhead.
  Disadvantage: single point of failure increases impact of credential
  compromise. Kerberos is an example.

- **Symmetric vs asymmetric encryption**:
  - Symmetric: single key for encryption and decryption; faster but key
    distribution is challenging
  - Asymmetric: public/private key pair; slower but scales better for large
    key distribution

- **Asymmetric key usage**:
  - Confidentiality: encrypt with receiver's public key, decrypt with
    receiver's private key
  - Authentication/non-repudiation: encrypt hash with sender's private key,
    verify with sender's public key
  - Integrity: sender encrypts hash with private key; receiver compares
    decrypted hash against independently computed hash

- **Digital signature**: Created by hashing the message and encrypting the
  hash with sender's private key. Provides integrity, authentication, and
  non-repudiation. Does NOT provide confidentiality.

- **PKI components**:
  - Digital Certificate: electronic proof of public key ownership
  - Certifying Authority (CA): issues and manages digital certificates
  - Registration Authority (RA): verifies applicant information before CA
    issuance
  - Certificate Revocation List (CRL): list of terminated/revoked
    certificates
  - Certification Practice Statement (CPS): procedures for certificate
    issuance and management

- **Role-Based Access Control (RBAC)**: Access granted on need-to-know
  basis. Most cost-effective method for large organizations. Reduces insider
  threat risk by limiting access to job-required data only.

- **Least privilege**: Access restricted to minimum necessary for job
  function. Enforces accountability and reduces unnecessary access rights.

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| User needs access to specific data | Apply need-to-know and least privilege | Limits exposure; prevents unauthorized data access |
| Protecting sensitive data at rest | Symmetric encryption (AES-256) | Fast, efficient for bulk data |
| Securing data in transit | Asymmetric encryption for key exchange, then symmetric | Combines security of asymmetric with speed of symmetric |
| Verifying message authenticity | Digital signature with PKI | Proves sender identity and message integrity |
| Password storage | Hashing with salt | One-way; original cannot be recovered from hash |
| SOD not feasible due to limited staff | Accept risk with compensating controls | Log monitoring, access reviews, external audits |
| Establishing secure website connection | PKI with X.509 certificates | Browser verifies CA-issued certificate before encrypting |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Strongest network authentication | Two-factor authentication | Requires multiple authentication methods |
| Protect data on mobile device | Encrypt stored data | Renders data unreadable without key |
| Secure wireless network entry point | Strong encryption | Protects against local sniffing attacks |
| Reduce insider threat to confidential data | RBAC | Limits access to authorized users only |
| Ensure password policy compliance | System-enforced password configuration | Technical control more reliable than policy awareness |
| Protect data on USB | Encrypt the USB device | Data remains protected even if device lost |
| Share password for confidential file | Out-of-band channel | Reduces interception risk |
| Prevent DBA from reading sensitive data | Application-level encryption | Data unreadable at database level |
| Compromised two-factor algorithm | Notify system owners using affected authentication | Enables risk-based response decisions |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **Digital signatures alone do not provide confidentiality**: Signature
  encrypts the hash, not the message content.

- **Need-to-know vs. least privilege**: Need-to-know limits data visibility;
  least privilege limits application access/permissions.

- **Single-factor authentication risk**: Identification (username) is often
  known; security depends entirely on authentication factor strength.

- **Asymmetric encryption is slower**: Use only for short messages or key
  exchange, not bulk data encryption.

- **CA private key compromise**: Creates SPOF for entire PKI; all certificates
  issued by that CA become untrustworthy.

- **Hashing is not encryption**: Hashing is one-way and irreversible;
  encryption is reversible with the key.

##### Doshi Review Manual
- **Digital signature does not provide confidentiality**: It encrypts only
  the hash, not the message itself. Confidentiality requires encrypting the
  full message with the receiver's public key.

- **Biometrics alone is single-factor**: Only combined with another factor
  type (knowledge or ownership) does it become strong authentication.

- **SSO convenience trade-off**: Reduces administrative overhead but creates
  single point of compromise. Requires strong password complexity.

- **CA private key is single point of failure**: Compromise affects all
  certificates issued by that CA, not just individual certificate holders.

- **FAR is the critical biometric metric for sensitive data**: Low FAR
  prevents unauthorized access. High FRR affects usability but not security.

- **Symmetric encryption key sharing risk**: Primary disadvantage is
  securely distributing the shared key. Asymmetric encryption solves this
  for large-scale distribution.

- **Public key encryption does not equal greater strength**: It provides
  scaling convenience, not stronger encryption than symmetric methods.

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Authentication factors | 3 types | Know, have, are |
| MFA | 2+ factors | Combining factors from different types |
| SOD compensating controls | 3 | Log monitoring, access reviews, external audits |
| Message security states | 3 | Encrypted only, signed only, signed and encrypted |
| Encryption types | 2 | Symmetric (single key), asymmetric (key pair) |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Password synchronization benefit | Reduced admin workload | Single password across devices |
| Most reliable biometric | Retina scan | Lowest FAR among current identifiers |
| Optimal biometric tuning for critical data | High FRR | Stringent matching rejects some valid users but maximizes protection |

#### Related topics

##### CRISC All-in-One Exam Guide
- SOX compliance: Requires SOD for financial controls
- PCI DSS: Mandates SOD and encryption of payment card data
- Incident response: Relies on accountability logs for forensics
- Business continuity: Availability pillar ensures operations continue
- Data privacy: Overlaps with confidentiality controls

##### Doshi Review Manual
- Non-repudiation (1.5): PKI enables non-repudiation through digital
  signatures and certificate-based authentication
- Data protection (4.8): Encryption protects confidentiality at rest and in
  transit
- Segregation of duties (4.24): RBAC enforces separation by restricting
  access to authorized roles only
- Information security principles (4.23): Authentication and access control
  implement confidentiality requirements

### 4.10: Network security (firewalls, IDS/IPS, VPN, cloud security)
#### Key concepts

##### CRISC All-in-One Exam Guide
- **Firewall**: Network security device that monitors incoming and outgoing
  traffic and permits or prohibits traffic based on predefined security rules
  - Can be hardware (physical device) or software
  - Primary purpose is preventing unauthorized access by blocking traffic that
    does not meet security criteria

- **Firewall types by OSI layer**:
  - **Packet filtering firewall**: Compares each packet to established criteria;
    works on Layer 3 (network layer)
  - **Circuit-level gateway firewall**: Monitors TCP handshakes and established
    sessions; works on Layer 5 (session layer)
  - **Application-level gateway firewall**: Examines each layer of
    communication; provides most secure connectivity; works on Layer 7
    (application layer)
  - **Stateful inspection firewall**: Tracks connections in a table to enforce
    rules based on session context; works on Layer 3 (network layer)
  - **Next-generation firewall (NGFW)**: Combines packet and stateful
    inspection with deep packet inspection for intrusion prevention; works on
    Layer 7 (application layer)

- **Intrusion Detection System (IDS)**: Detects potential malicious traffic but
  does not block it
  - Passive system that observes network traffic
  - Sends alerts to teams for investigation
  - No effect on network throughput
  - Critical to fine-tune IDS rules to prevent false positive overload

- **Intrusion Prevention System (IPS)**: Detects and blocks malicious traffic
  - Active system implemented in line with traffic
  - Often reduces network throughput due to inline inspection

- **IDS/IPS deployment options**:
  - Network layer: Between outside network and organization's network
  - Host level: Individually on user machines as software applications

- **Virtual Private Network (VPN)**: Creates a secure, encrypted tunnel over a
  less secure network such as the public internet
  - Enables remote connection to private networks (e.g., workplace network)
  - Implementation protocols:
    - **IPSec**: Network layer protocol; considered most secure
    - **TLS**: Transport layer protocol
  - VPN server acts as gateway to access the private network

- **Cloud computing service models**:
  - **IaaS**: Virtualized computing resources (servers, storage); customer
    manages OS upward; examples: AWS, Azure
  - **PaaS**: Platform for building/deploying applications; customer manages
    applications and data; examples: AWS Elastic Beanstalk, Google App Engine
  - **SaaS**: Software applications; customer manages only configuration;
    examples: Gmail, Office 365

- **Cloud deployment models**:
  - **Public cloud**: Third-party provider, shared resources
  - **Private cloud**: Dedicated resources, not shared with other organizations
  - **Hybrid cloud**: Combination of public and private
  - **Community cloud**: Shared among specific business community (e.g.,
    government agencies, hospitals)

##### Doshi Review Manual
- **Firewall**: Network security system that monitors and controls incoming and
  outgoing traffic according to defined rules; can be hardware or software
  - Restricts unauthorized access while permitting authorized connections
  - Most stringent configuration: deny all traffic and allow specific traffic

- **Packet filtering router**: Earliest firewall type; tracks IP address and port
  number of source/destination; operates at OSI network layer (layer 3)

- **Stateful inspection firewall**: Monitors destination of each outgoing packet;
  ensures incoming messages are responses to prior requests; operates at
  network layer (layer 3)

- **Circuit-level firewall**: Uses bastion host and proxy server concepts;
  provides same proxy for all services; operates at session layer (layer 5)

- **Application-level firewall**: Most secure firewall type; operates at
  application layer (layer 7); provides separate proxy per service; controls
  applications like FTP and HTTP

- **DMZ (demilitarized zone)**: Buffer zone between internal network and
  internet; houses public-facing servers; all systems should be hardened;
  nothing valuable kept in DMZ due to attack exposure

- **IDS (Intrusion Detection System)**: Monitors network or host to detect
  intrusion activity; cannot prevent attacks, only detect and alert
  - Network-based IDS: monitors full network; higher false positives; better
    for external attacks
  - Host-based IDS: monitors single system; lower false positives; better for
    internal attacks

- **IPS (Intrusion Prevention System)**: Detects and prevents intrusion impact;
  active blocking capability beyond IDS detection-only function

- **VPN (Virtual Private Network)**: Extends private network over public
  internet securely; enables remote user access to organizational resources
  - Uses IPSec tunnel mode (encrypts entire packet including header) or
    transport mode (encrypts data portion only)
  - Uses data encapsulation/tunneling for secure transmission

- **Cloud deployment models**:
  - Private cloud: most secure; controlled by organization; on-premises or
    off-premises
  - Public cloud: open to all on pay-per-use basis; highly scalable
  - Community cloud: shared by specific consumer communities
  - Hybrid cloud: combination of private and public cloud

#### Common scenarios

##### CRISC All-in-One Exam Guide
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Remote employees need secure access to corporate network | Implement VPN with IPSec | Creates encrypted tunnel; IPSec is most secure protocol |
| Need to detect attacks without affecting throughput | Deploy IDS | Passive monitoring, no throughput impact |
| Need to block malicious traffic in real time | Deploy IPS | Active inline blocking, accepts throughput trade-off |
| Cloud migration with compliance requirements | Understand shared responsibility model | Defines provider vs. customer security obligations |
| Malicious network requests from changing IP patterns | Implement firewall rules and monitor regularly | Attack patterns evolve; rules require periodic review |

##### Doshi Review Manual
| Scenario | Correct approach | Why |
| -------- | ---------------- | --- |
| Protect network from external attack | Screened subnet firewall (DMZ) | Uses 2 packet filtering routers plus bastion host; prevents direct internal-external connection |
| Ensure confidentiality over wireless | Deploy VPN over wireless network | Encrypts data in transit; prevents sniffing |
| Detect attacks bypassing firewall | Place IDS between firewall and internal network | Only detects traffic that passed firewall rules |
| Identify all intrusion attempts | Place IDS between firewall and external network | Sees all attempts regardless of firewall filtering |
| Verify CSP physical security | Obtain independent audit reports | Policy review alone insufficient; third-party verification required |
| Secure remote access | Implement VPN with proper configuration | Cost-efficient alternative to dedicated leased lines |

#### Gotchas

##### CRISC All-in-One Exam Guide
- **IDS vs. IPS confusion**: IDS only detects and alerts (passive); IPS detects
  and blocks (active). IDS does not affect throughput; IPS reduces throughput
  because it inspects traffic inline.

- **Firewall classification as control type**: Firewalls are technical/logical
  controls, not physical controls. They are also preventive controls, not
  detective controls.

- **IDS as detective control**: IDS is a detective control because it detects
  security incidents. Firewalls are preventive controls.

- **VPN protocol selection**: IPSec is the most secure VPN protocol. PPTP and
  L2TP are older and less secure. SSTP uses SSL/TLS but is Windows-only.

- **Cloud shared responsibility**: Customer security responsibilities vary by
  service model. IaaS customers manage more (OS, applications, data); SaaS
  customers manage only configuration and access.

- **Community vs. private cloud**: Community cloud shares resources among
  similar organizations with common concerns; private cloud is dedicated to a
  single organization.

##### Doshi Review Manual
- **Application vs circuit gateway**: Application gateway controls specific
  applications (HTTP, FTP); circuit gateway controls paths/circuits only

- **IDS placement affects detection scope**: Between firewall and external
  network sees all attempts; between firewall and internal network sees only
  bypassed attempts

- **Statistical IDS has highest false positives**: Flags any abnormal behavior;
  signature-based cannot detect new attack methods; neural network has
  self-learning capability

- **Most likely firewall implementation error**: Wrong configuration of access
  lists, not inadequate training or password issues

- **VPN risk with home computers**: Home systems have weakest security; if
  compromised, attacker can enter internal network through VPN tunnel

- **Cloud contract priority**: Legal/regulatory compliance is most important
  clause; data localization requirements before right to audit or backup terms

- **Private cloud lowest data leakage risk**: Data remains under organizational
  control; public cloud data may coexist with competitor data

#### Limits and defaults

##### CRISC All-in-One Exam Guide
| Item | Value | Notes |
| ---- | ----- | ----- |
| Packet filtering firewall | OSI Layer 3 | Network layer |
| Circuit-level gateway | OSI Layer 5 | Session layer |
| Application-level gateway | OSI Layer 7 | Application layer; most secure |
| Stateful inspection firewall | OSI Layer 3 | Network layer |
| Next-generation firewall | OSI Layer 7 | Application layer |
| IDS throughput impact | None | Passive observation |
| IPS throughput impact | Reduces | Inline inspection required |
| VPN IPSec | Network layer | Most secure VPN protocol |
| VPN TLS | Transport layer | Alternative to IPSec |

##### Doshi Review Manual
| Item | Value | Notes |
| ---- | ----- | ----- |
| Firewall OSI layers | 3 (packet filter, stateful), 5 (circuit), 7 (application) | Higher layer = more functionality |
| IDS components | Sensors, analyzers, admin console, user interface | Sensors collect data; analyzers detect intrusion |
| VPN encryption modes | Tunnel (full packet), Transport (data only) | Both use IPSec standard |
| Cloud service models | IaaS, PaaS, SaaS | IaaS = infrastructure; PaaS = platform; SaaS = software |

#### Related topics

##### CRISC All-in-One Exam Guide
- **Control types**: Understanding that firewalls are preventive/technical
  controls and IDS is a detective control is essential for control
  classification questions
- **Risk transfer**: Sharing security responsibility with SaaS providers is a
  form of risk transfer
- **Third-party risk**: Cloud providers introduce third-party risk requiring
  TPRM (Third-Party Risk Management) programs
- **Service-Level Agreements (SLAs)**: Cloud SLAs should include security terms
  and measures against data loss and downtime
- **Data protection**: Cloud security considerations include encryption, access
  controls, and monitoring to protect against data breaches

##### Doshi Review Manual
- **IDS tuning**: Adjusting sensitivity affects false positive rate; low
  threshold increases false positives; simulated attacks validate tuning
- **Honey pots**: Decoy systems to attract attackers; capture intruder details
  for proactive security; honey nets link multiple honey pots
- **VDI (Virtual Desktop Infrastructure)**: Alternative to VPN; segregates
  personal and organizational data; processing occurs on host server; prevents
  local data copies
- **WPA2 encryption**: Strongest wireless encryption standard; protects data in
  transit only, not data on device
- **SIEM integration**: Complements firewalls and IDS; does not replace packet
  filtering; provides policy compliance monitoring

---
